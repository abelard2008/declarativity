\section{Confluence}
\label{sec:confluence}

For many distributed computations, it is desirable to know that a deterministic result will be reached for every input, regardless of non-determinism in the environment.  Recall that nondeterminism in \lang only arises due to \dedalus{choice} in asynchronous rules, 
%which only occurs in asynchronous rules to model network nondeterminism.  
which model temporal nondeterminism in unreliable networks.
Model-theoretically, a nondeterministic result is manifest in multiple ultimate models.

\begin{definition}
A \lang program is {\em confluent} (has a deterministic output) if, for every EDB, it has a unique ultimate model.  A program that is not confluent is {\em diffluent}.
\end{definition}

Unfortunately, confluence is an undecidable property of \lang programs:

\begin{lemma}
\label{lem:confluence-undecidable}
Confluence of a \lang program is undecidable.
\end{lemma}
\begin{proof}
We take the undecidable problem of determining whether a two-counter machine accepts any input, and reduce it to testing confluence of a \lang program.  See appendix for details.
\end{proof}

Given undecidability, we will first identify classes of programs that have a unique ultimate model.  However, in general, a \lang program may encode many ultimate models.  We will show that every \lang program has a ``natural'' ultimate model that is preferable to all other ultimate models, and corresponds to intuition.  We show how to induce this ultimate model by rewriting the program.

%Fortunately, as we will show, there is a rich class of programs that can be statically detected as confluent.  Furthermore, many other programs have a ``natural'' ultimate model
%that corresponds to intuition; we show how to induce this ultimate model by augmenting the program.
%We will first consider programs that we can statically check as having a unique ultimate model.
%However, a \lang program may encode many ultimate models, so there is a question as to which ultimate model is preferable.
%\lang programs without negation are trivially confluent, as they are certain to have
%only one stable model.  The same is true of both negation-free and temporally stratified \lang programs that do not use the  {\em choice} construct.
%Cast in operational terms this is
%unsurprising: programs with no sources of nondeterminism have deterministic executions.

\eat{
\begin{example}
\label{ex:nonconfluent}
A non-confluent \lang program.

\begin{Dedalus}
p(x)@async <- p_edb(X);
q(X)@next <- p(X), !q(_);
q(X)@next <- q(X);
\end{Dedalus}
\end{example}

In the above program, assume the EDB contains facts \dedalus{p\_edb(1)} and \dedalus{p\_edb(2)}.  If the nondeterministic choice of \dedalus{async} chooses an earlier timestamp for \dedalus{p(1)} than \dedalus{p(2)}, then the ultimate model will consist of the single fact \dedalus{q(1)}.  Similarly, if \dedalus{p(2)} is assigned an earlier timestamp than \dedalus{p(1)}, then the ultimate model will consist of the single fact \dedalus{q(2)}.  If \dedalus{p(1)} and \dedalus{p(2)} are asigned the same timestamp, then the ultimate model will consist of the two facts \dedalus{q(1)} and \dedalus{q(2)}.  Since the program does not have a unique ultimate model for this EDB, it is non-confluent.
}

\subsection{Sources of Diffluence}

%Any \lang programs that use asynchronous rules have an infinite
%number of stable models, but as we will see, in many cases these correspond to a
%unique ultimate model.
%In general, however, \lang programs are not necessarily confluent even in the absence of negation.
First, we provide some intuition for the sources of diffluence in \lang programs.  
%In Example~\ref{ex:nonconfluent}, we saw a \lang program that was difluent because the ultimate model consisted of the first batch of messages in the \dedalus{p} predicate.

%\begin{definition}
%If removing negation 
%\jmh{Is that notion well-defined?  Just drop the exclamation points?  Be clear since this is a %surprising, semantics-changing thing to do.} 
%rom a \lang program results in fewer ultimate models, we say the program has {\em %nondeterministic world closing}.
%\end{definition}

\jmh{Added this.}
In Datalog programs with negation, the standard stratified interpretation assumes that predicates in a lower stratum are evaluated to fixpoint and ``closed'' before their contents are considered in higher strata.  In \lang, even with a stratified interpretation, the contents of a negated predicate at a given timestep $t$ may be a subset of its contents at $t+1$.  In essence, in \lang the closed-world assumption may be applied to incomplete sets over time.

Consider a \lang program $p'$ derived from another \lang program $p$ by 
%\paa{not dropping?}
dropping all negated subgoals 
%to positive subgoals (i.e., removing the $!$ symbol from 
%$p$) 
and removing any occurrences of the {\em count} aggregate function (i.e., replacing 
a clause like \dedalus{count<A>} with \dedalus{A}).  If $p'$ has fewer ultimate models than $p$, we say that $p$ has {\em nondeterministic
world closing}.  Nondeterministic world closing occurs when programs apply the closed world assumption to potentially incomplete sets.

\begin{example}
\label{ex:nonconfluent2}
A \lang program whose diffluence is caused by nondeterministic world closing.

\begin{Dedalus}
q()@async <- q_edb();
r()@async <- r_edb();
p() <- q(), !r();
p()@next <- p();
q()@next <- q();
r()@next <- r();
\end{Dedalus}

Assume an EDB of \dedalus{q\_edb(), r\_edb()}.  Any stable model where \dedalus{q()} has a lower timestamp than \dedalus{r()} yields an ultimate model containing \dedalus{p()}.  Otherwise, the ultimate model does not contain \dedalus{p()}.   We will see later how, using intuition from stratification to deterministically close worlds, we can induce confluence with an ultimate model that corresponds to intuition.
\end{example}


%\begin{definition}
%If a negation-free \lang program is diffluent, we say the program has {\em nondeterministic %coincidence}.

%\paa{isn't this backwards?  you are really saying, if a neg-free program is diffluent, it must be
%the case that it has nondeterministic coincidence, because we're pretty sure (I think I mostly %proved it...) that's the only other thing that can cause diffluence... but for this definition,
%don't we just want to define ``unguarded asynchrony'' here?}
%\jmh{I agree that this seems like a lemma, not a definition.}
%\end{definition}


Nondeterministic world closing is not necessary for program diffluence. 
A \lang program may have multiple ultimate models if it is possible for a join 
to succeed in one execution (stable model) and fail in another.  We say that such 
programs have {\em nondeterministic coincidence}.

\begin{example}
\label{ex:diffluent-noneg}
A \lang program whose diffluence is caused by nondeterministic coincidence.

\begin{Dedalus}
q()@async <- q_edb();
r()@async <- r_edb();
p() <- q(), r();
p()@next <- p();
q()@next <- q();
\end{Dedalus}

Example~\ref{ex:diffluent-noneg} may be obtained from Example~\ref{ex:nonconfluent2} by dropping negation in the third rule, and dropping the sixth rule. \jmh{Why do we care?}  As before, assume an EDB of \dedalus{q\_edb(), r\_edb()}.  Any stable model where the timestamp of \dedalus{q()} is less than or equal to the timestamp of \dedalus{r()} yields an ultimate model containing \dedalus{p()}.  Otherwise, the ultimate model does not contain \dedalus{p()}.  However, this example becomes confluent if we admit the last rule of Example~\ref{ex:nonconfluent2}: \dedalus{r()@next <- r();}.
\end{example}

%The above example illustrates that even without negation, a \lang program may induce multiple ultimate models.

We will see that ruling out both nondeterministic world closing and nondeterministic coincidence yields confluence.

\begin{definition}
A \lang program is {\em negation-free} if the \dedalus{!} symbol does not appear in the program.
\end{definition}

\begin{definition}

A fact $a$ is  {\em persistent} if it is henceforth true 
%(i.e., if $a \Rightarrow \Box a$) \jmh{cheating to borrow symbols from elsewhere.  use \lang notation or terminology.}
(i.e., if it is true at time $T$, then it is true at all $U > T$.)
\end{definition}

Persistent facts are the only facts that appear in a program's ultimate models.
Persistence is a semantic notion, but in certain cases it is detectable from the program's 
syntax alone.  A rule of the form \dedalus{p(X)@next <- p(X);} clearly establishes any fact
in \dedalus{p} as a persistent fact for any EDB and execution in which the fact
is ever true. 
We call a predicate referenced by such a rule
a {\em simply persisted} predicate.  
%All EDB predicates are both simply persisted and {\em a priori} true.  
We call a predicate that is both simply persisted and  {\em a priori} true (i.e., asserted
at time 0) a {\em ground truth}.  Ground truths are analogous to the EDB in Datalog programs,
in which time is not explicitly modeled.  \jmh{Sorta.  Though this makes non-time-0 EDB facts different, and I'm not sure why they're different from EDB in datalog.}

%\jmh{This last sentence surprised me.  Are you saying that is implicit in the language, or you will require simple persistence rules over the edb?  I though the edb facts were only true at time 1.}

\begin{definition}
A \lang program has {\em guarded asynchrony} if all predicates 
%\jmh{we have async rules, not async preds} 
appearing in the heads of \dedalus{async} rules
are simply persisted.
\end{definition}



\begin{lemma}
\label{lem:guarding}
A negation-free \lang program with guarded asynchrony is confluent.
\end{lemma}
\begin{proof}
%Sketch: only possible way two ultimate models are different is if two facts (or predicates, e.g. 
%``!'' on facts) join in one trace, but not the other.  If the program has guarded asynchrony, then 
%it is impossible for a join to succeed in one trace and not another.

%\wrm{yeah, this is right, need to define terms though-- define ``ground atom'' as ``first time %something in the ultimate model is true before it is eventually always true'', change ``join'' to %``unification'', change ``eventually always succeed'' to ``eventually always satisfied'' or %something, define ``modulo time'' define ``identical tuple''.  i'll let you fix this. you can delete %my sketch above too}

%\paa{I think I addressed everything but "change join to unify," which I don't agree with}
Towards a proof by contradiction, consider a negation-free \lang program that 
induces more than one ultimate model.  There must be a ground atom $a$ for a predicate $p$
that is true in one but
not in another model, and $a$ must be persistent, or it would not be
in the ultimate model.  Consider a derivation of $a$: a finite tree of applications of
implication whose leaves are EDB atoms.  If none of the implications involve a nondeterministic
choice of timestamp via an {\em async} rule, then certainly 
$a$ occurs in all stable models of the program,
%there is only one stable model of the program
%\jmh{I don't buy this; we're scoped down to atom $a$ here and the rules that feed into it}, 
so there must be at least one {\em async} rule in $a$'s derivation, contributing an atom
$r$.  
If $p$ is derived directly from 
$r$ via a series of derivation steps without any joins, then every stable
model $m$ will have a tuple $a_m$ in $p$ that differs from $a$ only in its timestamp, 
and hence correspond to the same ultimate model.
Therefore, $a$ must have at least one join step (i.e., a rule with at least two subgoals)
in its derivation following $r$,
which succeeded in this stable model (producing $a$), but did not succeed in another.  
%Guarded joins always
%eventually succeed, \jmh{don't you need to define ``join success'' and prove that guarded asynchrony does what you say?} what it and 

Consider such  a join rule.  One of its subgoals $s$ corresponds to a derivation that depends
on the async-derived atom $r$.  If any predicate between $s$ and $r$ is simply persisted and 
the program is negation-free,
then $s$ is persistent.  Regardless of the nondeterministic choice of timestamp for $r$, there
is some timestamp $V_m$ in every stable model $m$ of the program such that $s$ is true
for all $W > V$.  Hence in all stable models, $s$ is ``eventually'' true.  The same argument holds
for all subgoals of the rule under consideration, and hence guarded asynchrony implies that
all joins will eventually succeed.
Hence $a$ must exist in all ultimate models.

\end{proof}


If either qualification is false, problems can result, as we have previously illustrated.


\subsection{Monotonic Properties}

\paa{add some nice text here transitioning the discussion into distributed systems etc}

\begin{example}
%Example of a logically monotonic Dedalus program:\\
\begin{Dedalus}
response(X)@async <- response_edb(X);
node(X)@next <- node(X);
response(X)@next <- response(X);
all_responded() <- !not_responded(_);
not_responded(X) <- node(X), !response(X);
all_responded()@next <- all_responded();
\end{Dedalus}
\end{example}

%\jmh{suddenly we're getting to the nub of our application domain.  needs more prose to set this up; possibly even a section break}
%The above program is very nearly monotonic \jmh{whatever that means}. 

If we assume that 
%the contents of \texttt{node}
%are fixed (e.g., it is EDB and given \emph{a priori}), 
\texttt{node} is a ground truth,
there is only one possible nonempty ultimate model, which contains \dedalus{all\_responded()}, and this fact is implied by a predicate \dedalus{!not\_responded(\_)}, which \jmh{not sure what ``which'' refers to} is monotonic because it is {\em positive} (i.e. the negation depth is even). 
Note that the program is also confluent, because for any EDB, there is a unique ultimate model: either every node has an associated response, leading to a model with \dedalus{all\_responded()}, or there exists some node without an associated response, leading to an empty ultimate model.

If the set \texttt{node} is not fixed, however, the program is not monotonic, because 
\texttt{all\_responded} is defined with odd negation depth over \texttt{node}: adding a tuple
to \texttt{node} may cause a fact in \texttt{all\_responded} to become false.  If such inserts
are possible, careful maintenance of \texttt{node} is required to ensure confluence: we will
return to this subject in the following section when we introduce {\em coordination}.
%will require coordination 
%\jmh{we haven't defined coordination yet!}.  
This is analogous to
the problem of dynamic membership in quorum systems: quantifying over all (or a majority
of) participants requires some static ``view'' of membership, and changing these views requires
explicit coordination among participants.



We can generalize Lemma~\ref{lem:guarding} to account for monotonic programs that 
contain syntactic negation and aggregation with
the notion of a {\em monotonic property}.




\begin{definition}
A monotonic property is a formula which, if it is true at time \dedalus{T},  is true at any time \dedalus{U > T}.
\end{definition}

Intuitively, a monotonic property represents some knowledge that never becomes untrue as we acquire  more knowledge.  A persistent fact is a monotonic property, as is the negation of a
fact that will never be true.  We may define monotonic properties constructively as follows. \jmh{You're not defining, you're giving examples, right?}

%\paa{this constructive definition of monotonic properties may not pan out: feel free to revert.}
%\wrm{your definition is conservative.  first off, let's assume we can specify properties about sealed sets, so we know that coordination is monotonic.  now i want to know that adding coordination to a set makes its negation a monotonic property.  in other words, i have some \dedalus{foo} set that's async, and i want to coordinate something that depends on the negation of \dedalus{foo}.  so i change everything that defines \dedalus{foo} to some new predicate symbol \dedalus{bar}, and define \dedalus{foo} <- \dedalus{bar}, \dedalus{coordination\_foo}.  Now, we know that coordination\_foo is monotonic, and let's say \dedalus{bar} is monotonic.  When I negate \dedalus{foo}, I have the negation of two monotonic properties, but the negation of \dedalus{foo} is monotonic because the coordination is implemented properly, and only goes to true when \dedalus{foo} is complete.}

\begin{enumerate}
\item A persistent fact is a monotonic property.   
Note that facts in simply persisted relations cannot be retracted once they are asserted.  They begin false
(insofar as their complement can be asserted), and if they become true remain so.


\item A fact defined with even depth of negation over a monotonic property in all derivations is also a monotonic property.

The proof is trivial: even negation depth ensures that the polarity of the fact in question is the
same as that the monotonic property.  In the absence of recursion, negation depth is a syntactically-checkable property.  Whenever there is recursion through negation
(as in temporally stratified \lang programs~\cite{dedalus}), the negation depth is data-dependent.


\item A fact defined via an application of a non-async rule all of whose subgoals are monotonic properties is a
monotonic property.



\item A \lang program is {\em monotonic} if all facts in any ultimate model are monotonic properties.  \jmh{This doesn't belong in this list.  This is a standalone defn.}
\end{enumerate}

This list of constructive base cases for monotonic properties is not complete: later \jmh{use a fw ref in latex} we will
axiomatize the way that certain coordination techniques can transform an otherwise 
nonmonotonic predicate into a monotonic property.


We will see that all logically monotonic programs are confluent.  However, some programs that are not logically monotonic are confluent.

\begin{lemma}
If a monotonic property is true in any stable model of a program over a particular EDB, it is true in all stable models. 
\end{lemma}
\begin{proof}
\begin{comment}
Proof sketch: assume a monotonic property is true in one trace and false in another trace.  This means the monotonic property can differentiate between the two traces.  But since all async facts are persisted \jmh{when did we start requiring this?  I think you need to state it as an assumption in the lemma}, all messages eventually rendezvous.  Thus, the monotonic property must be able to observe the condition that some event has not yet occured (but will eventually occur). \jmh{I don't know what the preceding sentence means; I don't know what it means for a property to observe a condition.}  Monotonic properties cannot observe this though, becuase the property will be eventually untrue (when the thing that has not yet occured eventually occurs), thus it is not monotonic. \jmh{That only sorta made sense to me.}

\paa{or alternatively:}
\end{comment}
We proceed by induction on derivation depth.
% We will prove by structural induction that if a montononic property is true in any stable
% model of a \lang program, it is true in all stable models.  Consider a montonic property
% $p$.  
As a base case, $p$ may be an EDB fact, which clearly exists in all stable models.
\jmh{The remainder of this argument is not inductive.  Fix.}
Otherwise $p$ has a derivation $d$ grounded in EDB facts.  As we showed in the
proof of Lemma~\ref{lem:guarding}, if none of the inference 
steps in $d$ is an {\em async} rule, then $p$ exists in all stable models
of the program.
%\jmh{no, we're scoped to $p$ here} 
and
the lemma trivially holds.  If there are {\em async} rules, their head predicates are guarded,
because otherwise those head predicates are not monotonic
properties 
%\jmh{No, you only proved the inverse of that assertion: guarded$=>$monotonic.}
, and hence $p$, which depends on them, is not a monotonic property.  If there 
is no negation in any inference step of $d$, then by Lemma~\ref{lem:guarding} the program
is confluent, and hence facts in stable models of the program differ only in their timestamps.
Finally, if there is negation in $d$, $p$ is defined with even depth of negation over some
monotonic property or it would not itself be.  \paa{...hm, where do we go from here.  can
we argue syntactically that all derivations of $p$ in any stable model would be of the same 
depth of negation nesting??} \jmh{I like the idea of induction for this.} 

\ref{lem:guarding}
\end{proof}
%\paa{I don't really get the proof.  what does it mean for a property to observe a condition?} 

\begin{theorem}
Confluence is assured by logical monotonicity. \jmh{Can we get away with the phrase ``logical monotonicity?''  I think we may need to be more specific.}
\end{theorem}
\begin{proof}
\begin{comment}
Proof sketch: If a particular ultimate model is populated by atoms that depend only on monotonic properties, then those atoms occur in any ultimate model of the program.  If all ultimate models
are populated in such a way, they are indeed all the same, unique ultimate model.  
\jmh{
\end{comment}
The proof ollows directly.  By definition 13, a monotonic Dedalus program has an ultimate model consisting of only monotonic properties, and by Lemma 3 all such properties are true in all ultimate models.  Hence all ultimate models of a monotonic Dedalus program are the same.

%which are true in all traces, then there is a unique ultimate model.

\end{proof}

We now show that logical monotonicity is not necessary for confluence:

\begin{example}
A confluent Dedalus program that is not logically monotonic.
\jmh{I guess the first rule is legal because it has an omitted \dedalus{node} predicate, but it looks badly un-range-restriced.}
\begin{Dedalus}
//client
b(#s, I)@async :- b_edb(I);

//server
b(N, I)@next <- b(N, I), !dequeued(I);
b_lt(I, J) <- b(_, I), b(_, J), I < J;
dequeued(I)@next <- b(_, I), !b_lt(_, I);
mem(I) <- dequeued(I), !bt_lt(_, _);

\end{Dedalus}
\wrm{or, just consider the 2 counter machine...?}
\end{example}

%odd()@next <- odd(), !dequeued(_);
%odd()@next <- dequeued(), even();
%even() <- !odd();

%The ultimate model contains \dedalus{odd()} if there are an odd number of \dedalus{b\_edb(I)} %facts, and \dedalus{even()} otherwise.  
This program has a single ultimate model in which \dedalus{mem()} contains the highest
element in \dedalus{b\_edb()} according to the order \dedalus{<}.
Thus it is confluent.  However, the program is not logically monotonic because neither \dedalus{dequeued()} nor \dedalus{!dequeued()} are monotonic, so \dedalus{mem()} is not supported by only monotonic properties, thus the program is not logically monotonic.

\subsection{Perfect Ultimate Model}
\wrm{we are assuming guarded asynchrony}
\wrm{rework definition to make clear we aren't coordinating @nexts}
\jmh{motivate coordination by analogy to practice}
Programs that are not confluent often have a single ``natural'' ultimate model that corresponds to intuition, much as Datalog programs with negation have a {\em perfect model} corresponding to the model obtained by evaluating the program in a ``natural'' order.  For various uses of negation, we will define a {\em perfect ultimate model}, and present a rewrite technique to convert a \lang program into a confluent program that computes this model.

Consider the following example, which is analogous to example~\ref{ex:nonconfluent2} above:

\begin{example}
\label{ex:sayers}
The non-confluent ``sayers'' program.

\begin{Dedalus}
//sayer
statement(#L, S, X)@async <- statement_edb(#S, X),
                             node(L);
s_false(#L, S, X)@async <- statement_edb(#S, X),
                           false_edb(#S, X),
                           node(L);

//listener
true(X) <- statement(_, S, X), !s_false(_, S, X);
false(X) <- statement(_, S, X), s_false(_, S, X);
statement(L, S, X)@next <- statement(L, S, X);
s_false(L, S, X)@next <- s_false(L, S, X);
true(X)@next <- true(X);
\end{Dedalus}
\end{example}

Intuitively this program represents a group of nodes (the ``sayers'') making statements to all nodes (the ``listeners'').  The sayers also occasionally remark that a statement is false (but a sayer may only declare one of his own statements to be false -- not the statement of another sayer).  One may expect the contents of \dedalus{true} to contain all statements that are not \dedalus{false}.  However, this is not necessarily the case.  Recall that the un-sugared version of the third rule is:

\begin{Dedalus}
true(X,T) <- statement(X,T), !false(X,T);
\end{Dedalus}

Thus, the contents of \dedalus{true} at time \dedalus{T} is those items in \dedalus{statement} at time \dedalus{T} that are not in \dedalus{false} at time \dedalus{T}.  So in fact, the contents of \dedalus{true} in the ultimate model is ``everything stated that was ever not false''.  Such counter-intuitive results are enabled because the closed-world assumption is being applied to incomplete sets.

\begin{definition}
The {\em perfect ultimate model} of a \lang program with no negative cycles in its PDG, denoted $\mathcal{P}(P, E)$, is the ultimate model induced by ensuring a rule containing a \dedalus{!} or a \dedalus{count} is not evaluated until the complete set of facts in the negated or aggregated predicates is known.
%In other words, one must have ``complete information'' before applying the closed-world assumption for negation.
This intuitively corresponds to the definition of a perfect model from the Datalog literature.
%\wrm{make more formal}  \paa{this is an incomplete definition, right?  we are also interested in
%programs which when temporally flattened are not syntactically stratifiable, yet have a single ultimate model 
%corresponding to their ``coordinated'' evaluation(s)}
\wrm{Insert UCS Here}
%The perfect ultimate model of a universally constraint stratified~\cite{ross-ucs} program that is universally constraint stratified~\cite{ross-ucs} is the ultimate model induced by ensuring that for every predicate that appears negated in the program subsets are completed in the partial order associated with the stratification.
\end{definition}

%There is always a stable model representing the perfect ultimate model of a \lang program whose flattening is syntactically stratified, because there is no recursion through negation, and Lemma~\ref{cron} tells us that any choice of timestamps is permissible in this case.\jmh{huh?}

Example~\ref{ex:sayers} has no negative cycles in its PDG, thus the rule with \dedalus{!s\_false} in the body should not be evaluated until the \dedalus{s\_false} set is complete.  We can check completeness by having each sayer send a digest of \dedalus{s\_false} messages to all listeners; the listeners recompute the digest over the \dedalus{s\_false} messages they have received; when the computed digest matches the received digest, a data dependency is satisfied, which enables the rule with \dedalus{!s\_false}.

%In Example~\ref{ex:sayers}, any stable model where no \dedalus{false} message arrives after a \dedalus{statement} message with the same value results in the perfect ultimate model.
%In particular, we can modify the program to be confluent with the perfect ultimate model by ensuring that negation is not applied until the \dedalus{false} set is complete.  It turns out we can generalize this into an algorithm for all \lang programs whose temporal flattening is syntactically stratified.

%\wrm{for unstratifiable flattenings, we can introduce another notion of the ``synchronous flattening'', and fully order individual messages passing through an unstratifiable recursion through negation, and call this the perfect ultimate model...}

One possible digest is a \dedalus{count} of \dedalus{s\_false} messages\footnote{A digest that does not use \dedalus{count} has each sayer sort their messages, and send the sorted order, as well as the maximum message.}.  We add the following two rules to compute counts of false messages at each sayer, and each listener:

\begin{Dedalus}
count_false_sent(#N, S, 0) <- !false_edb(#S, _), node(N);
count_false_sent(#N, S, count<X>) <- false_edb(#S, X),
                                     node(N);
count_false_recv(S, count<X>) <- s_false(_, S, X);
\end{Dedalus}

Furthermore, we add a dependency on the equality of the counts into the body of the \dedalus{!s\_false} rule:

\begin{Dedalus}
true(X) <- statement(_, S, X), !s_false(_, S, X),
           count_false_recv(S, X),
           count_false_sent(_, S, X);
\end{Dedalus}

Now, independent of the assignment of timestamps, no statement from a sayer \dedalus{S} is considered to be true by any listener unless the listener has complete information about which statements are false.

\subsubsection{Coordination}
Given a \lang program $P$ with no negative cycles in its PDG, we can generate a confluent program $\textsc{Coord}(P)$, such that \linebreak $\mathcal{U}(\textsc{Coord}(P), E) = \mathcal{P}(P, E)$.


\begin{algorithmic}[1]
  \Procedure{Coord}{$P$}%\Comment{}
  \ForAll{\dedalus{p} such that $\dedalus{q} \Diamondright \dedalus{p} \nrightarrow \dedalus{r}$}
  \ForAll{async rules with \dedalus{p} in the head}
  \State{change head predicate name to \dedalus{p\_local}}
  \State{remove location attribute of every atom in rule}
  \EndFor
  \State{add rules in Figure 1} \label{alg:addrules} %XXX
  \ForAll{rules with \dedalus{!p} in the body} \label{alg:lastfor}
  \State{add \dedalus{!p\_incomplete()} to body}
  \EndFor
  \EndFor%\label{euclidendwhile}
  \State \textbf{return} $P$
  \EndProcedure
\end{algorithmic}


\begin{figure}[h!]
\label{fig:coordcode}
\begin{Dedalus}
p_count_send(#Y,S,count<*>)@async <- p_local(#S,Y,\dbar{X});
p_count_send(#Y,S,0)@async <- !p_local(#S,Y,\dbar{_});
p_send(#Y,S,\dbar{X})@async <- p_local(#S,Y,\dbar{X});
p_count_recv(S,count<*>) <- p(S,\dbar{X});
p_count_send(#Y,S,C)@next <- p_count_send(#Y,S,C);
p(\dbar{X}) <- p_send(\dbar{X});
p(\dbar{X})@next <- p(\dbar{X});
p_incomplete() <- node(S), !p_count_recv(S,_);
p_incomplete() <- node(S), !p_count_send(S,_);
p_incomplete() <- p_count_recv(S, C1),
                  p_count_send(S, C2), C1 < C2;
\end{Dedalus}
\caption{Coordination code}
\end{figure}

\begin{theorem}
For any program $P$, $\mathcal{U}(\textsc{Coord}(P), E)|_{\text{Pred}(P)} = \mathcal{P}(P, E)$, where $\text{Pred}(P)$ is the set of predicates in program $P$\footnote{We consider $\mathcal{U}(\textsc{Coord}(P), E)|_{\text{Pred}(P)}$ instead of $\mathcal{U}(\textsc{Coord}(P), E)$ because the latter contains facts in the predicates \dedalus{p\_count\_send}, \dedalus{p\_count\_recv}, and \dedalus{p\_incomplete()}.}.
\end{theorem}

A straightforward argument shows that if \dedalus{p\_incomplete()} is false at time \dedalus{t}, then it is false at time \dedalus{t+1}.  It is easy to see if \dedalus{p\_incomplete} is false at time \dedalus{t}, then there cannot exist a \dedalus{p} fact derived by an asynchronous rule at timestamp $\dedalus{t+1}$.  Thus, any rule with \dedalus{!p\_incomplete()} will not be satisfiable until all elements in the \dedalus{p} set are known.

\wrm{UCS Here}

\subsubsection{Nondeterministic Coordination}
As noted in Section~\ref{sec:failure}, practical distributed systems may experience failure.  A coordinated program may forever wait if a channel fails, and messages are lost---for example, \dedalus{p\_count\_recv} and \dedalus{p\_count\_send} may never be equal.  Thus, the perfect model is unachievable.  However, we do not want to give up and accept any arbitrary ultimate model.  We define a generalization of the perfect ultimate model called a {\em consistently sealed ultimate model} which we argue is preferable to an arbitrary ultimate model.

\begin{definition}
A {\em consistently sealed ultimate model} is an ultimate model generated by non-deterministically committing to the the current contents of a predicate.
\end{definition}

In Example~\ref{ex:sayers}, all consistently sealed ultimate models have the property that there is no \dedalus{statement} that is both \dedalus{true} and \dedalus{false}, however the \dedalus{true} set may be a superset of the \dedalus{true} set in the perfect ultimate model.  

Note that the perfect ultimate model is a consistently sealed ultimate model; it is the optimal such model in the sense that it commits to the largest version possible of any set.

%Consider what happens when we admit transient and permanent failures of nodes and channels to the model.  It is now the case that nodes may forever wait for a message that will never arrive.  Thus, achieving the perfect ultimate model comes at the expense of liveness.  It may be desirable to accept that the message will never arrive, and proceed with the computation.

%Example~\ref{ex:nonconfluent} performs non-deterministic sealing -- the first batch of \dedalus{p} facts are sealed in \dedalus{q}, and any further \dedalus{p} facts are ignored.  Any ingored \dedalus{p} facts correspond to ``lost'' \dedalus{p} facts, due to either transient or permanent channel or node failure.  It is easy to see that each possible ultimate model represents a possible failure scenario, and each combination of node and channel failures is represented, including the scenario with no failures~\footnote{In practical systems, we may want to model specific real-time constraints -- for example, we declare the set closed after a certain number of seconds have elapsed.  We can easily express this by adding the notion of a ``timer'' (a fact inserted into the queue at intervals measured on a wall clock) to our operational semantics.}.

For any \lang program $P$ with no negated cycles in its PDG, we can generate $\textsc{NDCoord}(P)$, the instrumentation of $P$ so it computes only consistently sealed ultimate models.  The procedure is the same as $\textsc{Coord}$, except we skip the loop on line~\ref{alg:lastfor}, and instead of line~\ref{alg:addrules}, we add the following rule:

\begin{Dedalus}
p(\dbar{X}) <- p_send(\dbar{X}), !p(\dbar{_});
\end{Dedalus}

%Applying In example~\ref{ex:sayers} above,   The instrumented version of the example would add the following rule:
%
%\begin{Dedalus}
%c_false(L, S, X)@next <- s_false(L, S, X),
%                         !c_false(_, _, _);
%\end{Dedalus}
%
%And would replace any instance of the predicate \dedalus{s\_false} in the ``listener'' rules with \dedalus{c\_false}.

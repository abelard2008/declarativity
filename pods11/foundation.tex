\section{\large \bf \lang}
\label{sec:slang}

\lang is based on Datalog$\lnot$~\cite{ullmanbook}: Datalog enhanced with arbitrary negation (we will henceforth refer to Datalog$\lnot$ as ``Datalog'').  Each predicate in \lang has single a distinguished {\em temporal attribute}, which takes on only values from the {\em temporal universe} ($\mathbb{N}$)
%\cup \infty$
, represented by the unary relation \dedalus{time}).
%We will see later how $\infty$ is used to model failure.
The balance of the arguments are generic and may not take on values from the temporal universe.  We admit the order constraints \dedalus{<}, \dedalus{=}, \dedalus{!=}, and \dedalus{<=}, over all elements in the generic universe, and the order constraint \dedalus{<} over the temporal universe.
%, where every element of $\mathbb{N}$ is less than $\infty$.

We assume an infinite binary relation over the temporal universe
%(except $\infty$)
called \dedalus{successor} $:= \{(a,b) \ | \ a + 1 = b\}$.  We also admit Sacc\`{a} and Zaniolo's \dedalus{choice} construct~\cite{sacca-zaniolo}---a model-theoretic characterization of non-determinism using stable models of cyclic negation~\cite{stable-model}, which we use to model the inherent non-determinism of asynchronous distributed computation.  To model distribution, we adopt the convention introduced in~\cite{Loo:2005}, where all predicates (except for \dedalus{successor} and \dedalus{time}) are {\em horizontally partitioned};  the location of a fact in a predicate is indicated by the value of its {\em location attribute}, a single column whose variable symbol is prefixed with a \dedalus{\#}.  All atoms that reference a predicate must indicate the same column as its location attribute.

We also admit the \dedalus{count} {\em aggregate} over the generic universe, which computes the number of elements in a set.  Our syntax for \dedalus{count}, similar to~\cite{datalog-agg}, allows its use in the head of a rule, such as:

\begin{Dedalus}
p(\dbar{X}, count<Y>) <- ...;
\end{Dedalus}

For each binding of variables in \dedalus{\dbar{X}}, \dedalus{p} contains the count of distinct satisfying assignments to the variable \dedalus{Y}.  It is also permissible to use the symbol \dedalus{*} as the argument to a count if \dedalus{\dbar{X}} is ommitted; this counts the number of distinct satisfying assignments to all body variables.

We presently outline restrictions on \lang.

\vspace{1em}
\noindent {\bf Locality in Space and Time:}
\lang requires that all atoms in each rule body use the same variable symbol in their temporal attribute.  \lang also requires that all atoms in each rule body use the same variable symbol in their location attribute.  If the rule head's location attribute uses the same variable symbol as the body, we call the rule {\em local}.  Otherwise the rule is a {\em communication rule}.

%, and that its value must not be $\infty$.
The temporal variable in the head atom may be constrained by exactly one of the following methods:

\begin{enumerate}
\item The rule is called a {\em deductive} rule if its head temporal variable is the same as its body temporal variable;
\item The rule is called an {\em inductive} rule if its head temporal variable is the \dedalus{successor} of its body temporal variable;
\item The rule is called an {\em asynchronous} rule if its head temporal variable is constrained using the \dedalus{choice} construct over all body variables (including the body temporal variable).
\end{enumerate}

All deductive and inductive rules must be local.  Asynchronous rules may either be local or communication rules.

\begin{example}
\label{ex:nonsugared}
Examples of local deductive, inductive, and asynchronous rules, and a communication rule, where \dedalus{S} and \dedalus{T} are variables ranging over the temporal universe.
\\\\
deductive:\\
\begin{Dedalus}
p(#X, A, B, T) <- e(#X, A, B, T);
\end{Dedalus}
inductive:\\
\begin{Dedalus}
q(#X, A, B, S) <- e(#X, A, B, T), successor(T, S);
\end{Dedalus}
asynchronous local:\\
\begin{Dedalus}
r(#X, A, B, S) <- e(#X, A, B, T), time(S), S > T,
                  choice((A, B, T), (S));
\end{Dedalus}
asynchronous communication:\\
\begin{Dedalus}
r(#Y, A, B, S) <- e(#X, A, B, T), time(S), S > T,
                  choice((A, B, T), (S)),
                  neighbor(#X, Y);
\end{Dedalus}
\end{example}

\dedalus{choice} and \dedalus{successor} are prohibited in rules, except as described above.

Since unification on the temporal attribute is required in every rule body,
%(as well as the $!= \infty$ constraint)
we introduce syntax sugar that omits the body temporal variable.  Since the relationship between the head and body temporal variables is tightly constrained, we omit the head temporal variable and instead introduce a temporal annotation: \dedalus{@next} or \dedalus{@async}.  We also omit the location specifier in local rules.  In Example~\ref{ex:sugared}, we rewrite the above rules using this syntax sugar.

\begin{example}
\label{ex:sugared}
The rules from Example~\ref{ex:nonsugared} in sugared form.
\\\\
deductive:\\
\begin{Dedalus}
p(A, B) <- e(A, B);
\end{Dedalus}
inductive:\\
\begin{Dedalus}
q(A, B)@next <- e(A, B);
\end{Dedalus}
asynchronous local:\\
\begin{Dedalus}
r(A, B)@async <- e(A, B);
\end{Dedalus}
asynchronous communication:\\
\begin{Dedalus}
r(#Y, A, B)@async <- e(#X, A, B), neighbor(#X, Y);
\end{Dedalus}
\end{example}

When we talk about the {\em predicate dependency graph} (PDG)~\cite{ullmanbook} of a \lang program, we assume that it does not include the \dedalus{time} or \dedalus{successor} predicates\footnote{We also assume that the graph does not include any predicates or rules added by rewriting \dedalus{choice}.}.  In addition to marking edges in the graph as negated, we will keep track of which edges are \dedalus{@async} or \dedalus{@next}---we will refer to such edges as {\em temporal edges}.


\vspace{1em}
\noindent {\bf EDB:}
By convention, EDB facts are supplied without a time suffix, and are true at the first time: timestamp \dedalus{0}.  Like Datalog, we require the EDB to be finite.

\vspace{1em}
\noindent {\bf Negation and Aggregation:}
\lang restricts negation by requiring any recursion through negation to include a temporal edge\footnote{The only exception is the rewrite of \dedalus{choice}, which involves recursion through negation without any temporal edges.}  Any recursion through \dedalus{count} is disallowed, in order to ensure finiteness of the generic universe.

%\subsection{Design Rationale and Implications}

%Below we explain the rationale for certain choices.
%\wrm{We need to remember to mention the dual role of time.  Atomicity and non-determinism.  Say stuff about dense partial orders.}

%{\bf Time:}
%We want to model intermediates states of distributed systems that are not necessarily models of the programs and their
%input (e.g., to represent states with messages that are in flight, in which the premises
%of certain implications hold but their conclusions do not).
%Moreover, distributed systems are often noninflationary over time.  However, Datalog's {\em least fixpoint} operator is inflationary.  Reifying time into the langauge solves both these problems.
%{\bf Locality in Time and Space:}
%\begin{definition}
%The {\em temporal diameter} of a \lang program is the number of ``old values'' accessible for a fact \wrm{formalize}.
%\end{definition}
%Every \lang program has a temporal diameter polynomial in the data size \wrm{or is this linear??}.\footnote{We can allow a program to have an unbounded temporal diameter by allowing {\em entanglement} between the {\em temporal} kind and the {\em data} kind.  This is sufficient to model an arbitrary Turing Machine in \lang (via substitution of \dedalus{finite\_succ} with \dedalus{successor} in the proof of Lemma~\ref{lem:} in the appendix.}.
%\paa{still not sure what we need this for}

%\begin{example}
%A \lang program with a temporal diameter of 2.
%
%\begin{Dedalus}
%p_1(X,Y)@next \(\leftarrow\) p(X,Y);
%p_2(X,Y)@next \(\leftarrow\) p_1(X,Y);
%r(X,Y) \(\leftarrow\) p_2(X,Y), q(X,Y);
%\end{Dedalus}
%\end{example}

%\wrm{synchronous systems are captured by \lang with no @async}
%\wrm{explain motivation for non-determinism.  why don't we just treat the whole world as synchronous?}

\subsection{Semantics}
Since \lang uses \dedalus{choice}, we characterize the semantics of \lang programs in terms of the {\em stable model semantics}~\cite{stable-model}.  A \lang program without asynchronous rules has a single stable model\footnote{This corresponds to its perfect model evaluated with local stratification on temporal attributes.  It is known that the stable model semanics coincides with the perfect model semantics for locally stratified programs~\cite{stable-model}.}.  Use of the \dedalus{choice} construct in asynchronous rules induces multiple stable models; each corresponds to a different non-deterministic choice of timestamps.  Later when we define our operational model of a distributed system, we will argue that the multiplicity of stable models captures all possible executions of a distributed system.
%A stable model of a \lang program is a trace of one of its possible distributed executions,.

However, there are two issues with considering a stable model as the {\em output} of a \lang program.  First, every program with an asynchronous rule has infinitely many stable models.  Not all of these stable models may be meaningfully different.  Second, a stable model of a \lang program may be infinite.  We address both concerns in our definition of an {\em ultimate model}.

\begin{example}
\label{ex:flipflop}
A \lang program with an infinite stable model.

\begin{Dedalus}
flipflop(Y,X)@next \(\leftarrow\) flipflop(X,Y);
flipflop(1,2)@1;
\end{Dedalus}

\dedalus{flipflop(1,2)} is true at all odd times, and \dedalus{flipflop(2,1)} is true at all even times.  In other words \dedalus{flipflop(1,2)} and \dedalus{flipflop(2,1)} are each cyclic with period 2.
\end{example}

%by regarding the output of the program as those facts that are eventually always true.  Thus, if two stable models differ only momentarily, but are ``eventually the same,'' we regard these stable models as producing the same output.

%\subsubsection{Ultimate Models}

\begin{definition}
For each stable model, the cylic facts of period 1---so-called {\em trivially periodic} facts---comprise an {\em ultimate model} for the program.  We represent a trivially periodic fact in the ultimate model finitely by picking a representative, and discarding its timestamp.  For example, the trivially periodic fact \{\dedalus{p(a,7); p(a,8); p(a,9);} \ldots\} is represented in the ultimate model as \dedalus{p(a)}.  A program has multiple distinct ultimate models if it has multiple stable models with different trivially periodic facts.
\end{definition}

%The program in Example~\ref{ex:flipflop} has a single ultimate model, which is empty.
Note that ultimate models are always of finite cardinality because the only constant symbols that may appear in the ultimate model are those from the EDB, which is finite, and finitely many numbers generated by \dedalus{count}.  By the same reasoning, a \lang program may only have a finite number of different ultimate models.  As long as two stable models have the same nontrivial periodicities, they result in the same ultimate model, regardless of any other differences in their behavior over time.

%\begin{example}
%A \lang program with uncountably many stable models, but a single ultimate model.
%
%\begin{Dedalus}
%p(X,Y)@next \(\leftarrow\) p(X,Y);
%r(#X,Y)@async \(\leftarrow\) p(X,Y);
%\end{Dedalus}
%\end{example}


%\wrm{re-frame the CRON conjecture as part of proving equivalence to the operational formalism}
%\wrm{In the CRON conjecture below, we should explain how purely monotonic logic does not allow us to establish a ``happens before'' relation on network traffic.  If we can't express it, then intuitively it doesn't matter whether the execution abides by the property.}
%\begin{lemma}
%Any non-deterministic choice of timestamps induces a stable model for a \lang program with no recursion through negation; If a \lang program has recursion through negation, only a causal choice of timestamps is permissible~\footnote{This lemma is similar in spirit to Hellerstein's CRON conjecture~\cite{declarative-imperative}.}.
%\end{lemma}
%
%Note that we have not restricted \dedalus{async} to choose a timestamp in the future.  Thus, one may be concerned about a {\em temporal paradox}, such as the grandfather paradox.  A program that we might be worried about would be the following:
%
%\begin{Dedalus}
%g(X)@next \(\leftarrow\) g(X), !del_g(X);
%del_g(X)@async \(\leftarrow\) p(X), g(X);
%p(1)@3;
%g(1)@1;
%\end{Dedalus}
%
%Taking the operational interpretation, we might posit the folowing trace, where \dedalus{p(1)@3, g(1)@3} cause \dedalus{del\_g(1)@2} in the past, implying that \dedalus{g(1)@3} should never have existed:
%
%\begin{Dedalus}
%g(1)@1;
%g(1)@2;
%del_g(1)@2;
%g(1)@3;
%p(1)@3;
%\end{Dedalus}
%
%\begin{proof}
%By the definition of the stable model semantics, such situations due not produce stable models~\cite{stable-model}.  Whereas, if recursion through negation is unsatisfiable, all choices of timestamps produce stable models.
%\end{proof}

%\subsubsection{Predicate Dependency Graphs}
%A \lang program may be represented as a directed graph of the dependencies
%among predicates called a \textbf{PDG}.
%Each predicate in the program corresponds to a node in the PDG.
%For every subgoal \texttt{B} appearing in the body of a rule with head \texttt{A},
%we add to the graph a directed edge from \texttt{B} to \texttt{A}.  The edges are annotated
%with a set of labels representing additional syntactic information that is relevant to 
%analysis.  In particular, if the subgoal is negated or the rule applies an aggregate function,
%its corresponding edge is labeled as nonmonotonic.  If the rule is inductive or asynchronous,
%it is labeled as such.
%In general, we do not include the \dedalus{time} or \dedalus{successor} predicates in PDGs,
%nor do we include any predicates or rules added by rewriting \dedalus{choice}.

\subsection{Operational Interpretation}

\vspace{1em}
{\bf Computing the Ultimate Model:}
Any \lang program with no asynchronous rules is a $\text{Datalog}_{1S}$ program, whose ultimate model can be computed in polynomial space, in the size of the input~\cite{tdd}. 
Let $G$ be the number of ways to instantiate all predicates' generic arguments with all constants from the generic universe, and let $c$ be the maximum depth of the timestamp of any input to the program---in this case, $c=1$, because all inputs are EDB, and all EDB facts are considered during the first timestamp.  The algorithm runs each partition of the program for $2^{G+1} + c$ timestamps and tracks the periodicity of each of the facts---there are polynomially many of these in the size of the data.  Evaluation of a single timestamp is akin to evaluation of a Datalog program, which may take polynomial time~\cite{immerman-ptime, vardi-ptime}.  After evaluating the Datalog program at time $i$, the IDB facts whose timestamp is $i+1$ are considered the EDB of the Datalog program at time $i+1$.


With asynchronous rules, the $c=1$ assumption does not hold.  Asynchronous facts may appear at arbitrary timestamps, including after any maximum timestamp committed to by our algorithm.  We start running on the EDB for $2^{G+1}$ timestamps.  Then at some later time, we may receive a batch of new messages.  If we have already seen this same batch of messages at an earlier time, we do not need to do anything.  If we have not seen this batch before, the batch may enlarge $G$ to $G'$ by introducing new constants (from another node).  Regardless of any enlargement, we will then need to run for $2^{G'+1}$ more steps if we haven't seen the batch before.  A naive solution to keep track of the batches requires exponential space.  If we complete our designated number of steps without receiving another message, the node goes into a waiting state.  Once all nodes are in a waiting state and there are no outstanding messages being delivered, the ultimate model is computed.  This takes a finite number of computation steps, but can of course take unbounded time, unless we assume bounded message delay, or admit timeouts to enforce real-time constraints.  We will show how failure is modeled later.


%\wrm{talk about operational interpretation of choice}
Operationally, we can model a \lang execution as a collection of nodes (Turing Machines), each enhanced with an input queue, and fully connected by channels that may arbitrarily delay or re-order messages.  Each node continuously executes phases, where each phase comprises a polynomial number of steps.  Steps consist of normal Turing Machine operations, as well as a node writing to its own queue.  Information about the derived facts is written to the tape for atemporal rules, and is written to the queue for inductive rules.  Upon completion of a phase, the Turing Machine writes information about derived facts for asynchronous rules to the queues of the nodes indicated in the location specifiers.  Then, the tape is erased, and atomically, the contents of the queue are moved to the tape.

In other words, a fact, \dedalus{p(\dbar{c}, t)}, with some constant \dedalus{t} in its time suffix can be thought of as a fact that is true at a node during some local phase represented by time \dedalus{t}.  Deductive rules can be seen as {\em instantaneous} statements: their deductions hold for predicates agreeing in the time suffix and describe what is true during the current phase given what is known during the current phase. Inductive and asynchronous rules are {\em temporal}---their consequents are defined to be true during a later phase than their antecedents.

Requiring unification on temporal and location attributes enables the locally synchronous evaluation process of atomically erasing and rewriting the tape at the boundary between phases.  It also ensures that the only communication between nodes occurs due to derived facts in asynchronous rules.  The non-determinism of \dedalus{choice} models the asynchrony between the machines, which may be caused by different nodes running at different speeds, or by the nondeterminism of the channels. Thus, \dedalus{choice} models the fact that the data that will be dequeued for a given phase on a node is unknowable, until it is actually dequeued.

\subsection{Modeling Failure}

If we want \lang to model transient or permanent channel failure, we can add an element $\infty$ to \dedalus{time}, such that every element of $\mathbb{N}$ is less than $\infty$.  We also need to introduce the constraint \dedalus{T != \(\infty\)} into every \lang rule.

Modeling failure introduces a whole host of new ultimate models. \wrm{expand}

Except when explicitly mentioned, in the rest of the paper we will assume bounded delays---and thus no failures.

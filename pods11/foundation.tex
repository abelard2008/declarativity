\section{\large \bf \lang}
\label{sec:foundation}

\lang is based on Datalog$\lnot$~\cite{ullmanbook}: Datalog enhanced with
arbitrary negation (we will henceforth refer to Datalog$\lnot$ as ``Datalog'').
Every predicate in \lang has a single distinguished {\em temporal attribute} unless otherwise noted,
%\footnote{Except for \dedalus{time}, \dedalus{node}, and \dedalus{successor}.}, 
which only takes on values from the {\em temporal universe} (a domain isomorphic to $\mathbb{N}$,
%\cup \infty$
represented by the unary relation \dedalus{time}).
%We will see later how $\infty$ is used to model failure.
The balance of the arguments are drawn from the Herbrand Universe of the program and EDB, and may not take on values from the temporal universe.  We admit the order constraints \dedalus{<}, \dedalus{=}, \dedalus{!=}, and \dedalus{<=}, over all elements in the Herbrand Universe, and the order constraint \dedalus{<} over the temporal universe.
%, where every element of $\mathbb{N}$ is less than $\infty$.

We assume an infinite binary relation over the temporal universe
%(except $\infty$)
called \dedalus{successor} $:= \{(a,b) \ | \ a + 1 = b\}$, which has no
distinguished temporal attribute.  We also make use of Sacc\`{a} and Zaniolo's \dedalus{choice} construct~\cite{sacca-zaniolo}---a model-theoretic characterization of nondeterminism, which we use to model the inherent nondeterminism of asynchronous distributed computation.  The atom \dedalus{choice((\dbar{X}), (\dbar{Y}))} in a rule---where \dedalus{\dbar{X}}, \dedalus{\dbar{Y}} are subsets of the variables in the rule---implies that \dedalus{\dbar{X}} functionally determines \dedalus{\dbar{Y}}.  The \dedalus{choice} atom is syntactic sugar for a cycle through negation.  Under the stable model semantics~\cite{stable-model}, each stable model of a program with \dedalus{choice} represents committing to specific \dedalus{\dbar{Y}} values for every satisfying assignment of \dedalus{\dbar{X}} values for every \dedalus{choice} atom.  We call a representation of such a commitment a {\em nondeterministic choice set}.

Our model of distribution assumes that all participants have the same information about all other participants, in the form of a unary \dedalus{node} relation, which has no temporal attribute. Note that \dedalus{node} is simply a finite domain of legal node names, and does not represent any other assumptions about the membership or connectivity of nodes in the system. We adopt the convention introduced in~\cite{Loo:2005}, where all predicates (except for \dedalus{successor}, \dedalus{time}, and \dedalus{node}) are {\em horizontally partitioned};  the location of a fact in a predicate is indicated by the value of its {\em location attribute}, a single column whose variable symbol is prefixed with \dedalus{\#}.  In each \lang rule, every such location variable must be unified with the \dedalus{node} set.  All atoms that reference a predicate must indicate the same column as its location attribute.

We also admit the \dedalus{count} aggregate over the Herbrand Universe.  Our syntax for \dedalus{count}, similar to~\cite{datalog-agg}, allows its use in the head of a rule, such as:

\begin{Dedalus}
p(\dbar{X}, count<Y>) <- ...;
\end{Dedalus}

For each binding of variables in \dedalus{\dbar{X}}, the last argument of \dedalus{p} contains the count of distinct satisfying assignments to the variable \dedalus{Y}.  It is also permissible to use the symbol \dedalus{*} as the argument to a count if \dedalus{\dbar{X}} is omitted; this counts the number of distinct satisfying assignments to all body variables.


\vspace{1em}
\noindent {\bf Locality in Space and Time:}
We would like the temporal and location attributes of \lang predicates to capture the practical semantics of communication in distributed systems.  To that end we introduce a set of restrictions on the use of these attributes, as well as the \dedalus{successor} and \dedalus{choice} constructs.

To model the notion of local computation at a given timestep, \lang requires that all atoms in each rule body unify on their temporal and location attributes: that is, they all use the same variable symbol $\Tau$ in their temporal attribute, and the same variable symbol $\SDedalus$ in their location attribute.  If the rule head's location attribute uses the same variable symbol as the body, we call the rule {\em local}.  Otherwise the rule is a {\em communication rule}.

%, and that its value must not be $\infty$.
The temporal variable in the head atom is constrained by exactly one of the following methods:
\begin{enumerate}
\item The rule is called a {\em deductive} rule if its head temporal variable is the same as its body temporal variable;
\item The rule is called an {\em inductive} rule if its head temporal variable is the \dedalus{successor} of its body temporal variable;
\item The rule is called an {\em asynchronous} rule if its head temporal variable is constrained using the \dedalus{choice} construct over all body variables (including the body temporal variable).
\end{enumerate}
The use of \dedalus{successor} and \dedalus{choice} is prohibited in \lang outside of these special usages.

Communication rules are required to be asynchronous, to model practical non-determinism in message delay and clock drift.  Local rules can be in defined in any of the three temporal classes above.

\begin{example}
\label{ex:nonsugared}
Examples of deductive, inductive, and asynchronous local rules, and an asynchronous communication rule, where \dedalus{S} and \dedalus{T} are variables ranging over the temporal universe.
\\\\
\textit{deductive:}\\
\begin{Dedalus}
p(#X, A, B, T) <- e(A, B, T), node(X);
\end{Dedalus}
\textit{inductive:}\\
\begin{Dedalus}
q(#X, A, B, S) <- e(#X, A, B, T), node(X),
                  successor(T, S);
\end{Dedalus}
\textit{asynchronous local:}\\
\begin{Dedalus}
r(#X, A, B, S) <- e(#X, A, B, T), node(X), time(S),
                  S > T, choice((X, A, B, T), (S));
\end{Dedalus}
\textit{asynchronous communication:}\\
\begin{Dedalus}
s(#Y, A, B, S) <- e(#X, A, B, T), node(X), node(Y),
                  time(S), S > T, neighbor(#X, Y),
                  choice((X, Y, A, B, T), (S));
\end{Dedalus}
\end{example}

\noindent
\textbf{Syntactic sugar for space-time in \lang:}
The restrictions on temporal and location attributes suggest a natural syntactic sugar to improve readability.  Given the unification requirements for location and temporal attributes in rule bodies, we can omit these attributes from predicates without risk of ambiguity.  
%\jmh{Gents: there is no need to require that we show location attributes in body predicates. But now this discussion has to be made consistent with all the communication rules in the text.}
The three temporal classes of rules listed above can be distinguished by annotating inductive head predicates with \dedalus{@next}, and asynchronous head predicates with \dedalus{@async}; simple deductive rules have no head annotation. 
Communication rules must include the location attribute of their head predicate; by definition this is a different variable than that of the body predicates.
 Given these conventions, the presence of appropriate \dedalus{successor}, \dedalus{choice} and \dedalus{node} predicates in the body are implicit, and can be omitted.  The result is a syntax that reads like a simple temporal variant of Datalog.
\begin{example}
\label{ex:sugared}
The rules from Example~\ref{ex:nonsugared} in sugared form, with one addition at the end.
\\\\
\textit{deductive:}\\
\begin{Dedalus}
p(A, B) <- e(A, B);
\end{Dedalus}
\textit{inductive:}\\
\begin{Dedalus}
q(A, B)@next <- e(A, B);
\end{Dedalus}
\textit{asynchronous local:}\\
\begin{Dedalus}
r(A, B)@async <- e(A, B);
\end{Dedalus}
\textit{asynchronous communication:}\\
\begin{Dedalus}
s(#Y, A, B)@async <- e(A, B), neighbor(Y);
\end{Dedalus}
\textit{asynchronous communication (with spatial entanglement):}\\
\begin{Dedalus}
t(#Y, X, A, B)@async <- e(#X, A, B), f(#X, X, Y);
\end{Dedalus}
\end{example}

The last example
% s merits some discussion.  In the fourth rule above (corresponding to the last unsugared rule of Example~\ref{ex:nonsugared}), the location variable in the head appears not to be range-restricted; in fact, it ranges over the finite domain \dedalus{node(Y)}.  The additional fifth rule 
here illustrates the case where the body location attribute is unified with other attributes (in this case, in both head and body predicates).  In order to specify this \textit{entanglement} of locations and data attributes, we include location attributes even in body predicates. 
Note that we forbid entanglement of temporal attributes in our discussion here, as this would introduce an infinite domain into the Herbrand Universe.


\vspace{1em}
\noindent {\bf EDB:}
EDB facts must be specified with a location and time.  For a given EDB $E$ and location \dedalus{n}, we refer to all EDB facts with location \dedalus{n} as $E_{\text{ \dedalus{{\scriptsize n}}}}$.  Note that $E = \bigcup_{\text{\dedalus{{\scriptsize n}}} \in \text{\dedalus{{\scriptsize node}}}} E_{\text{\dedalus{{\scriptsize n}}}}$.  We assume that the entire EDB is provided in a single batch
(we will formalize this notion in Section~\ref{sec:confluence} with the concept of
ground truths), and no EDB may be provided afterwards.  Like Datalog, we require the EDB to be finite.

\vspace{1em}
\noindent {\bf Negation and Aggregation:}
\lang restricts negation by requiring any cycle through a negated edge in the PDG to include a temporal edge.\footnote{The only exception is the cyclic negation of \dedalus{choice}, which involves recursion through negation without any temporal edges.}  Any recursion through \dedalus{count} is disallowed, in order to ensure finiteness of the Herbrand Universe.  %\jmh{You say "generic universe" a few times.  Is that an agreed-upon term?  I don't know it.}

%\subsection{Design Rationale and Implications}

%Below we explain the rationale for certain choices.
%\wrm{We need to remember to mention the dual role of time.  Atomicity and nondeterminism.  Say stuff about dense partial orders.}

%{\bf Time:}
%We want to model intermediates states of distributed systems that are not necessarily models of the programs and their
%input (e.g., to represent states with messages that are in flight, in which the premises
%of certain implications hold but their conclusions do not).
%Moreover, distributed systems are often noninflationary over time.  However, Datalog's {\em least fixpoint} operator is inflationary.  Reifying time into the langauge solves both these problems.
%{\bf Locality in Time and Space:}
%\begin{definition}
%The {\em temporal diameter} of a \lang program is the number of ``old values'' accessible for a fact \wrm{formalize}.
%\end{definition}
%Every \lang program has a temporal diameter polynomial in the data size \wrm{or is this linear??}.\footnote{We can allow a program to have an unbounded temporal diameter by allowing {\em entanglement} between the {\em temporal} kind and the {\em data} kind.  This is sufficient to model an arbitrary Turing Machine in \lang (via substitution of \dedalus{finite\_succ} with \dedalus{successor} in the proof of Lemma~\ref{lem:} in the appendix.}.
%\paa{still not sure what we need this for}

%\begin{example}
%A \lang program with a temporal diameter of 2.
%
%\begin{Dedalus}
%p_1(X,Y)@next \(\leftarrow\) p(X,Y);
%p_2(X,Y)@next \(\leftarrow\) p_1(X,Y);
%r(X,Y) \(\leftarrow\) p_2(X,Y), q(X,Y);
%\end{Dedalus}
%\end{example}

%\wrm{synchronous systems are captured by \lang with no @async}
%\wrm{explain motivation for nondeterminism.  why don't we just treat the whole world as synchronous?}

\subsection{Semantics}
\lang incorporates \dedalus{choice} to capture the non-determinism of message delays in distributed systems.  Thus we characterize the semantics of \lang  in terms of the {\em stable model semantics}~\cite{stable-model}, which captures this non-determinism.  A \lang program without asynchronous rules has a single stable model.\footnote{This corresponds to its perfect model evaluated with local stratification on temporal attributes.  It is known that the stable model semantics coincides with the perfect model semantics for locally stratified programs~\cite{stable-model}.}  Use of the \dedalus{choice} construct in asynchronous rules induces multiple stable models; each corresponds to a different nondeterministic choice of timestamps for the heads of communication rules.
%A stable model of a \lang program is a trace of one of its possible distributed executions,.

There are two potential problems with considering a stable model as the {\em output} of a \lang program.  First, every program with an asynchronous rule has infinitely many stable models.  Not all of these stable models may be meaningfully different.  Second, a stable model of a \lang program may itself be infinite.  We address both concerns in our definition of an {\em ultimate model}.

\begin{example}
\label{ex:flipflop}
A \lang program with an infinite stable model.

\begin{Dedalus}
flipflop(Y,X)@next \(\leftarrow\) flipflop(X,Y);
flipflop(1,2)@1;
\end{Dedalus}

\dedalus{flipflop(1,2)} is true at all odd times, and \dedalus{flipflop(2,1)} is true at all even times.  Thus, \dedalus{flipflop(1,2)} and \dedalus{flipflop(2,1)} are each cyclic with period 2.
\end{example}

%by regarding the output of the program as those facts that are eventually always true.  Thus, if two stable models differ only momentarily, but are ``eventually the same,'' we regard these stable models as producing the same output.

%\subsubsection{Ultimate Models}

\begin{definition}
For each stable model, the cyclic facts of period 1---so-called {\em trivially periodic} facts---comprise an {\em ultimate model} for the program.  We represent a trivially periodic fact in the ultimate model finitely by picking a representative, and discarding its timestamp.
For example, the trivially periodic fact \{\dedalus{p(a,7); p(a,8); p(a,9);} \ldots\} is represented as \dedalus{p(a)}.  We denote the ultimate model of a program $P$, EDB $E$, and nondeterministic choice set $ND$ as $\mathcal{U}(P, E, ND)$.  In programs $P$ where $\forall ND_1, ND_2, \mathcal{U}(P, E, ND_1) = \mathcal{U}(P, E, ND_2)$, we denote the unique ultimate model with EDB $E$ as $\mathcal{U}(P, E)$.  In subsequent discussion we will occasionally consider the {\em restriction} of an ultimate model to a set $R$ of predicates---the subset of the ultimate model consisting of all facts with predicates in $R$---denoted: $\mathcal{U}(P, E, ND)|_{R}$.
%Note that it may be the case that $\mathcal{U}(P, E, ND_1) \neq \mathcal{U}(P, E, ND_2)$ if $ND_1 \neq ND_2$.
\end{definition}

%The program in Example~\ref{ex:flipflop} has a single ultimate model, which is empty.
Note that ultimate models are always of finite cardinality because the only constant symbols that may appear in the ultimate model are those from the EDB, which is finite, and finitely many numbers generated by \dedalus{count}.  By the same reasoning, a \lang program may only have a finite number of different ultimate models.  As long as two stable models have the same trivial periodicities, they result in the same ultimate model, regardless of any other differences.
%\begin{example}
%A \lang program with uncountably many stable models, but a single ultimate model.
%
%\begin{Dedalus}
%p(X,Y)@next \(\leftarrow\) p(X,Y);
%r(#X,Y)@async \(\leftarrow\) p(X,Y);
%\end{Dedalus}
%\end{example}


%\wrm{re-frame the CRON conjecture as part of proving equivalence to the operational formalism}
%\wrm{In the CRON conjecture below, we should explain how purely monotonic logic does not allow us to establish a ``happens before'' relation on network traffic.  If we can't express it, then intuitively it doesn't matter whether the execution abides by the property.}
%\begin{lemma}
%Any nondeterministic choice of timestamps induces a stable model for a \lang program with no recursion through negation; If a \lang program has recursion through negation, only a causal choice of timestamps is permissible~\footnote{This lemma is similar in spirit to Hellerstein's CRON conjecture~\cite{declarative-imperative}.}.
%\end{lemma}
%
%Note that we have not restricted \dedalus{async} to choose a timestamp in the future.  Thus, one may be concerned about a {\em temporal paradox}, such as the grandfather paradox.  A program that we might be worried about would be the following:
%
%\begin{Dedalus}
%g(X)@next \(\leftarrow\) g(X), !del_g(X);
%del_g(X)@async \(\leftarrow\) p(X), g(X);
%p(1)@3;
%g(1)@1;
%\end{Dedalus}
%
%Taking the operational interpretation, we might posit the folowing trace, where \dedalus{p(1)@3, g(1)@3} cause \dedalus{del\_g(1)@2} in the past, implying that \dedalus{g(1)@3} should never have existed:
%
%\begin{Dedalus}
%g(1)@1;
%g(1)@2;
%del_g(1)@2;
%g(1)@3;
%p(1)@3;
%\end{Dedalus}
%
%\begin{proof}
%By the definition of the stable model semantics, such situations due not produce stable models~\cite{stable-model}.  Whereas, if recursion through negation is unsatisfiable, all choices of timestamps produce stable models.
%\end{proof}

%\subsubsection{Predicate Dependency Graphs}
%A \lang program may be represented as a directed graph of the dependencies
%among predicates called a \textbf{PDG}.
%Each predicate in the program corresponds to a node in the PDG.
%For every subgoal \texttt{B} appearing in the body of a rule with head \texttt{A},
%we add to the graph a directed edge from \texttt{B} to \texttt{A}.  The edges are annotated
%with a set of labels representing additional syntactic information that is relevant to 
%analysis.  In particular, if the subgoal is negated or the rule applies an aggregate function,
%its corresponding edge is labeled as nonmonotonic.  If the rule is inductive or asynchronous,
%it is labeled as such.
%In general, we do not include the \dedalus{time} or \dedalus{successor} predicates in PDGs,
%nor do we include any predicates or rules added by rewriting \dedalus{choice}.


\subsection{Operational Interpretation}
\label{sec:operational}

Our goal in defining an operational formalism is to demonstrate that our model-theoretic view of distributed systems corresponds to the real-world behaviors of such systems.  Specifically, we want to demonstrate an equivalence relation between the models of a \lang program and possible executions of a typical distributed system implementing that program.

We first present an operational model of a distributed system, then
%, and explain how it can be modeled in \lang.
develop an algorithm for computing ultimate models of a \lang program on our operational model.  We show that running the algorithm on a program $P$ only outputs ultimate models of $P$, and can output any ultimate model of $P$; we also show a correspondence between stable models and traces of the algorithm's execution.  For completeness, we also show how to express the operational formalism in our language.

%First, we will devise an operational model that is sufficient to compute the fixpoint
%We first describe an algorithm that implements such a computation, and then explain how it can be modeled by a collection of Turing Machines enhanced with queues.
%We ground our model-theoretic formalism in a natural and equivalent operational semantics.

%We will compute each partition of $\mathcal{U}(P, E, ND)$ separately.  Note that:
%$$\mathcal{U}(P, E, ND) = \bigcup_{\text{\dedalus{{\scriptsize n}}} \in \text{\dedalus{{\scriptsize node}}}} \mathcal{U}(P, E_{\text{\dedalus{{\scriptsize n}}}}, ND)$$

Our model consists of $n$ Turing Machines (called nodes), each with a single input queue, which independently sequentially execute programs, and may communicate via channels with non-deterministic delay and re-ordering.  Each machine may run for a polynomially-bounded number of steps, which include sending messages over channels---into the queues of other nodes---with non-deterministic delay and re-ordering, and placing messages in its own queue.  After running, the tape is erased, the contents of the queue are copied to the tape, the next timestamp begins, and the process repeats.  The computation halts when no messages are in flight, and each node has halted.  In this case, the output is the final contents of each machine's tape.

\begin{lemma}
\label{lem:dedalus2turing}
Any \lang program can be executed by the operational formalism.  Furthermore, the set of ultimate models of $P$ exactly corresponds to the result computed by the Turing Machines.
\end{lemma}
\begin{proof}
See appendix for details.
\end{proof}

\begin{lemma}
\label{lem:turing2dedalus}
Any system that can be represented in this operational formalism can be represented by a \lang program $P$.  Furthermore, the set of ultimate models of $P$ exactly correspond to the union of the set of possible final tape states of the Turing Machines.
\end{lemma}
\begin{proof}
See appendix for details.
\end{proof}

%$D_n@1$ is $E_n$.  
%Our model consists of $n = |\dedalus{node}|$ Turing Machines, which independently step sequentially through time and communicate via channels with non-deterministic delay.  At each timestep \dedalus{t} they run a Datalog fixpoint computation that evaluates $P$ on $D_n@\dedalus{t}$; this takes polynomial time~\cite{immerman-ptime, vardi-ptime}.  At the end of this fixpoint there are three sets of relevant facts: local, synchronous facts that have timestep \dedalus{t+1} and become part of $D_n@\dedalus{t+1}$, local asynchronous facts whose timestep is chosen non-deterministically to be greater than \dedalus{t} and become part of later timesteps, and remote asynchronous facts.  The timestamps in this third class of facts are chosen non-deterministically ``at the receiver''.
% to model delay, in a way that observes traditional causality restrictions~\cite{timeclocks}.

%Any \lang program without  async rules is a $\text{Datalog}_{1S}$ program, and the above intuition is captured by the algorithm given in~\cite{tdd}, computing an ultimate model in polynomial space in the size of the input.  In the presence of asynchronous rules, this formalize needs to be expanded to account for the asynchronous advancement of time through \dedalus{successor} at each node.  The PSPACE guarantees of~\cite{tdd} are not shown to hold for such programs, but in Appendix Foo we show that the following Lemma holds for all \lang programs under this model:

%\begin{lemma}

%\end{lemma}
%\begin{proof}

%\end{proof}

%Lemma:  (Something like the current Lemma 2, with ``distributed partial fixpoint'' defined in such a way that it matches the discussion in (2) above. It would be fine if you simply
%assert that the appendix formalizes the intuition of (2) by representing its finite traces of execution in terms of ``distributed partial fixpoints''.  You do have to define that
%term though, and connect it to the discussion.)



%\subsubsection{Distributed Partial Fixpoint}

%We will compute each partition of $\mathcal{U}(P, E, ND)$ separately.  Note that:
%$$\mathcal{U}(P, E, ND) = \bigcup_{\text{\dedalus{{\scriptsize n}}} \in \text{\dedalus{{\scriptsize node}}}} \mathcal{U}(P, E_{\text{\dedalus{{\scriptsize n}}}}, ND)$$

%Any \lang program without asynchronous rules is a $\text{Datalog}_{1S}$ program~\cite{tdd}, whose ultimate model can be computed in polynomial space in the size of the input.  We present a variation of the algorithm given in~\cite{tdd} for programs without asynchronous rules, and then enhance it to support asynchronous rules.

%\vspace{1em}
%{\bf Without asynchronous rules:}
%For a given node \dedalus{n}, let $G$ be the number of ways to instantiate all predicates' generic arguments with all constants that appear in the program and $E_{\text{\dedalus{{\scriptsize n}}}}$, and let $c$ be the maximum timestamp of any fact in $E_{\text{\dedalus{{\scriptsize n}}}}$.  The algorithm runs $P$ on $E_{\text{\dedalus{{\scriptsize n}}}}$ for $2^{G+1} + c$ timestamps and keeps track of the periodicity of each of the facts over the previous $2^G$ timestamps.  Note that $2^G$ is the maximum period of any fact~\cite{tdd}, and there are at most polynomially many periodic facts.  Evaluation of a single timestamp is akin to evaluation of a Datalog program, which may take polynomial time~\cite{immerman-ptime, vardi-ptime}.  After evaluating the Datalog program at time $i$, the IDB facts whose timestamp is $i+1$, as well as the \dedalus{node} relation, and tuple \dedalus{successor(i+1, i+2)}, are considered the EDB of the Datalog program at time $i+1$.  The output of the procedure are all facts that are trivially periodic.

%\vspace{1em}
%{\bf With asynchronous rules:}
%There are several complications with asynchronous rules.  First, for two nodes \dedalus{n}, \dedalus{m}, $E_{\text{\dedalus{{\scriptsize m}}}}$ may contain different constants than $E_{\text{\dedalus{{\scriptsize m}}}}$.  If \dedalus{n} and \dedalus{m} commit to values of $G$, and then communicate, they may introduce new constants into each others' universes, and their initial choice of $G$ may be too small.  Additionally, asynchronous facts may appear at arbitrary timestamps, including after any maximum timestamp our algorithm commits to.  Thus, the algorithm must enlarge $G$ to account for new constants, and extend computation whenever a new asynchronous fact arrives.

%We start running on the EDB for $2^{G+1}$ timestamps.  Then at some later time, we may receive a batch of new messages.  If we have already seen this same batch of messages at an earlier time, we do not need to do anything.  If we have not seen this batch before, the batch may enlarge $G$ to $G'$ by introducing new constants (from another node).  Regardless of any enlargement, we will then need to run for $2^{G'+1}$ more steps if we haven't seen the batch before.  A naive solution to keep track of the batches requires exponential space.  If we complete our designated number of steps without receiving another message, the node goes into a waiting state.  Once all nodes are in a waiting state and there are no outstanding messages being delivered, the ultimate model is computed.  This takes a finite number of computation steps, but can of course take unbounded time, unless we assume bounded message delay, or admit timeouts to enforce real-time constraints.  We will show how failure is modeled later.

%\jmh{you never defined a partial fixpoint, much less a distributed one.}
%Note that a distributed partial fixpoint computation corresponds to a finite prefix of a stable model.  

%\subsubsection{Turing Machine Model}

%\wrm{clean this up, use immerman citation for turing machine}
%\wrm{talk about operational interpretation of choice}
%Operationally, we can model a \lang execution as a collection of nodes (Turing Machines), each enhanced with an input queue, and fully connected by channels that may arbitrarily delay or re-order messages.  Each node continuously executes phases, where each phase comprises a polynomial number of steps.  Steps consist of normal Turing Machine operations, as well as a node writing to its own queue.  Information about the derived facts is written to the tape for atemporal rules, and is written to the queue for inductive rules.  Upon completion of a phase, the Turing Machine writes information about derived facts for asynchronous rules to the queues of the nodes indicated in the location attributes.  Then, the tape is erased, and atomically, the contents of the queue are moved to the tape.

%In other words, a fact, \dedalus{p(\dbar{c}, t)}, with some constant \dedalus{t} in its time suffix can be thought of as a fact that is true at a node during some local phase represented by time \dedalus{t}.  Deductive rules can be seen as {\em instantaneous} statements: their deductions hold for predicates agreeing in the time suffix and describe what is true during the current phase given what is known during the current phase. Inductive and asynchronous rules are {\em temporal}---their consequents are defined to be true during a later phase than their antecedents.

%Requiring unification on temporal and location attributes enables the locally synchronous evaluation process of atomically erasing and rewriting the tape at the boundary between phases.  It also ensures that the only communication between nodes occurs due to derived facts in asynchronous rules.  The nondeterminism of \dedalus{choice} models the asynchrony between the machines, which may be caused by different nodes running at different speeds, or by the nondeterminism of the channels. Thus, \dedalus{choice} models the fact that the data that will be dequeued for a given phase on a node is unknowable, until it is actually dequeued.

\subsection{Modeling Failure}
\label{sec:failure}

If we want \lang to model transient or permanent channel failure, we can add an element $\infty$ to \dedalus{time}, such that every element of $\mathbb{N}$ is less than $\infty$.  We also need to introduce the conjunct \dedalus{T != \(\infty\)} into every \lang rule.

Assuming failure may admit additional ultimate models.  We identify an interesting class of these ultimate models in Section~\ref{sec:ndcoord}.  Except when explicitly mentioned, in the rest of the paper we will assume that there are no failures, and all messages are eventually delivered.

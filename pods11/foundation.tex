\section{\large \bf \lang}
\label{sec:slang}

We start with Datalog$\lnot$~\cite{ullmanbook}: Datalog enhanced with arbitrary negation.  We assume the existence of an ordering \dedalus{<} over all elements in the universe.  We also admit the aggregate \dedalus{count}, which may be used in the head of a rule like: \dedalus{p(X1, ..., Xn, count<Y>) <- ...;}.  The meaning is that given a binding for \dedalus{X1, ..., Xn}, \dedalus{p} contains the count of distinct satisfying assignments to the variable \dedalus{Y}.  Any column of a predicate that hosts a \dedalus{count} aggregate is considered to be of the {\em number} sort; any variable of the {\em number} sort can only be constrained by other variables of the {\em number} sort, and the variable in the \dedalus{count} aggregate can not be of the {\em number} sort.

We will henceforth refer to Datalog$\lnot$ as ``Datalog''.  Each predicate has a distinguished {\em temporal attribute}, and only a {\em temporal variable} may appear here.  The balance of the arguments are {\em data} arguments, and may not contain temporal variables.  We posit the existence of an infinite unary relation \dedalus{time} $= \mathbb{N}$, and an infinite binary relation \dedalus{successor} $:= {(a,b) | a,b \in \mathbb{N} \land b = a + 1}$.  Later, when we consider \lang with failure, we will add the element $\infty$ to \dedalus{time}.  To model network nondeterminisim, we allow the use of Sacaa and Zaniolo's \dedalus{choice} construct to bind a rule's head temporal attribute.

\wrm{we assume no network partitions, right?}

\wrm{make this discussion of location specifiers jibe more}
\lang adopts the ``horizontal partitioning'' convention introduced by Loo et al. and used in many subsequent efforts~\cite{Loo:2005}. To represent a distributed system, we consider some number of agents, each running a copy of the same program against a disjoint subset ({\em horizontal partition}) of each predicate's contents.  We require one attribute in each predicate to be used to identify the partitioning for tuples in that predicate. We call such an attribute a {\em location specifier}, and prefix it with a \dedalus{\#} symbol in Dedalus.
Finally, we constrain \lang rules so that the location specifier variable in each body predicate be the same---i.e.\ the body contains tuples from exactly one partition of the database, logically colocated (on a single ``machine'').  If the head of the rule has the same location specifier variable as the body, we call the rule ``local,'' since its results can remain on the machine where they are computed.  If the head has a different variable in its location specifier, we call the rule a {\em communication rule}.

\lang requires that all atoms in each rule body use the same temporal variable symbol in their temporal attribute.  The temporal variable in the head atom may be constrained by exactly one of the following methods:

\begin{enumerate}
\item The rule is called an {\em atemporal rule} if its head temporal variable is the same as its body temporal variable;
\item The rule is called an {\em inductive rule} if its head temporal variable is the \dedalus{successor} of its body temporal variable;
\item The rule is called an {\em asynchronous rule} if its head temporal variable is constrained using the \dedalus{choice} construct over all body variables (including the body temporal variable).
\end{enumerate}

\begin{example}
The following are examples of well-formed deductive, inductive, and asynchronous rules, respectively.
\\
deductive:
\begin{Dedalus}
p(A, B, T) \(\leftarrow\) e(A, B, T);
\end{Dedalus}
\\
inductive:
\begin{Dedalus}
q(A, B, S) \(\leftarrow\) e(A, B, T), successor(T, S);
\end{Dedalus}
\\
asynchronous:
\begin{Dedalus}
r(A, B, S) \(\leftarrow\) e(A, B, T), time(S), choose((A, B, T), (S));
\end{Dedalus}
\end{example}

Since unification on the temporal attribute is required in every rule body, we introduce syntax sugar that omits the body temporal variable.  Since the relationship between the head and body temporal variables is tightly constrained, we mayomit the head temporal variable and instead introduce a temporal annotation: \dedalus{@next} or \dedalus{@async}.  Below, we rewrite the above rules using this syntax sugar:

\begin{example}
The following are examples of sugared well-formed deductive, inductive, and asynchronous rules, respectively.
\\
deductive:
\begin{Dedalus}
p(A, B) \(\leftarrow\) e(A, B);
\end{Dedalus}
\\
inductive:
\begin{Dedalus}
q(A, B)@next \(\leftarrow\) e(A, B, T);
\end{Dedalus}
\\
asynchronous:
\begin{Dedalus}
r(A, B)@async \(\leftarrow\) e(A, B, T);
\end{Dedalus}
\end{example}


\wrm{note that communication rules required to be asynchronous}
First, by restricting bodies to a single agent, the only communication
modeled in \lang occurs via communication rules.  Second, because
all communication rules are asynchronous, agents may only learn about
time values at another agent by receiving messages (with unbounded
delay) from that agent.  Note that this model says nothing about the
relationship between the agents' clocks; they could be
non-monotonically increasing, or they could respect a global order.

\subsection{Design Rationale}

Below we explain the rationale for certain choices.
\wrm{We need to remember to mention the dual role of time.  Atomicity and non-determinism.  Say stuff about dense partial orders.}

{\bf Time:}
Distributed systems are noninflationary over time (they have intermediate states that we want to model, such as the case where a message hasn't been received yet, or a coordination protocol).  However, Datalog's {\em least fixpoint} operator is inflationary.  Reifying time into the langauge solves this problem.

{\bf Locality in Time and Space:}
Locality in space is so that the only communication modeled in \lang occurs via communication rules.  Locality in time seems a natural way to model noninflationary semantics.  \lang allows bounded nonlocality in time.  The following example joins \dedalus{p} from two timestamps in the past with \dedalus{q} in the current timestamp:

\begin{example}
\begin{Dedalus}
p_1(X,Y)@next \(\leftarrow\) p(X,Y);
p_2(X,Y)@next \(\leftarrow\) p_1(X,Y);
r(X,Y) \(\leftarrow\) p_2(X,Y), q(X,Y);
\end{Dedalus}
\end{example}

\subsection{Semantics}
The semantics of a \lang program can be characterized by the {\em stable model semantics} for logic programming.  Intuitively, a stable model of a \lang program is a trace of its distributed execution.  A stable model of a \lang program may be infinite, such as in the following example:

\begin{example}
\begin{Dedalus}
flipflop(Y,X)@next \(\leftarrow\) flipflop(X,Y);
flipflop(1,2)@1;
\end{Dedalus}
\end{example}

\dedalus{flipflop(1,2)} is true at all odd times, and \dedalus{flipflop(2,1)} is true at all even times.

\wrm{explain persistence}
This definition of persistence suggests we define the output of the program as the facts (not including their timestamp attributes) that are eventually always true.  We call this the {\em ultimate model}.

Ultimate models are always finite in \dedalus because there are no function symbols, a finite number of predicate symbols of fixed arity, and a finite number of constant symbols.  Therefore an upper bound on the size of any ultimate model is $|P| * |C| ^ max_arity$.

A Dedalus program may only have a finite number of different ultimate models; in other words there are only finitely many meaningful orderings of messages.  This is because any ultimate model must be a subset of the set of all predicate symbols instantiated with all possible constant symbols.  Note, however, that infinitely many messages may be sent, since the trace (stable model) may be of infinite size.  The following example sends infinitely many messages:

\begin{example}
\begin{Dedalus}
p(X,Y)@next \(\leftarrow\) p(X,Y);
r(#X,Y)@async \(\leftarrow\) p(X,Y);
\end{Dedalus}
\end{example}

A Dedalus program without asynchronous rules has a single stable model.  This corresponds to its perfect model evaluated with a local stratification on time, as in \wrm{cite temporal stratification paper, Cleary I think?}.  It is known that the stable model semantics coincides with the perfect model semantics for locally stratified programs \wrm{cite}, so our usage here is consistent.

Clearly, a Dedalus program with asynchronous rules may have multiple stable models corresponding to multiple possible non-deterministic choices of timestamps \wrm{cite Greco and Zaniolo choice}.

\wrm{In the CRON conjecture below, we should explain how purely monotonic logic does not allow us to establish a ``happens before'' relation on network traffic.  If we can't express it, then intuitively it doesn't matter whether the execution abides by the property.}

\begin{lemma}
Any non-deterministic choice of timestamps induces a stable model for a \lang program with no recursion through negation; If a \lang program has recursion through negation, only a causal choice of timestamps is permissible.
\end{lemma}

Note that we have not restricted \dedalus{async} to choose a timestamp in the future.  Thus, one may be concerned about a {\em temporal paradox}, such as the grandfather paradox.  A program that we might be worried about would be the following:

\begin{Dedalus}
g(X)@next \(\leftarrow\) g(X), !del_g(X);
del_g(X)@async \(\leftarrow\) p(X), g(X);
p(1)@3;
g(1)@1;
\end{Dedalus}

Taking the operational interpretation, we might posit the folowing trace, where \dedalus{p(1)@3, g(1)@3} cause \dedalus{del\_g(1)@2} in the past, implying that \dedalus{g(1)@3} should never have existed:

\begin{Dedalus}
g(1)@1;
g(1)@2;
del_g(1)@2;
g(1)@3;
p(1)@3;
\end{Dedalus}

This lemma says that such situations do not produce stable models.  In other words, a combination of choices of timestamps does not lead to a stable model iff it causes recursion through negation, as in the above example.  Messages may arbirariliy time travel as long as they do not cause recursion through negation.

\begin{proof}

First part of the proof (recursion thru negation => no stable model) is easy, by the definition of the stable model reduction.

Second part of the proof (no recursion thru negation => stable model).  If there's no recursion thru negation, then the program is locally stratified, thus there is a stable model.  (Is this cheating, or is it really that simple?)

\end{proof}

\subsection{Operational Interpretation}
\lang programs are intended to capture the execution of an asynchronous distributed system.  An important property of distributed systems is that individual computers cannot control or observe the temporal interleaving of their computations with other computers.  One aspect of this uncertainty is captured in network delays: the arrival ``time'' of messages cannot be directly controlled by either sender or receiver.

For example, a fact, \dedalus{p($C_1 \ldots C_n$, $C_{n+1}$)}, with some constant $C_{n+1}$ in its time
suffix can be thought of as a fact that is true ``at time $C_{n+1}$''.

Deductive rules can be seen as {\em instantaneous} statements: their deductions hold for 
predicates agreeing in the time suffix and describe what is true ``for an instant'' given 
what is known at that instant.
 Inductive and asynchronous 
 rules are {\em temporal}---their consequents are defined to
be true ``at a different time'' than their antecedents.

Operationally, we can model a \lang execution as a collection of Turing Machines, each enhanced with an input queue; the machine is polynomially time bounded, during which time it can perform normal operations, and additionally write to its queue, or the queue of any other machine; after the machine has executed, the tape is erased, and atomically, the queue is erased and the tape initialized with the contents of the queue. \wrm{how do we decide whether the Turing Machine has accepted???? need coordination?}

\begin{lemma}
For any \lang program, the family of ultimate models is the same as the elements which are eventually always in the queue of the Turing Machine. \wrm{blah}
\end{lemma}
\begin{proof}
\end{proof}


\subsection{Complexity}

The language of confluent \lang programs is equal to the language of PSPACE, provided we introduce a \dedalus{bit} relation as described in Immerman.  The main part of the proof is that adding recursion or choice to FO[PFP] does not screw things up.  \wrm{This may not be important for the paper, but I feel we should at least mention something offhand so people don't think ``wow you've got this language but can it really express a wide range of distributed systems?''  Also, the fact that it corresponds so well with existing languages suggests it's a natural characterization.}

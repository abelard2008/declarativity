\section{\large \bf \lang}
\label{sec:slang}

\lang is based on Datalog$\lnot$~\cite{ullmanbook}: Datalog enhanced with arbitrary negation (we will henceforth refer to Datalog$\lnot$ as ``Datalog'').  Each predicate in \lang has single a distinguished {\em temporal attribute}, which takes on only values from the {\em temporal universe} ($\mathbb{N}$, represented by the unary relation \dedalus{time}). The balance of the arguments are generic and may not take on values from the temporal universe.  We admit the order constraints \dedalus{<}, \dedalus{=}, \dedalus{!=}, and \dedalus{<=}, over all elements in the generic universe.

We assume an infinite binary relation over the temporal universe called \dedalus{successor} $:= \{\left(a,b\right) | a + b = 1\}$.  We also admit Saca\`{a} and Zaniolo's \dedalus{choice} construct~\cite{sacaa-zaniolo}---a model-theoretic characterization of non-determinism using stable models, which we use to model message re-ordering, delay, and channel failure.  To model distribution, we adopt the convention introduced in~\cite{Loo:2005}, where certain predicates are {\em horizontally partitioned};  the location of a fact in a partitioned predicate is indicated by the value of its {\em location attribute}, a single column whose variable symbol is prefixed with a \dedalus{\#}.  All rules that define a partitioned predicate must indicate the same column as its location attribute.

We also admit the \dedalus{count} {\em aggregate} over the generic universe, which computes the number of elements in a set.  Our syntax for \dedalus{count}, similar to~\cite{datalog-agg}, allows its use in the head of a rule, such as:

\begin{Dedalus}
p(\(\bar{X}\), count<Y>) <- ...;
\end{Dedalus}

For each binding of variables in \dedalus{\(\bar{X}\)}, \dedalus{p} contains the count of distinct satisfying assignments to the variable \dedalus{Y}.  It is also permissible to use the symbol \dedalus{*} as the argument to a count if \dedalus{\(\bar{X}\)} is ommitted; this counts the number of distinct satisfying assignments to all body variables.

We presently outline restrictions on \lang.

\vspace{1em}
\noindent {\bf Temporal Attributes:}
\lang requires that all atoms in each rule body use the same variable symbol in their temporal attribute.  The temporal variable in the head atom may be constrained by exactly one of the following methods:

\begin{enumerate}
\item The rule is called a {\em deductive} rule if its head temporal variable is the same as its body temporal variable;
\item The rule is called an {\em inductive} rule if its head temporal variable is the \dedalus{successor} of its body temporal variable;
\item The rule is called an {\em asynchronous} rule if its head temporal variable is constrained using the \dedalus{choice} construct over all body variables (including the body temporal variable).
\end{enumerate}

\begin{example}
\label{ex:nonsugared}
Examples of well-formed deductive, inductive, and asynchronous rules, respectively, where \dedalus{S} and \dedalus{T} are variables ranging over the temporal universe.
\\\\
deductive:
\begin{Dedalus}
p(A, B, T) <- e(A, B, T);
\end{Dedalus}
inductive:
\begin{Dedalus}
q(A, B, S) <- e(A, B, T), successor(S, T);
\end{Dedalus}
asynchronous:
\begin{Dedalus}
r(A, B, S) <- e(A, B, T), time(S),
              choice((A, B, T), (S));
\end{Dedalus}
\end{example}

\dedalus{choice} and \dedalus{successor} are prohibited in rules, except as described above.

Since unification on the temporal attribute is required in every rule body, we introduce syntax sugar that omits the body temporal variable.  Since the relationship between the head and body temporal variables is tightly constrained, we may omit the head temporal variable and instead introduce a temporal annotation: \dedalus{@next} or \dedalus{@async}.  In Example~\ref{ex:sugared}, we rewrite the above rules using this syntax sugar.

\begin{example}
\label{ex:sugared}
The rules from Example~\ref{ex:nonsugared} in sugared form.
\\\\
deductive:
\begin{Dedalus}
p(A, B) \(\leftarrow\) e(A, B);
\end{Dedalus}
inductive:
\begin{Dedalus}
q(A, B)@next \(\leftarrow\) e(A, B);
\end{Dedalus}
asynchronous:
\begin{Dedalus}
r(A, B)@async \(\leftarrow\) e(A, B);
\end{Dedalus}
\end{example}



\vspace{1em}
\noindent {\bf EDB:}
By convention, EDB facts are supplied without a time suffix, and are true at all times.  Like Datalog, we require the EDB to be finite.

\vspace{1em}
\noindent {\bf Distribution:}
\lang requires that all atoms with partitioned predicates in each rule body use the same variable symbol in their location attribute---i.e.\ the rule is an implication over data located in exactly one partition of the database, logically collocated (on a single ``machine'').  If the rule head's location attribute uses the same variable symbol as the body, we call the rule {\em local}.  Otherwise the rule is a {\em communication rule}, and must be an asynchronous rule.                                                              

\vspace{1em}
\noindent {\bf Negation and Aggregation:}
\lang restricts negation by requiring any recursion through negation to include either a temporal or asynchronous rule~\footnote{The only exception is the rewrite of \dedalus{choice}, which involves recursion through negation without any \dedalus{@next} or \dedalus{@async}.}  Any recursion through \dedalus{count} is disallowed, in order to ensure finiteness of the generic universe.


%\wrm{move this somewhere?  or don't wory about node failure}
%{\bf Modeling failure:}  Later, when we discuss \lang with failure, we will add the element $\infty$ to \dedalus{time} to model transient or permanent channel failure, or transient node failure.  Furthermore, to model permanent node failure, we will assume all rules have the \dedalus{!fail()} predicate in their body, except for a single rule \dedalus{fail()@async <- enabled();}, and all programs have an \dedalus{enabled()} fact, where \dedalus{enabled} is a predicate symbol that does not otherwise appear in the program.  \wrm{Also, we assume durability through transient node failure?}  \wrm{Also note that failure makes confluence impossible}

%\subsection{Design Rationale and Implications}

%Below we explain the rationale for certain choices.
%\wrm{We need to remember to mention the dual role of time.  Atomicity and non-determinism.  Say stuff about dense partial orders.}

%{\bf Time:}
%We want to model intermediates states of distributed systems that are not necessarily models of the programs and their
%input (e.g., to represent states with messages that are in flight, in which the premises
%of certain implications hold but their conclusions do not).
%Moreover, distributed systems are often noninflationary over time.  However, Datalog's {\em least fixpoint} operator is inflationary.  Reifying time into the langauge solves both these problems.
%{\bf Locality in Time and Space:}
%\begin{definition}
%The {\em temporal diameter} of a \lang program is the number of ``old values'' accessible for a fact \wrm{formalize}.
%\end{definition}
%Every \lang program has a temporal diameter polynomial in the data size \wrm{or is this linear??}.\footnote{We can allow a program to have an unbounded temporal diameter by allowing {\em entanglement} between the {\em temporal} kind and the {\em data} kind.  This is sufficient to model an arbitrary Turing Machine in \lang (via substitution of \dedalus{finite\_succ} with \dedalus{successor} in the proof of Lemma~\ref{lem:} in the appendix.}.
%\paa{still not sure what we need this for}

%\begin{example}
%A \lang program with a temporal diameter of 2.
%
%\begin{Dedalus}
%p_1(X,Y)@next \(\leftarrow\) p(X,Y);
%p_2(X,Y)@next \(\leftarrow\) p_1(X,Y);
%r(X,Y) \(\leftarrow\) p_2(X,Y), q(X,Y);
%\end{Dedalus}
%\end{example}

\wrm{synchronous systems are captured by \lang with no @async}
\wrm{explain motivation for non-determinism.  why don't we just treat the whole world as synchronous?}

\subsection{Semantics}
Since \lang uses \dedalus{choice}, we characterize the semantics of \lang programs in terms of the {\em stable model semantics}~\cite{stable-model}.  The \dedalus{choice} construct induces multiple stable models that model possible message re-ordering and delay.  Intuitively, a stable model of a \lang program is a trace of one of its possible distributed executions.  However, there are two issues with considering a stable model as the {\em output} of a distributed program.  First, permuting the timesteps of two messages may not meaningfully affect the program's behavior, and second, a stable model of a \lang program may be infinite, such as in the following example:

\begin{example}
\label{ex:flipflop}
A \lang program with an infinite stable model.

\begin{Dedalus}
flipflop(Y,X)@next \(\leftarrow\) flipflop(X,Y);
flipflop(1,2)@1;
\end{Dedalus}

\dedalus{flipflop(1,2)} is true at all odd times, and \dedalus{flipflop(2,1)} is true at all even times.
\end{example}

Such periodicities are not unfamiliar to the logic programming community.  

\begin{definition}
A cycle is {\em nontrivially periodic} if its period is at least 2.  Otherwise, it is {\em trivially periodic}.
\end{definition}

The program in Example~\ref{ex:flipflop} has a nontrivially periodic cycle of period 2.  Previous work in temporal deductive databases attempted to compute finite representations for such periodicities~\cite{tdd-infinite}.  Additionally, the noninflationary generalization of the least fixpoint---the {\em partial fixpoint}---is equal to all trivially periodic cycles.  We adopt the latter approach of ignoring nontrivial periodicity when defining the output of a \lang program.

\subsubsection{Ultimate Models}

\begin{definition}
For each stable model, the trivially periodic cycles comprise an {\em ultimate model} for the program.  We represent a nontrivially periodic cycle in the ultimate model finitely by picking a representative, and discarding its timestamp.  For example, the cycle \{\dedalus{p(a,7); p(a,8); p(a,9);} \ldots\} is represented in the ultimate model as \dedalus{p(a)}.  A program may have multiple distinct ultimate models if it has multiple stable models with different nontrivial periodicities.
\end{definition}

The program in Example~\ref{ex:flipflop} has a single ultimate model, which is empty.

Note that ultimate models are always of finite cardinality because only constants part of the input---and finitely many numbers generated by \dedalus{count}---may appear in the ultimate model.  By the same reasoning, a \lang program may only have a finite number of different ultimate models, whereas it may have infinitely many stable models, as infinitely many messages may be sent.
%\begin{example}
%A \lang program with uncountably many stable models, but a single ultimate model.
%
%\begin{Dedalus}
%p(X,Y)@next \(\leftarrow\) p(X,Y);
%r(#X,Y)@async \(\leftarrow\) p(X,Y);
%\end{Dedalus}
%\end{example}

A \lang program without asynchronous rules has a single stable model.  This corresponds to its perfect model evaluated with a local stratification on temporal attributes.  It is known that the stable model semantics coincides with the perfect model semantics for locally stratified programs~\cite{stable-model}, so our usage here is consistent.

\wrm{re-frame the CRON conjecture as part of proving equivalence to the operational formalism}
\wrm{In the CRON conjecture below, we should explain how purely monotonic logic does not allow us to establish a ``happens before'' relation on network traffic.  If we can't express it, then intuitively it doesn't matter whether the execution abides by the property.}

\begin{lemma}
Any non-deterministic choice of timestamps induces a stable model for a \lang program with no recursion through negation; If a \lang program has recursion through negation, only a causal choice of timestamps is permissible~\footnote{This lemma is similar in spirit to Hellerstein's CRON conjecture~\cite{declarative-imperative}.}.
\end{lemma}

Note that we have not restricted \dedalus{async} to choose a timestamp in the future.  Thus, one may be concerned about a {\em temporal paradox}, such as the grandfather paradox.  A program that we might be worried about would be the following:

\begin{Dedalus}
g(X)@next \(\leftarrow\) g(X), !del_g(X);
del_g(X)@async \(\leftarrow\) p(X), g(X);
p(1)@3;
g(1)@1;
\end{Dedalus}

Taking the operational interpretation, we might posit the folowing trace, where \dedalus{p(1)@3, g(1)@3} cause \dedalus{del\_g(1)@2} in the past, implying that \dedalus{g(1)@3} should never have existed:

\begin{Dedalus}
g(1)@1;
g(1)@2;
del_g(1)@2;
g(1)@3;
p(1)@3;
\end{Dedalus}

\begin{proof}
By the definition of the stable model semantics, such situations due not produce stable models~\cite{stable-model}.  Whereas, if recursion through negation is unsatisfiable, all choices of timestamps produce stable models.
\end{proof}

\subsubsection{Predicate Dependency Graphs}

A \lang program may be represented as a directed graph of the dependencies
among predicates called a \textbf{PDG}.
Each predicate in the program corresponds to a node in the PDG.
For every subgoal \texttt{B} appearing in the body of a rule with head \texttt{A},
we add to the graph a directed edge from \texttt{B} to \texttt{A}.  The edges are annotated
with a set of labels representing additional syntactic information that is relevant to 
analysis.  In particular, if the subgoal is negated or the rule applies an aggregate function,
its corresponding edge is labeled as nonmonotonic.  If the rule is inductive or asynchronous,
it is labeled as such.

In general, we do not include the \dedalus{time} or \dedalus{successor} predicates in PDGs,
nor do we include any predicates or rules added by rewriting \dedalus{choice}.

\subsection{Operational Interpretation}
\wrm{talk about operational interpretation of choice}

\lang programs are intended to capture the execution of an asynchronous distributed system.  An important property of distributed systems is that individual computers cannot control or observe the temporal interleaving of their computations with other computers.  One aspect of this uncertainty is captured in network delays: the arrival ``time'' of messages cannot be directly controlled by either sender or receiver.

For example, a fact, \dedalus{p($C_1 \ldots C_n$, $C_{n+1}$)}, with some constant $C_{n+1}$ in its time
suffix can be thought of as a fact that is true ``at time $C_{n+1}$''.

Deductive rules can be seen as {\em instantaneous} statements: their deductions hold for 
predicates agreeing in the time suffix and describe what is true ``for an instant'' given 
what is known at that instant.
 Inductive and asynchronous 
 rules are {\em temporal}---their consequents are defined to
be true ``at a different time'' than their antecedents.

Operationally, we can model a \lang execution as a collection of Turing Machines, each enhanced with an input queue; the machine is polynomially time bounded, during which time it can perform normal operations, and additionally write to its queue, or the queue of any other machine; after the machine has executed, the tape is erased, and atomically, the queue is erased and the tape initialized with the contents of the queue. \wrm{how do we decide whether the Turing Machine has accepted???? need coordination?}

\begin{lemma}
For any \lang program, the family of ultimate models is the same as the elements which are eventually always in the queue of the Turing Machine. \wrm{blah}
\end{lemma}
\begin{proof}
\end{proof}

\wrm{fit in}
By restricting bodies to a single agent, the only communication
modeled in \lang is modeled by communication rules.  Second, because
all communication rules are asynchronous, agents may only learn about
time values at another agent by receiving messages (with unbounded
delay) from that agent.  Note that this model says nothing about the
relationship between the agents' clocks; they could be
non-monotonically increasing, or they could respect a global order.

%\subsection{Complexity}
%
%The language of confluent \lang programs is equal to the language of PSPACE, provided we introduce a \dedalus{bit} relation as described in Immerman.  The main part of the proof is that adding recursion or choice to FO[PFP] does not screw things up.  \wrm{This may not be important for the paper, but I feel we should at least mention something offhand so people don't think ``wow you've got this language but can it really express a wide range of distributed systems?''  Also, the fact that it corresponds so well with existing languages suggests it's a natural characterization.}

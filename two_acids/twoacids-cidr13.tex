\documentclass{sig-alternate}

\usepackage{xspace}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{color}
\usepackage{txfonts}
\usepackage{textcomp}
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{comment}
\usepackage{url}


\usepackage{listings}
\lstset{ %
basicstyle=\ttfamily\scriptsize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\ttfamily,      % the size of the fonts that are used for the line-numbers
%aboveskip=0pt,
%belowskip=0pt,
stepnumber=1,                   % the step between two line-numbers. If it is 1 each line will be numbered
%numbersep=10pt,                  % how far the line-numbers are from the code
breakindent=0pt,
firstnumber=1,
%backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=leftline,
tabsize=2,      % sets default tabsize to 2 spaces
captionpos=b,       % sets the caption-position to bottom
breaklines=false,     % sets automatic line breaking
breakatwhitespace=true,    % sets if automatic breaks should only happen at whitespace
%escapeinside={\%}{)}          % if you want to add a comment within your code
columns=fixed,
basewidth=0.52em,
% are you fucking kidding me lstlistings?  who puts the line numbers outside the margin?
xleftmargin=6mm,
xrightmargin=-6mm,
numberblanklines=false,
escapeinside={(*}{*)},
language=Ruby,
morekeywords={declare,table,scratch,channel,interface,periodic}
}


\newcommand{\jmh}[1]{{\textcolor{red}{#1 -- jmh}}}
\newcommand{\paa}[1]{{\textcolor{blue}{[[#1 -- paa]]}}}
\newcommand{\nrc}[1]{{\textcolor{green}{[[#1 -- nrc]]}}}

\begin{document}
\conferenceinfo{CIDR}{'13 Asilomar, CA USA}

\title{{\ttlit Aqua Regia}: A Solution of Two ACIDs\titlenote{\emph{Aqua regia}
    (``royal water'') is a mixture of nitric acid and hydrochloric acid~\cite{aqua-regia}.}}
\numberofauthors{3}
\author{
\alignauthor
Joseph M.~Hellerstein, Peter~Alvaro, Neil~Conway, William~R.~Marczak\\
       \affaddr{UC Berkeley}\\
       % \affaddr{387 Soda Hall \#1776}\\
       % \affaddr{Berkeley, CA 94720-1776  USA}\\
       \email{\small \{hellerstein, palvaro, nrc, wrm\}@cs.berkeley.edu}
\alignauthor
Alan Fekete\\
       \affaddr{University of Sydney}\\
       % \affaddr{Building J12}\\
       % \affaddr{NSW 2006, Sydney, Australia}\\
       \email{\small alan.fekete@sydney.edu.au}
\alignauthor
David Maier\\
       \affaddr{Portland State University}\\
       \email{\small maier@cs.pdx.edu}
}

\maketitle
\begin{abstract}
  Distributed concurrency is supported by two scientific traditions that each
  have a vernacular centered on the acronym ``ACID''.  The original use of
  the term refers, of course, to database transactions. A separate long
  tradition of reorderable convergent actions was recently dubbed
  ACID~2.0.  Both mnemonics are backed by formal theories:
  ACID transactions rely on the theory of serializable schedules, while the ACID
  2.0 idea recently acquired theoretical underpinnings via lattices and the CALM
  Theorem.

  We propose rethinking distributed concurrency from the application viewpoint
  and present a solution blended from both ACIDs.  We begin by combining the
  notion of conflict serializability with CALM analysis, to propose a general
  notion of \emph{Non-Monotone Serializability} that a compiler can synthesize
  in an application-aware fashion.  We then show how traditional ACID ideas
  inform crucial semantics-versus-performance design tradeoffs in modern ACID
  2.0 systems.  Finally, given this discussion of software synthesis, we look
  toward a future of custom-tailored \emph{Bespoke Systems}, in which
  application-aware language designs and compiler analyses enable the synthesis
  of custom low-level code.
\end{abstract}

\section{Introduction}
Concurrency is an evergreen problem in computer systems that has regained a
great deal of interest in the recent era of wide-area distributed systems and
cloud computing.  There are two scientific traditions in this area that have
been dubbed with the mnemonic ``ACID'', and for each there is an
accompanying theory that codifies the tradition formally and leads to useful
engineering techniques.

The original notion of ACID transactions---and its foundation in serializability theory---was defined in an era of limited physical concurrency and low-level sequential languages.  Software engineering at that time focused on carefully layered monolithic software, and compilers focused on low-level performance optimizations rather than higher-level static analysis for semantic guarantees.  In a spirit of generality, serializability captured the low-level von Neumann model of computation prevalent at the time: a sequential program issuing a series of Reads and Writes to a mutable store.  As a result, practical work on serializability focuses on \emph{enforcing orderings of Reads and Writes} across transactions.

Work on ACID 2.0 also has deep roots in the literature~\cite{Fischer1982}, though the acronym is recent~\cite{Helland2009}.  Most work in the area concerns itself with a modern context of distributed systems and componentized services, and attempts to address programming at a higher level of abstraction.  Specifically,  it encourages programmers to define application-specific vocabularies of \emph{actions that tolerate reordering}---that is, operations
that produce the same final outcome regardless of the order in which they occur.  
Unfortunately, most work on ACID 2.0 assumes programmers are still using relatively low-level sequential languages, so the lessons tend to be in the form of rough design maxims or special-purpose libraries.  Recent work on the CALM theorem showed how database theory regarding monotonicity can be used to formalize ACID 2.0 maxims~\cite{Alvaro2011,Ameloot2011,Conway2012,Hellerstein2010}, and our work on Bloom showed how language design and compiler technology can use that theory to automatically inform and generate custom, application-aware systems infrastructure in a general-purpose manner~\cite{Alvaro2011}.  

With the theory behind ACID 2.0 maturing and computing moving to the cloud, we believe it is time to examine theoretical and practical questions that emerge from these two ACID traditions. Can our understanding of ACID 2.0 and the CALM theorem inform the original goals of ACID transactions?  Are there lessons from ACID that can inform design and program analysis in modern distributed computing?  And given the radical change in computing platforms in the last half-century, is it not time to change our design philosophy from one that focuses on monolithic systems and von Neumann machines to one that focuses on application-aware compilation of code for the cloud?

\subsection{Brief Update: CRDTs, CALM and Bloom}
The basics of traditional ACID transactions are well known, but ACID 2.0 is an
idea in evolution.  Hence we pause briefly to survey work relevant to our discussion.  The ACID 2.0
acronym reminds us of the desired algebraic properties of a reorderable
vocabulary: Associativity, Commutativity, and Idempotence. (The D stands for
Distributed systems.)  These properties are helpful in distributed systems where
network delays and failures often lead to reordering and a need for
retry. Low-level Read and Write operations clearly do not satisfy these
properties, so work in this domain tends to suggest application-specific
vocabularies of actions where the relevant properties hold.  Formally, the ACID
2.0 properties are precisely those of the least upper bound operator in a \emph{join
  semilattice}, which led to recent work on Convergent Replicated Data Types
(CRDTs)~\cite{Shapiro2011a,Shapiro2011b}, an object-oriented model for defining
distributed object classes whose instances tolerate reordering and retry. CRDTs
are of limited utility, however, since an individual class instance rarely
encompasses a full-featured program.


The key property of semilattices is that they describe values that grow
\emph{monotonically} under the action of least upper bound.  The CALM
  Theorem proved that monotonic programs have eventually consistent,
coordination-free distributed
implementations~\cite{Alvaro2011,Ameloot2011,Hellerstein2010}.  This translated some key maxims of the ACID 2.0 literature into a robust theory.  The Bloom language~\cite{Alvaro2011} embodies this theory in a programming language and code analysis tools.  Bloom programmers write high-level programs over collections of unordered data.  By default, the order of statements and data structures in Bloom is left unspecified by the programmer, maximizing runtime latitude for parallelism and asynchrony.  The CALM-based static program analysis identifies non-monotonic constructs; these ``points of order'' need to be controlled via a coordination protocol to ensure deterministic behavior.  In recent work combining the idea of lattice data types with CALM, we extended Bloom to support complex programs constructed out of simple lattice types composed 
with monotone operators; CALM analysis can then check for monotonicity and
points of order in a manner that takes into account the ACID 2.0 properties of
the lattices and their compositions~\cite{Conway2012}.  Since this result is new, we give familiar examples of this idea below.  However, in order to highlight the non-monotonicity in our examples, we do not use Bloom syntax; instead, we use the formal logic Dedalus~\cite{dedalus} that is the basis of Bloom.


\section{Non-Monotone Serializability}
We begin by applying ACID 2.0 ideas to traditional ACID.  Specifically, we use the CALM theorem to generalize the traditional notion of conflicting actions.  We then propose program analysis techniques that can automatically identify high-level semantic concurrency opportunities, allowing wait-free behaviors that would be forbidden by traditional Read/Write transaction protocols.

Recall that serializability has a declarative definition: it encompasses all interleavings
that produce an outcome equivalent to a serial execution of transactions.  In
practice, the more conservative notion of conflict serializability has typically
been used, which \emph{constrains the ordering of actions} across transactions:
actions conflict if they access the same data item and one of them is a
Write~\cite{Eswaran1976}.  
% Since an individual transaction is classically a
% sequential program, conflicts are only explicitly ordered between actions across
% transactions.

Viewed through the lens of ACID 2.0, we might see this more positively.  Reads are commutative, associative and idempotent, hence we can \emph{tolerate reordering of Reads}.  But what about Writes? 
As noted in the literature on stateful logic languages~\cite{dedalus,statelog}, mutable state 
involves non-monotonic logic: the persistence of a value depends on it being
NOT(revoked). Logically, a Write is an atomic pair of actions: the revocation of a previous
value (``the King is dead'') and the introduction of a new value (``long live the King!''). 
% Non-monotonic persistence logic is ``triggered'' by the revocation, so 
Write triggers revocation, which is negated in the persistence logic; hence, \emph{Writes are non-monotonic}.

The CALM Theorem shows that monotonic logic is insensitive to the order of evaluation, but non-monotonic logic may produce different outcomes depending on evaluation order.  
In essence, CALM explains ``why'' Writes conflict with Reads and other Writes.
From the other direction, CALM also generalizes the notion of ``non-conflicting'' actions beyond Reads: monotonic logic can be reordered, so transaction scheduling need only consider non-monotonic actions as the basis of conflicts.

To make this discussion more concrete, we first show how traditional Read/Write
schedules can be encoded in a stateful logic such as Dedalus~\cite{dedalus} which exposes 
the inherent non-monotonicity. We
then show how schedules containing only monotonic updates can be executed
without concurrency control and yet still guarantee serializability. Finally, we
show that schedules containing a mix of monotonic and non-monotonic updates only
require concurrency control ``around'' the non-monotonic constructs. We refer to
this as \emph{Non-Monotone Serializability}---a generalization of Conflict Serializability.

Consider the classic case of credit/debit ledgers. For the sake of exposition we begin with simple ``canned'' transactions that only issue a single credit request.  Using
traditional Read and Write operations, we can model this transaction mix using Dedalus~\cite{dedalus} as
shown in Figure~\ref{fig:balance}.

\begin{figure}[ht]
\begin{scriptsize}
\lstinputlisting{code/bal.ded}
\centering
\vspace{-10pt}
\caption{Simple Read/Write credit transactions in logic.  Note the non-monotonic negation symbol in line~\ref{line:neg}.}
\label{fig:balance}
\end{scriptsize}
\vspace{-2pt}
\end{figure}

Dedalus models time passing in discrete sequential timesteps.
% The expression \texttt{p(X)@t} asserts that a fact \texttt{p(X)} is true at time
% \texttt{t}; the absence of a time suffix \texttt{@t} implies the current timestep~\paa{but I see no literal suffixes in the example...}.  
The time suffix \texttt{@next} denotes the timestamp that immediately follows the
current timestamp, while \texttt{@async} denotes a 
future timestamp chosen non-deterministically by a network or scheduler.  
Line~\ref{line:neg} says that an account balance persists from one timestep (now) to the \texttt{next} unless it is revoked. The
conflict in this program is manifest in that syntax: negation
($\neg$ in line~\ref{line:neg}) is non-monotonic.  
The negated logic \texttt{revoke\_bal} is derived from the \texttt{write} in line~\ref{line:write_trans}, 
which is itself derived from the non-deterministic scheduling of \texttt{write\_req} 
in line~\ref{line:async-beg}.  A similar analysis can show that \texttt{read} requests do not affect the contents of \texttt{revoke\_bal} but do depend upon the state of \texttt{revoke\_bal}.
Hence, a compiler for this language---or for a more programmer-friendly language
such as Bloom~\cite{Alvaro2011}---can determine that scheduler requests will need to control the order of both \texttt{read}s and \texttt{write}s with respect to \texttt{write}s, but can ignore the ordering of \texttt{read}s independent of \texttt{write}s.  That is, the compiler can statically determine the conflicts in the program from syntax.

However this program contains what we might call ``false conflicts'': in a credit-only program, balances grow monotonically, so it should in some way be OK to reorder these writes.  We can avoid these false conflicts by better exposing the monotonicity of our balance updates in application logic. We
can model the account balance as an instance of an object class (a join semilattice) with a monotonic merge method ``$\sqcup$'' (least upper bound)~\cite{Conway2012}. Using this idea, we can replace the previous non-monotonic persistence rule: rather than revoking old account balances,
we say simply that the balance object grows as more credit operations are merged into it.\footnote{The choice of a merge method is pluggable, as long as it is associative, commutative, and idempotent. Note that addition is not idempotent.  To capture typical credit ledger logic, the \texttt{proposed} values can use a custom lattice data type that pairs a nonce and an integer, and a merge function that essentially removes duplicates by nonce.  Bloom supports the registration and validation of such user-defined lattice data types~\cite{Conway2012}.}  We can capture this in a version of Dedalus that includes a merge method, as in Figure~\ref{fig:lattice_balance}.

\begin{figure}[t]
\begin{scriptsize}
\lstinputlisting[mathescape]{code/latticebal.ded}
\centering
\vspace{-10pt}
\caption{Credit transactions in monotonic logic.}
\label{fig:lattice_balance}
\end{scriptsize}
\vspace{-2pt}
\end{figure}

Because this program contains only monotonic constructs, a compiler can 
certify that it is deterministic regardless of the timestamps that are
assigned to the write operations; thus, it can safely be executed without
concurrency control. 
% Said differently, we have achieved \emph{compiler-cert conflict-free}.

We now consider how to support non-monotonicity: debit operations that include an overdraft test. 
Intuitively, debits would seem to introduce conflicts because they are 
non-monotonic relative to credits: monotone operations can only cause the
\texttt{bal} lattice to increase. However, in traditional ledgers, debits are recorded separately from credits as a monotonic list.  It is the balance calculations---and specifically, the tests for overdrafts---where non-monotonicity becomes apparent.  We add two statements to Figure~\ref{fig:lattice_balance}:
\begin{scriptsize}
	\begin{lstlisting}[mathescape,firstnumber=7]
proposed_deb(Acct, $\bigsqcup$(Deb)) :- sched_D(Acct, Deb, Xid)
bal(Acct, Val $-$ Deb)@next :- bal(Acct, Val), 
                             proposed_deb(Acct, Deb), 
                             Val $-$ Deb $>$ 0 (*\label{line:subtract}*)
	\end{lstlisting}
 	% \textsf{debit account \textbf{if} (old\_balance + SUM(credits) - SUM(debits) $>$ 0)}
\end{scriptsize}
Basic rules of arithmetic---easily registered with a compiler~\cite{Conway2012}---tell us that as credits and debits grow monotonically, the left-hand-side of the inequality on line~\ref{line:subtract} goes up {\em and down}, and hence the truth value of the predicate can oscillate non-monotonically as well.  Much like our discussion of Figure~\ref{fig:balance}, the logic for the overdraft test contains a non-monotonic clause (arithmetic subtraction), which is transitively dependent on a monotonic operation (accumulation of debits).  Hence scheduler requests will need to control the order of both credits and debits with respect to debits, but can ignore the ordering of credits independent of debits.\footnote{Note that we coupled debit with an overdraft check.  A common design pattern decouples overdraft checks---e.g., it applies them only once per day.  This introduces the potential to allow free reordering of debits and credits during a single day without affecting the non-monotonic logic.  We return to this point in the next section.}

Summing up, we make two key points.  First, ACID 2.0 helps us better understand ACID: the CALM theorem allows us to explain and generalize the notion of Read/Write conflict into a semantically richer, application-specific sphere of non-monotonic (non-lattice) operations.  Second, and more suggestively, compilers for new high-level languages like Bloom can pinpoint these non-monotonic operations in the context of whole programs, and hence automatically synthesize ``just enough'' order enforcement to achieve serializability for those programs.

\section{ACID ACID 2.0}
In the previous section, we saw how the ACID 2.0 idea of \emph{tolerating
  disorder} at application level informs serializable transaction
processing. The idea is not surprising.  With only ACID 2.0 actions, (1) all
serial schedules have the same outcome, (2) all transaction schedules have the
same outcome, and hence (3) all schedules are serializable.  Indeed, in this
scenario, transaction IDs are irrelevant---the set of actions alone defines the
outcome of the schedule.  As a result, fully ACID 2.0 systems admit
\emph{streaming} implementations: any order of operations produces the same
(desired) result, so operations can be applied on demand.

But what can traditional ACID tell us about ACID 2.0?  How can serializability
inform CALM?  The answer must come from consideration of
non-monotonicity---cases where pure ACID 2.0 designs are not sufficient, or what
the papers on CALM call \emph{points of order}~\cite{Alvaro2011}.

Non-monotonic logic induces a ``point of order'' in a program because the order of execution may affect its logical outcome.  
While predicates in non-monotonic logic are growing, our conclusions about them can change.  
In order to evaluate a non-monotonic statement (e.g., ``set $S$ does not contain $x$''), we must \emph{seal} the 
contents of its inputs---exclude the possibility of future changes.  
Sealing a predicate marks a point in time: ``before'' (mutable but unknown) and ``after'' (immutable and known).  
Once its inputs are sealed, we can evaluate the non-monotonic operation and proceed with monotonic reasoning regarding its outcome.

Said differently, non-monotonic logic should be defined by an \emph{Atomic} input set, whose contents are \emph{Durable} throughout the evaluation of subsequent application logic!  We can see the connection to transactions more readily when we face the realities of a live service supporting non-monotonic logic.  In a typical live service, some inputs grow indefinitely: they capture the stream of requests from users.  If these sets participate transitively in non-monotonic logic, how or when do we ``seal'' them?  What are the atomic boundaries?  Consider a concrete example from the previous section: in a debit/credit ledger, when should we check for overdrawn accounts?  If we check on every debit, we get a strictly ordered system with little more concurrency than a naive Read/Write analysis.  On the other hand, if we follow the standard accounting practice of checking once per day, we get a system with significant latitude for reordering. 

Outside the rosy halo of pure ACID 2.0 and streaming execution, the partitioning
of the input stream is a critical design decision of a live service.  It is
standard practice to partition a service's input into bounded subsequences:
\emph{sessions}, \emph{epochs}, and the like. Logically, this partitioning
involves little more than adding a field to each data item that captures the
identifier value for partitioning (session ID, epoch number, etc.).  It is of
course also possible to further partition on other keys in the application data:
account IDs, geographic locations, etc.  But the partitioning of unbounded
inputs is required for liveness.

Notice that in this worldview, the mapping of actions to transactions is a \emph{proactive} aspect of system design.  In traditional literature on ACID, we assume that transaction boundaries are given from on high by ``application logic'', and the transaction system must react by enforcing ordering constraints.  In ACID 2.0, we are explicitly interested in designing the application logic.  A key part of that design process---even if we eschew serializability---is to choose transaction boundaries to achieve the right balance of application batch granularity (e.g., how much time can elapse with an overdrawn account) and system efficiency (how often we want to invoke coordination logic to compute balances).  CALM analysis can aid in this task by exposing points of order precisely and enabling the application designer to think about rewriting programs to change partitioning in a way that allows points of order to be crossed less often (to improve throughput by reducing coordination), more often (to improve latency at the expense of more frequent coordination) and/or on smaller partitions of the data (to limit the parties who may have inputs to coordinate).  This is an interesting and important area for more detailed future work in guiding application design via compiler and performance analysis.

This discussion has not yet mentioned Consistency or Isolation.  The ``C'' in ACID is a common source of confusion and tedious re-definition in discussions of transactions and distributed systems, and we will ignore it here.\footnote{Consistency was apparently added to ACID simply to make it a more entertaining acronym.  It is often defined quite loosely in the transactions literature, but one concrete definition is ``enforcement of database integrity constraints''.  This has some bearing on our discussion here of partitioning keys but will have to wait for a longer paper.  The distributed systems community tends to use the term Consistency differently, with an equally frequent disregard for formalism, but without even the justification of forming an entertaining acronym.}  With regard to Isolation, the previous section on serializability and CALM comes into play directly.  Once transaction boundaries are assigned to a program, CALM analysis can expose the non-monotonic conflicts in the program and their transitive data dependencies.  The programmer can then choose how to resolve the observable non-monotonicity.  Serializability provides a certain strong Isolation guarantee, which the programmer can choose to enforce across non-monotonic boundaries.  But the literature offers many other choices, and CALM-style dataflow analysis of a logic program can help determine the transitive effects of weaker models: by chasing logical dependencies (data derivations across tables and keys within tables) it can help the programmer understand and control how non-monotonic non-determinism can ``flow'' through a program.  This discussion is admittedly brief, but we note that (a) the various definitions of isolation should be formally translatable into the framework of non-monotonic conflicts and data dependencies from the previous section, and (b) there is a rich formal literature on chasing program dependencies that can aid in the compiler analysis~\cite{alicebook}.  Future work opportunities abound.

In short, we have argued here that (1) live distributed systems that are not pure ACID 2.0 \emph{must} consider the ``A \& D'' of traditional ACID, (2) the proactive design of ``transaction'' or ``session'' boundaries is a critical aspect of distributed systems that goes beyond ACID 2.0, and (3) compiler techniques based on the CALM theorem bear the promise of helping programmers reason about and control this design with respect to traditional ``A \& D'' as well as ``I''.  Given the state of modern computing, this is the kind of reasoning that compilers \emph{should} engage in: helping developers reason through fundamental design decisions that simultaneously involve semantics and performance.  

\section{Bespoke Systems for the Cloud}
Much has changed in computing since the early ACID era of minicomputers and mainframes, C and PL/1.  Despite various analogies regarding multicore and virtualization, EC2 really looks very little like a PDP-11 or a System/370.  One thing that has changed very little, however, has been the model of programming and the ethos behind ``systems design'' as a mechanism for delivering software.  Most distributed infrastructure is still built in languages that are based on a von Neumann model of sequential programming over mutable storage.  Even in the new generation of cloud-based systems, design discussion still focuses on ``system architecture'' and ``API design''.  People still presume that infrastructure must be ``built to last'', and provide a relatively fixed API for a wide range of reuse.  

A popular retort in recent years has been to argue (on somewhat narrower ground)
that ``one size does not fit all''---at least for data management systems.  This
argument is typically used to sell $n>1$ monolithic implementations of roughly the same functionality, to be used for different workloads.  But the idea of pushing $n$ minor variants of the same idea does not scale from the perspective of customer consumption, nor does it lead to a very wide diversity of system designs or research ideas.  What is really needed is a design philosophy where \emph{public APIs} change relatively rarely, while code that is internal to an opaque service infrastructure is tuned to the needs of the applications that run on top.

To pour a powerful solution of ACIDs on a by-now threadbare tailoring
analogy,\footnote{Having mixed ACIDs already, we feel no shame in mixing
  metaphors.} our discussion in the previous sections suggests a new era of
\emph{Bespoke Systems}, tailored to fit application needs.  As we illustrated
above, technology is emerging to enable compiler-driven synthesis---or at least
guidance---of application-specific designs for deep system internals such as concurrency and coordination.  Our work is specific to key issues in the performance of cloud computing, but in the programming language community, sketching and other software synthesis techniques are also gaining steam for other software design concerns~\cite{Kuncak2012}.  Generally, this movement suggests a radical opening of the design space via intelligent search: rather than working on the $n^\textrm{th}$ ``System Architecture'' design that chooses a particular set of tradeoffs based on dutiful manual experimentation, perhaps we can design compilers to automatically explore---and importantly, to judiciously prune---the design space \emph{en masse}, choosing equivalence classes of very different designs for a given application, and automating experimentation.  By embracing language and compiler design and eschewing system architecture, the technical community can ``uplevel'' itself and use computational tools in design.

Moreover, this movement should come naturally to the database research community, which has long prided itself on declarative specification languages and top-down designs from semantics.  It is time to turn that ethos inward: develop ``optimizers'' for declarative code that allow us to design data-rich, application-specific, scalable systems from specification.

%ACKNOWLEDGMENTS are optional
% \section{Acknowledgments}

\bibliographystyle{abbrv}
\bibliography{cidr}
\end{document}

\section{Introduction} 
\label{sec:intro} 
Although distributed programming has become an essential and commonplace task,
it remains very challenging for most developers to write correct distributed
programs. The inherent difficulties of distributed computing---asynchrony,
concurrency, and partial failure---are exacerbated by the scale at which modern
distributed systems operate.

% remind reviewers that it's a database problem. can remove if accepted! 
% Much of the discussion about distributed programming today revolves around data
% management systems, and the tradeoffs between transactions and loose
% consistency. Programmers using distributed transactions are relieved of
% consistency concerns but often face significant performance and operational
% challenges~\cite{Birman2009}. By contrast, programmers who use loosely
% consistent systems can expect more predictable and low-latency performance, but
% must reason explicitly about program correctness over inconsistent distributed
% state.
The coordination protocols that provide strongly consistent storage are widely believed to raise unacceptable challenges in performance and operational overhead for modern systems~\cite{Birman2009}. As a result, 
there has been increased interest in techniques for achieving correct program behavior without requiring coordination. 
Two different frameworks for these techniques have received significant attention in recent research:
\emph{Convergent Modules} and \emph{Monotonic Logic}.  
%Both of these frameworks guarantee confluence: eventually deterministic outcomes in the face of message reordering and delay.

\vspace{0.5em}\noindent
\textbf{Convergent Modules}: In this approach, a programmer writes encapsulated
modules whose public methods guarantee certain properties regarding
message reordering and/or retry. For example, Statebox is an open-source library
that merges conflicting updates to data items in a key-value store; the user of
the library need only register commutative, idempotent merge
functions~\cite{statebox}. This approach has roots in research in
databases~\cite{Farrag1989,Garcia-Molina1983,Helland2009} and
groupware~\cite{Ellis1989,Sun1998}.  Shapiro et al.\ recently proposed a model
for these approaches called \emph{Conflict-Free Replicated Data Types} (CRDTs),
which formalizes these ideas in the algebraic framework of {\em join semi-lattices}~\cite{Shapiro2011b}.

The main problem with the CRDT approach is that it provides guarantees at per-module granularity: arguments about correctness apply only to an individual replicated data value, not to application logic in
general. For example, consider a distributed algorithmic trading service that
uses a CRDT to represent a mutable set \texttt{Portfolio} of stock symbols. Suppose one server
$S$ reads a local version of the set containing the symbol \texttt{PEAR} and
constructs an expected portfolio value $v = f(\mbox{\texttt{Portfolio}})$
derived from that version. Concurrently, \texttt{PEAR} is removed from the local
version of \texttt{Portfolio} at another server $T$. The CRDT ensures that
$S$ and $T$ will eventually agree that \texttt{PEAR} is absent from the set. But
the application state at $S$ and $T$ may remain inconsistent unless the value
$v$ at $S$ is updated to reflect the removal of \texttt{PEAR}. Although the CRDT
maintains its local invariants, the programmer still bears the burden of ensuring
the consistency semantics of the whole program.

\vspace{0.5em} \noindent
\textbf{Monotonic Logic}: In recent work, we observed that the database theory
literature on non-monotonic logic provides a promising starting point for
reasoning about distributed consistency. Intuitively, a \emph{monotonic} program
computes more information over time---it never ``retracts'' an earlier
conclusion in the face of new information. We proposed the CALM
theorem, which established that all monotonic programs
are eventually consistent~\cite{Ameloot2011,Hellerstein2010,dedalus-pods12-tr}. Monotonicity of
a Datalog-style program is straightforward to determine conservatively from
syntax, so the CALM theorem provides the basis for a simple analysis technique
for verifying the consistency of distributed programs. We
realized CALM analysis as part of Bloom, a Datalog-based DSL for distributed
programming~\cite{Alvaro2011,bloom}.

The original formulation of Bloom and CALM only validated consistency for programs that compute sets of facts that grow over time (``set monotonicity''); that is, ``growth'' is defined according to set containment. As a practical matter, this is overly conservative.  Consider extending our algorithmic trading system example by maintaining counter variables recording each stock's daily trade volume. The trading policy chooses to sell a portfolio if the MAX counter in the portfolio exceeds a certain threshold.  This is monotonic in the broad sense: the counter values grow monotonically, and the threshold test (\texttt{max(counters) $> k$}) also grows monotonically from False to True.  But both of these constructs (upward-moving mutable variables and aggregates) are considered to be non-monotonic by the original CALM analysis.  As a result, the initial Bloom prototype would advise the programmer to guard those constructs with strong consistency methods like Paxos~\cite{Lamport1998} or Two-Phase Commit~\cite{Gray1978}. 

% \jmh{A problem with the above trading examples are that we don't return to them ever again. At minimum, we should flag that we return to the constructs they use: replicated mutable set, counters and threshold tests.}

\subsection{\lang: Logic and Lattices}
% The strengths and weaknesses of these two approaches appear complementary. CRDTs provide synchronization-free consistent objects, but cannot guarantee whole-program consistency. Bloom's CALM analysis guarantees whole-program consistency but is unable to verify a number of natural coordination-free mechanisms.
Instead of only allowing growth according to the set containment
partial order, we would like to allow any user-defined partial order to be used.  
To this end, we introduce a new language extension \lang, which provides a programming construct for defining join semi-lattices like CRDTs.
We give a
formal definition of this construct below, but the intuition is that the programmer provides a commutative, idempotent merge function (``least upper bound'')
that takes two input values and produces an output value that is not smaller
than either of the input values, according to the user's partial order. This
generalizes Bloom (and traditional Datalog), which assumes a fixed merge
function (set union) and partial order (set containment).
% Relate user-defined merge functions to merge functions in other contexts?
% (e.g., key-value store, COPS, Piccolo)

\lang provides three main improvements in the state of the art of both Bloom and CRDTs:  
\begin{enumerate}
\item By combining lattices and logic, the CALM analysis in \lang is able to be
  significantly more liberal in identifying monotonic code that is confluent
  without the need for coordination.  This enables the coordination-free use of
  common monotonic constructs, including timestamps and sequence numbers.
\item {\lang}'s lattice framework provides monotonicity-preserving mappings
  between lattices via \emph{morphisms} and \emph{monotonic functions}.  By using such mappings, the per-component monotonicity guarantees offered by CRDTs can be extended across multiple lattice-based components.  This is key to the CALM analysis of monotonic \lang programs described above.  It is also useful for establishing the monotonicity of sub-programs even when the whole program is not designed to be monotonic.
\item For efficient execution, we extend the standard Datalog semi-naive
  evaluation scheme~\cite{Balbin1987} to support both lattices and traditional
  database relations. We also describe how an existing Datalog engine can be
  extended to support lattices with relatively minor changes.
\end{enumerate}

% \subsection{Beyond confluence}
% Both Convergent Objects and Monotonic Logic provide eventual consistency in the face of message delay and reordering.  In fact they provide an even stronger guarantee than consistency: {\em confluent} (i.e., deterministic) outcomes.  However, many distributed applications are not intended to be confluent.  Instead, they use coordination to achieve {\em controlled non-determinism}: the ability for timing conditions to affect the choice of one among many acceptable outcomes. This includes applications that require serializability or causal consistency, both of which employ coordination to stay within a ``family'' of acceptable timing schedules.  
% 
% The coordination protocols used for controlled non-determinism are expressible in Bloom, but typical implementations are not syntactically monotonic~\cite{Alvaro2011}.  In many cases, however, these protocols work in a monotonic fashion, providing distributed barriers in computation by using constructs like arrays of mutable counters.  These protocols can be quite directly mapped to \lang using lattices.  This further improves the fit between Bloom's logic programming roots and standard practice in distributed programming.  On a more concrete basis, \lang can provide strong monotonicity guarantees for these coordination constructs.  This can ensure, for example, that a barrier-inducing protocol does indeed ``coordinate'' correctly: it monotonically transitions from ``Wait'' to ``Go''.

\subsection{Outline}
% Explain how lattices generalize monotonic datalog
The remainder of the paper proceeds as follows.  Section~\ref{sec:background}
provides background on Bloom and CALM.  In Section~\ref{sec:lang} we introduce
\lang, including cross-lattice morphisms and monotonic functions. We detail \lang's built-in lattice types and show how developers can define new lattices.  We also describe how
the CALM analysis extends to \lang (Section~\ref{sec:calmL}).  In
Section~\ref{sec:impl}, we describe how we modified the Bloom runtime to support
\lang, including our extension to semi-naive evaluation that supports both
lattices and relations.  In Sections~\ref{sec:carts} and~\ref{sec:causal}, we
consider two case studies from the literature.  First we revisit the simple
e-commerce scenario presented in Alvaro et al.\ in which clients interact with a
replicated shopping cart service~\cite{Alvaro2011}. We show how \lang can be
used to make the ``checkout'' operation monotonic and confluent, despite the
fact that it requires aggregating over a distributed data set.  Second, we use
\lang to implement vector clocks and causal delivery, two standard building
blocks for non-confluent distributed programming. We show how both techniques
can be realized as concise, monotonic \lang programs.

  % We generalize the CALM analysis to programs that contain both lattices and
  % set-oriented collections, and show how lattices can be used to prove the
  % confluence of several common distributed design patterns that were regarded as
  % non-monotonic in Bloom. % XXX: revisit this

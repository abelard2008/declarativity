\section{Introduction} 
\label{sec:intro} 
Although distributed programming has become an essential and commonplace task, it remains very challenging for most developers to write correct distributed programs. The inherent difficulties of distributed computing---concurrency, asynchrony, and partial failure---have been exacerbated by the scale at which modern distributed systems must operate.

% remind reviewers that it's a database problem. can remove if accepted! 
Much of the discussion about distributed programming today revolves around data management systems, and the tradeoffs between transactions and loose consistency. Programmers using distributed transactions are relieved of consistency concerns but often face significant performance and operational challenges~\cite{Birman2009}. By contrast, programmers who use loosely-consistent systems can expect more predictable and low-latency performance, but must reason explicitly about program correctness over inconsistent distributed state.

In recent years there has been increased interest in techniques to help programmers achieve correct program behavior without requiring strongly consistent storage. This idea has been explored in two different frameworks, \emph{Convergent Objects} and \emph{Monotonic Logic}.

\vspace{0.5em}
\noindent \textbf{Convergent Objects}: In this approach, a programmer writes encapsulated object classes whose public methods guarantee certain properties regarding message reordering and/or retry. For example, Statebox is an open-source library that merges conflicting updates to data items in a key-value store; the user of the library need only register commutative, idempotent merge functions~\cite{statebox}. This approach has roots in research in databases~\cite{Garcia-Molina1983,Farrag1989,Helland2009} and groupware~\cite{Ellis1989,Sun1998}.  Shapiro et al. recently proposed a model for these approaches called {\em Conflict-Free Replicated Data Types (CRDTs)}, which formalizes these ideas in an algebraic framework~\cite{Shapiro2011b}. 

\jmh{Note that this discussion seems to apply better to CvRDTs (which are the lattices) than to CmRDTs.  We'd best clarify, if only in related work.}
The main problem with the CRDT approach is that its guarantees of correctness are typically limited only to an individual class, not to application logic in general. For example, consider a distributed algorithmic trading service that uses a CRDT to represent a mutable set \texttt{Portfolio}. Suppose one server $M$ reads a local version of the set containing an element \texttt{BNNA} and constructs an expected portfolio value $v = f(\mbox{\texttt{Portfolio}})$ derived from that version. Concurrently, \texttt{BNNA} is removed from the local version of \texttt{Portfolio} at another server $N$. The CRDT can ensure that $M$ and $N$ will eventually agree that \texttt{BNNA} is absent from the set, but the application state at $M$ and $N$ may remain inconsistent unless the value $v$ at $M$ is updated to reflect the removal of \texttt{BNNA}. Although the CRDT maintains its own invariants, the programmer still bears the burden of ensuring the consistency semantics of the entire program.

\vspace{0.5em}
\noindent \textbf{Monotonic Logic}: In recent work, we observed that the database theory literature on non-monotonic logic provides a promising starting point for reasoning about distributed consistency. Intuitively, a monotonic program computes more information over time---it never ``retracts'' an earlier conclusion in the face of new information. We proposed the CALM theorem~\cite{Hellerstein2010}, which established that all monotonic programs are eventually consistent~\cite{Ameloot2011}. Monotonicity of a Datalog-style program is straightforward to determine conservatively from syntax, so the CALM theorem provides the basis for a simple analysis technique for verifying the consistency of distributed programs~\cite{Alvaro2011}. We realized the CALM analysis as part of Bloom, a Datalog-based DSL for distributed programming~\cite{bloom}.

The original formulation of Bloom and CALM only validated consistency for programs that compute sets of facts that grow over time (``set monotonicity''); that is, ``growth'' is defined according to set containment. As a practical matter, this is overly conservative: several common distributed programming idioms that are monotonic do not satisfy syntactic monotonicity tests for Datalog. In particular, threshold tests over monotonic aggregate values (e.g., ``$\textrm{max}(S) > k$'') and upward-moving mutable counters are both evaluated to be non-monotonic by the original CALM analysis for Bloom.  As a result, the initial Bloom prototype advises the programmer to guard those constructs with strong consistency methods like Paxos~\cite{Lamport1998} or Two-Phase Commit. 

\subsection{A Hybrid Approach}
% The strengths and weaknesses of these two approaches appear complementary. CRDTs provide synchronization-free consistent objects, but cannot guarantee whole-program consistency. Bloom's CALM analysis guarantees whole-program consistency but is unable to verify a number of natural coordination-free mechanisms.
In this paper, we extend our previous work to accommodate the ideas underlying CRDTs. Instead of only allowing growth according to the set containment
partial order, we allow any user-defined partial order to be used.  
We do this by providing \emph{join semi-lattices} as a programming construct.
We give a
formal definition of this construct below, but the intuition is that the programmer provides a commutative, idempotent merge function (``least upper bound'')
that takes two input values and produces an output value that is not smaller
than either of the input values (according to the user's partial order). This
generalizes Bloom (and traditional Datalog), which assumes a fixed merge
function (set union) and partial order (set containment).
% Relate user-defined merge functions to merge functions in other contexts?
% (e.g., key-value store, COPS, Piccolo)

% Explain how lattices generalize monotonic datalog
It is attractive to incorporate join semi-lattices into logic programming,  but doing so raises challenges in language design, consistency analysis and efficient execution.  In this paper, we make the following contributions:
\begin{enumerate}
% \item
%   We present \baselang, a variant of Datalog that is defined over lattices. We
%   define a model-theoretic semantics for \baselang, and show that \baselang
%   generalizes Datalog.

\item
  We introduce \lang, an extension of Bloom that supports lattices. We describe
  how to express computation over lattices, detail the builtin lattice types
  provided by \lang, and illustrate how developers can define new lattice
  types.
  
\item 
  We provide interfaces for consistency-preserving mappings across lattices via \emph{morphisms} and \emph{monotonic functions}.  This is critical for \lang, and forms a useful extension to the CRDT framework as well.

\item 
  We generalize the CALM analysis to programs that contain both lattices and
  set-oriented collections, and show how lattices can be used to prove the
  confluence of several common distributed design patterns that were regarded as
  non-monotonic in Bloom. % XXX: revisit this

\item
  For efficient execution, we show how to extend the standard Datalog semi-naive evaluation
  scheme~\cite{Balbin1987} to support both lattices and traditional database
  relations. We also describe how an existing Datalog engine can be extended to
  support lattices with relatively minor changes.

\item
  Finally, we validate the effectiveness of lattices with two case studies. First we
  revisit the simple e-commerce scenario presented in Alvaro et al., in which
  clients interact with a replicated shopping cart service~\cite{Alvaro2011}. We
  use lattices to allow a more flexible and compact representation of shopping
  cart state. We also show how lattices can make the ``checkout'' aggregation
  operation monotonic.

  Second, we use lattices to implement a classical distributed protocol for
  point-to-point causal delivery~\cite{Schiper1989}. We show that causal
  delivery is monotonic and detail how domain-specific correctness criteria can
  be proven more easily with the aid of the lattice properties.
\end{enumerate}

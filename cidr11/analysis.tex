\section{CALM Analysis}
Bloom programs define unordered collections and statements that describe
transformations over these collections.  A Bloom program may be viewed as a
dataflow graph with external inputs and outputs as sources and sinks,
respectively, collections as internal nodes, and rules as edges.  Given this
view, we may adapt powerful static analyses from the logic programming
literature which are expressed as properties of such dataflow graphs.

In this section, we implement a simple key-value store in Bud and analyze the
resulting dataflow graph.  We begin with an interface for an abstract store, and
extend it first into a single-site implementation and finally into a replicated implementation.
Along the way, we use a dataflow visualization to reason about the completeness
and correctness of the evolving program.

% TODO: tee-up points of order
% TODO: tee-up divergence into PDGs

\subsection{Predicate Dependency Graphs}
\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{fig/mittalk_legend.pdf}
\vspace{-10pt}
\caption{Visual analysis legend. \jmh{Check on the $+/-$ label in the figure.  Is that right, do we ever use $-$?}}
\label{fig:analysis-legend}
\vspace{-2pt}
\end{figure}

The Bud interpreter can automatically generate a graph that represents the
dependencies between collections in a program. Each node in the graph is either
a collection or a cluster of collections; tables are shown as rectangles,
ephemeral collections (scratch, periodic and channel) are depicted as ovals, and
clusters (described below) as octagons.

A directed edge from node $A$ to node $B$ indicates that $B$ appears in the lhs
of a Bloom rule with $A$ referenced directly, or through a join expression, in
the rhs.  An edge is annotated based on the operator symbol in the rule. If the
rule uses the \texttt{$<$+} or \texttt{$<$-} operators, the edge is marked with
$+$. This indicates that facts traversing the edge ``spend'' a timestep to move
from the rhs to the lhs. Similarly, if the rule uses the \texttt{$<\sim$}
operator, the edge is a dashed line---this indicates that facts from the rhs
appear at the lhs at a non-deterministic future time. If the rule involves a
non-monotonic operation (aggregation, anti-join, or the \texttt{$<$-} operator),
then the edge is marked with a small circle.  To make the visualizations more
readable, any strongly connected component marked with both a circle and a $+$
edge is collapsed into an octagonal ``temporal cluster,'' which can be viewed
abstractly as a single, non-monotonic node in the dataflow. \emph{Points of
  order} are indicated in the graph by an edge with a white circle.  Any
non-monotonic edge in the graph is a point of order, as are all edges incident to
a temporal cluster, including any self-edges.  Figure~\ref{fig:analysis-legend}
provides a legend for the analysis visualizations.

\subsection{KVS Interface}

\begin{figure}[t]
\begin{scriptsize}
\begin{lstlisting}
module KVSProtocol
  def state
    interface input, :kvput, 
      ['client', 'key', 'reqid'], ['value']
    interface input, :kvget, ['reqid'], ['key']
    interface output, :kvget_response, 
      ['reqid'], ['key', 'value']
  end
end
\end{lstlisting}
\centering
\vspace{-10pt}
\caption{Abstract key-value store protocol.}
\label{fig:kvs-proto}
\end{scriptsize}
\vspace{-2pt}
\end{figure}

Figure~\ref{fig:kvs-proto} specifies a protocol for interacting with an abstract
key-value store. The protocol comprises two input events (representing attempts
to insert and fetch items from the store) and a single output event (which
represents the outcome of a fetch operation). To use an implementation of this
protocol, a Bloom program can store key-value pairs by inserting facts into
\texttt{kvput}. To retrieve the value associated with a key, the client program
can insert a fact into \texttt{kvget} and then wait for a response tuple to
eventually appear in \texttt{kvget\_response}. In both cases, the client program
must supply a unique request identifier (\texttt{reqid}) to differentiate tuples
in the event of multiple concurrent requests.

A module which uses a key-value store but is indifferent to the specifics of the
implementation may simply mix in this protocol specification and postpone
committing to a particular implementation until runtime. As we will see shortly,
an implementation of the \texttt{KVSProtocol} is a collection of Bud rules that
read tuples from the protocol's input interfaces and send results to the output
interface.

\subsection{Single-Node Key-Value Store}
\label{sec:simple-kvs}
\begin{figure}[t]
\begin{scriptsize}
\begin{lstlisting}
module BasicKVS
  include KVSProtocol

  def state
    table :kvstate, ['key'], ['value'] (*\label{line:kvs-state}*)
  end

  declare
  def mutate
    kvstate <+ kvput.map{|p| [p.key, p.value]} (*\label{line:kvs-put}*)
    jst = join [kvstate, kvput], [kvstate.key, kvput.key] (*\label{line:kvs-join}*)
    kvstate <- jst.map{|b, p| b} (*\label{line:kvs-clean}*)
  end

  declare
  def get
    getj = join [kvget, kvstate], [kvget.key, kvstate.key] (*\label{line:kvs-getjoin}*)
    kvget_response <= getj.map do |g, t|
      [g.reqid, t.key, t.value]
    end
  end
end
\end{lstlisting}
\centering
%%\includegraphics[width=0.55\linewidth]{fig/basickvs.pdf}
\vspace{-10pt}
\caption{Single-node key-value store implementation.}
\label{fig:kvs-impl}
\end{scriptsize}
\vspace{-2pt}
\end{figure}

Figure~\ref{fig:kvs-impl} contains a simple single-node implementation of the
abstract key-value store protocol. Key-value pairs are stored in a persistent
table called \texttt{kvstate} (line~\ref{line:kvs-state}). When a \texttt{kvput}
tuple appears, its key-value pair is stored in \texttt{kvstate} at the immediately
next timestep (line~\ref{line:kvs-put}).  If the given key already exists in
\texttt{kvstate}, we want to replace the key's old value. This is done by
joining \texttt{kvput} against the current version of \texttt{kvstate}
(line~\ref{line:kvs-join}). If a matching tuple is found, the old key-value pair
is removed from \texttt{kvstate} at the beginning of the next timestep
(line~\ref{line:kvs-clean}). Note that we also insert the new key-value pair
into \texttt{kvstate} in the next timestep (line~\ref{line:kvs-put});
hence, we implement an overwriting update as an atomic deletion and insertion.

\subsection{Replicated Key-Value Store}
\label{sec:rep-kvs}

\begin{figure}[t]
\begin{scriptsize}
\begin{lstlisting}
module ReplicatedKVS
  include BasicKVS
  include MulticastProtocol

  def state
    interface input, :kvput, (*\label{line:rep-put-beg}*)
      ['client', 'key', 'reqid'], ['value']  (*\label{line:rep-put-end}*)
  end

  declare
  def local_indir
    send_mcast <= kvput.map do |k| (*\label{line:send-mcast-beg}*)
      unless members.include? [k.client]  (*\label{line:not-rep}*)
        [k.reqid, [@addy, k.key, k.reqid, k.value]]   (*\label{line:marshall}*)            
      end
    end (*\label{line:send-mcast-end}*)
    
    kvput <= mcast_done.map{|m| m.payload}  (*\label{line:mcast-done}*)

    kvput <= pipe_chan.map do |d| (*\label{line:mcast-peer-beg}*)
      if d.payload.fetch(1) != @addy
        d.payload
      end
    end (*\label{line:mcast-peer-end}*)
  end
end
\end{lstlisting}
\vspace{-10pt}
\caption{Replicated key-value store implementation.}
\label{fig:kvs-repl}
\end{scriptsize}
\vspace{-2pt}
\end{figure}

Next, we extend the basic key-value store implementation to support replication
(Figure~\ref{fig:kvs-repl}). To communicate between replicas, we use a simple
multicast library implemented in Bloom; the complete source code for this
library can be found in Appendix~\ref{app:network-code}. To multicast messages
using this library, a Bloom program inserts a fact into \texttt{send\_mcast}; a
corresponding fact appears in \texttt{mcast\_done} when the multicast operation
has completed.\footnote{XXX: error handling.} The multicast library also
provides the membership of the multicast group in a table called
\texttt{members}.

Our replicated key-value store is implemented by sub-classing the single-node
key-value store described in the previous section. When a new key is inserted by
a client, we multicast the insertion to the other replicas
(lines~\ref{line:send-mcast-beg}--\ref{line:send-mcast-end}). To avoid repeated
multicasts of the same inserted key, we avoid multicasting updates we receive
from another replica (line~\ref{line:not-rep}). We apply an update to our local
\texttt{kvstate} table in two cases: (1) if a multicast succeeds at the node
that originated it (line~\ref{line:mcast-done}) (2) whenever a multicast is
received at a peer replica
(lines~\ref{line:mcast-peer-beg}--\ref{line:mcast-peer-end}).

Note that the implementation of ReplicatedKVS wants to ``intercept''
\texttt{kvput} events from clients, and only apply them to the underlying
single-node key-value store when certain conditions are met. To achieve this, we
``override'' the declaration of the \texttt{kvput} input interface
(lines~\ref{line:rep-put-beg}--\ref{line:rep-put-end}). In ReplicatedKVS,
references to \texttt{kvput} appearing in the LHS of rules are resolved to the
\texttt{kvput} provided by BasicKVS, while references in the RHS of rules
resolve to the local \texttt{kvput}.  Note that this is unambiguous, because a
module cannot insert into its own input or read from its own output
interfaces. Nevertheless, the current syntax for achieving this is somewhat
cryptic; it might be improved by the addition of a namespace-like concept.

\subsection{Analyses}
Figure~\ref{fig:pdg-kvs-proto-analysis} presents a visual representation of the KVS protocol.  Data
flows from the source node (an external caller) to one or both of \texttt{kvput} and 
\texttt{kvget}, through some unknown dataflow, to \texttt{kvget\_response}.
The existence of the red diamond labeled ``??'' indicates that the dataflow is underspecified:
is must be ``completed'' by supplying dataflow that, at minimum, connects the input 
interfaces to the output interface.

Figure~\ref{fig:pdg-kvs-analysis} shows the visual analysis of the basic KVS
implementation, which supplies a concrete dataflow for the unspecified component
in the previous graph.  \texttt{kvstate} and \texttt{jst} are collapsed into a
red octagon because they are part of a strongly connected component in the graph
with both negative and temporal edges.  Any data flowing from \texttt{kvput} to
the sink must cross at least one non-monotonic point of order (at ingress to the
octagon) and possible an arbitrary number of them (via the octagon's self-edge),
and any path from \texttt{kvget} to the sink must join state potentially
affected by non-monotonicity (because \texttt{kvstate} is used to derive
\texttt{kvget\_response}).

Reviewing the code in Figure~\ref{fig:kvs-impl}, we see that this is
unavoidable.  The contents of \texttt{kvstate} at a given time are defined (in
part; line~\ref{line:kvs-clean}) in terms of its contents at the immediate
previous state and the current input.  Hence the state of \texttt{kvstate} at
any point in time may depend on the order of arrival of \texttt{kvput} tuples.
% We challenge the reader to implement the KeyValueProto interface in a way that
% has no such point of order.



\begin{figure}[t]
\centering
\includegraphics[width=0.4\linewidth]{fig/kvs_proto_pdg.pdf}
\vspace{-10pt}
\caption{Visualization of the abstract key-value store protocol.}
\label{fig:pdg-kvs-proto-analysis}
\vspace{-2pt}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{fig/basickvs.pdf}
\vspace{-10pt}
\caption{Visualization of the single-node key-value store.}
\label{fig:pdg-kvs-analysis}
\vspace{-2pt}
\end{figure}

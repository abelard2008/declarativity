\section{Introduction}
Until fairly recently, distributed programming was a rarefied topic handled by systems experts building high-end commercial software. But recent technology trends have brought distributed programming into the mainstream of software engineering.  The inherent challenges of distribution---concurrency and asynchrony, performance variability, and component failure (among others)---often translate into tricky data management challenges regarding task coordination and data consistency.  Software engineers dealing with these issues today have a much wider variety of backgrounds and sophistication than in previous decades, but the challenges involved remain largely unchanged.  Hence there is increased need to find ways to simplify the data management challenges inherent in distributed programming.

There are two main bodies of work to guide programmers through these issues.  The first is the ``ACID'' foundation provided by the theory and practice of concurrency control and distributed coordination, exemplified by serializable transactions and consensus protocols like Two-Phase Commit and Paxos.  These concepts are built on careful understanding and control over the ordering of {\em physical} I/O: reads, writes, and messages.  On the positive front, mechanisms built from these concepts provide strong guarantees on data consistency, and are readily available in packaged solutions that shield the programmer from most of the complexities of coordination and consistency.  But there is a widespread belief---even among many seasoned practitioners~\cite{ladis}---that the costs of these mechanisms are too high in many important scenarios.  The interaction of these mechanisms with message delays and node failures often results in data being unavailable. This not only stalls jobs that depend on that data, it also produces transitive delays for other jobs via queueing effects that can be hard to contain.  As a result, there is a great deal of interest in building distributed software that makes minimal (or no) use of these mechanisms.

The second point of reference is a long tradition of research and system development that uses {\em logical} application-level reasoning to tolerate ``loose'' consistency of reads, writes and messages (e.g., \cite{sagas,base,acid20,quicksand}, etc.)  This approach enables machines to operate independently, and hence easily tolerate temporary delays, message reordering, and component failures.  Results include simplified code, improved responsiveness, and a restriction on the effects of delays and failures to those tasks that are directly accessing the unavailable resources.  The challenge with this approach is to ensure that the resulting software truly tolerates the inconsistencies, producing acceptable results in all cases.  Although there is a body of wisdom and best practices that informs this approach, there are few concrete tools to allow programmers to harness that wisdom during software development.  It is hard to know what guarantees are provided by systems built in this style, and hence the resulting code is hard to test and hard to trust.  
%\jmh{The following is useful somewhere, but I chopped it from here as  unnecessary.  It is generally bad software engineering practice to rely on programmer wisdom, which is hard to maintain as code evolves and teams shift over time.}

Merging the best of these traditions, it would be ideal to have a robust theory and practical tools based on higher-level program properties than raw I/O, allowing developers to produce verifiably trustworthy code in the face of loosely consistent I/O.  In this paper we demonstrate significant progress in this direction via the use of a declarative language, and static analysis of code written in that language.  We begin by introducing the CALM principle, which makes a formal connection between the theory of monotonic logic and the need for distributed coordination to guarantee consistency.  Using an initial version of our {\em Bloom} declarative language, we translate this theory into a practical program analysis technique that detects potential consistency anomalies in distributed programs.  We then show how such anomalies can be handled by a programmer during development: either by introducing coordination mechanisms to ensure consistency, or by program rewrites that identify inconsistency ``taint'' as it propagates through code.  We demonstrate the use of Bloom and our analysis techniques on both ``loose'' and ``transactional'' implementations of a canonical distributed systems example: a fault-tolerant replicated shopping cart.  We run our Bloom shopping cart code on Amazon's EC2 cluster, and demonstrate the performance and consistency effects of the different design styles, and the way that our analyses inform code evolution.

As a secondary issue, we submit our Bloom prototype and application examples as a case for the practicality of declarative logic-based programming.  We believe these ideas are ready to graduate from topics of academic interest into practical, general-purpose approaches that we hope can substantially improve the state of the art in distributed programming.

If accepted, our paper presentation will include a live coding demo, with graphical analyses of our distributed shopping cart code, the ways that we manage inconsistency, and performance behavior in the face of distributed delays.

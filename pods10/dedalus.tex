\section{Dedalus}

By reifying time as data, we are able to reason about time in our logic.  some useful things fall out of this right away: persistence is now programatic rather than a separate type, ditto key constraints.  event creation vs. effect ambiguities are resolved.

Perhaps more importantly, the infinite sequence of abstract time gives us a way to reason about ordering, which is particularly difficult in a set-oriented language like Datalog.  The ordering over any program inputs (e.g. message queues) can be represented as a mapping between the ordering domain of the input and the time relation.

We consider an infinite Herbrand universe of constants \emph{C}, in which $C_{1}, C_{2}, [...], C_{n}$ are representations of individual constants,
and an infinite universe of variable symbols \emph{A} which may take on the values of any constants.   We also consider the ordered set
of positive integers \emph{S}, representing possible time values.

\subsection{Syntax}

A Dedalus program is a Datalog program in which every predicate is annotated with a time suffix.  A Dedalus predicate has the following form:

$p(A_{1}, A_{2}, [...], A_{n})@S$

The predicate p() is a truth-valued function over its arguments $A_{1} - A_{n}$, which may be of any type, and S, which is an integer expression 
referring to the logical clock time at which the predicate holds, taking one of the following three suffix forms:

\begin{enumerate}
\item $N$
\item $N + 1$
\item $N + r(A_{1}, A_{2}, [...], A_{n})$
\item an integer
\end{enumerate}

The arguments to the function $r$ are variables from the rule body, and thus attributes of subgoals.  Facts and rules in Dedalus are 
defined just as in Datalog, with the additional restrictions:

\begin{itemize}
\item Every body predicate may only have the suffix $N$.
\item A head predicate may have any suffix except a constant integer.
\item A fact must be posited with a constant integer for S, or the special function now().
\end{itemize}
Rules with the head suffix $N$ are called \emph{deductive} or atemporal rules, and describe all the logical consequences of facts in a given 
timestep. Deductive rules may be interpreted as pure Datalog rules by dropping the suffixes, treating all facts that are true in the current 
timestep as Datalog EDB, and running the rules to fixpoint.

Rules with the head suffix $N + 1$ are called \emph{inductive} temporal rules, and describe the relationship between facts in the current timestep 
and their consequences in the immediate next timestep. Inductive rules allow us to atomically capture change in time, and to model persistent state.

Rules with the head suffix $N+r(\_)$ are also temporal rules, but unlike inductive rules, they carry no guarantee as to in which timestep, if any, 
their consequences will become visible. Such rules, called message rules, allow us to model network messages between nodes: the nodes 
are likely to have different clock values, and messages may be lost or delayed arbitrarily.

\newdef{definition}{Definition}
\begin{definition}
I am a definition.
\end{definition}

\subsubsection{Events}

An event in Dedalus corresponds to a Datalog fact.  It is a bodyless head clause with all constant terms in the form


$p(C_{1},C_{2},[...],C_{n})@I;$


where the elements of C are constants of any type and I is an integer constant.

Events provide ground for any logical inferences given by the deductive rules of the program, and may provide ground for inferences at 
future time steps via inductive rules.

\subsubsection{Persistence}

Events are only true at a single timestep.  It might seem that we could express a persistent predicate as a Datalog fact with a free variable 
for the time suffix.  The tuple would then be universally quantified over time:

\begin{Dedalus}
p(a, b)@N;
\end{Dedalus}

But clearly, because this must be interpreted as a rule head with an unbound variable, it produces an unsafe rule.  Instead, persistence is
expressed by an inductive rule that projects a tuple into the next timestep:

\begin{Dedalus}
p(a, b)@N+1 \(\leftarrow\)
  p(a, b)@N, 
  \(\lnot\) del\_p(a, b)@N;
\end{Dedalus}

This rule, in turn, may be viewed as informally equivalent to a rule in which the inductive step is driven by an 
explicit successor relation, and in which the time suffixes are attributes of their respective predicates:

\begin{Dedalus}
p(a, b, S) \(\leftarrow\)
  p(a, b, N),
  successor(N, S), 
  \(\lnot\) del\_p(a, b, N);
\end{Dedalus}

The final subgoal \emph{del\_p} allows us to model overwriteable storage: without it, a tuple will be trivially true at every future timestep if it becomes true
at any timestep.  Instead, the \emph{del\_p} event, true only at a single timestep, breaks the induction.

Consider the following trace of events:

\begin{Dedalus}
p(1,2)@101;
p(1,3)@102;
p(1,?)@200;
del_p(1,2)@300;
p(1,?)@301;
\end{Dedalus}

It is easy to see that the results of the two queries are:


\begin{Dedalus}
p(1,2)@200;
p(1,3)@200;
p(1,3)@301;
\end{Dedalus}

\subsubsection{State Change}

Under this interpretation, a database update is an atomic (due to the adjacent timestamps)
pair of events with a deletion of the old value and assertion of the new, in the form:

$p(C_{1},C_{2},[...],C_{n})@I;$
\\
$del\_p(C_{1},C_{2},[...],C_{n})@I+1;$

For example:

\begin{Dedalus}
del\_p(1,2)@300; 
p(1, 4)@301;
\end{Dedalus}

Or more generally, an update can be described by a pair of rules that, in effect, describe a
constraint that holds between values in two adjacent timesteps:

\begin{Dedalus}
p(A, B)@N+1 \(\leftarrow\)
  update_p(A, B)@N;
  p(A, _)@N;
  
del_p(A, C)@N \(\leftarrow\)
  p(A, C)@N,
  update_p(A, _)@N;
  
\end{Dedalus}

\subsubsection{Sequences}

Database sequences, objects that retain a counter value and sometimes increment it, may be
represented with a pair of two inductive rules.  One increments the current counter value when the
trigger event is true, while the other persists the current value of the sequence only when the event is 
not true.

\begin{Dedalus}
seq(Agent, S + 1)@N+1 \(\leftarrow\)
  seq(Agent, S)@N, 
  event(Agent)@N; 
  
seq(Agent, S)@N+1 \(\leftarrow\) 
  seq(Agent, S)@N, 
  \(\lnot\) event(Agent)@N;
\end{Dedalus}

\subsubsection{Queues}
%%any tuple sent via a message rule is not sent to the indicated head p but to the builtin (as del\_p)
%%m\_p.  

\paa{it is here (at the m\_p relation) that is is assigned a timestamp which is consistent with r() at the sender, but which
is really "now" (how do we talk about this, having banished now?)}




Consider a relation that contains input from the external world, e.g. messages or tuple insertions from the host language.  
Having defined persistence as induction over time, we can define \emph{external} inputs as any sources of tuples 
that are not produced by an inductive rule.  This corresponds precisely to the concept of events that we have already
defined.

It will often be necessary to interpose some queueing discipline between an external table as defined above and any
rules that read from them.  For instance, if the tuples represent non-idempotent commands, it may be necessary to dequeue
the tuples in some data-dependent order, and to run the program to fixpoint before considering new tuples.  Consider a binary
predicate \emph{balance\_update} that contains updates to a bank account and an integer indicating the order in which they
should be executed.  If deductive rules are directly associated with \emph{balance\_update}, we must ensure at minimum that
the rules cleanly handle cases is which multiple events occur in a single fixpoint.  Instead, we can ensure ordered delivery 
of tuples to a program via a subprogram that defines a queueing discipline.

In the program below, we define a table \emph{m\_p} that we use as a queue to feed \emph{p}.  


\begin{Dedalus}
m\_p(A, B)@N+1 \(\leftarrow\)
  m\_p(A, B)@N,
  notin del\_m\_p(A, B)@N;

omin(A, min<B>)@N \(\leftarrow\)
  m\_p(A, B)@N;

p(A, B)@N+1 \(\leftarrow\)
  m\_p(A, B)@N,
  omin(B)@N;

del\_m\_p(A, B)@N \(\leftarrow\)
  m\_p(A, B)@N,
  omin(B)@N;
\end{Dedalus}

that's it!

observation: queues are just another example of programmatic interaction with time, not a language feature.

there is still an operational element here: the assignment of the timestamps as tuples are inserted.  this is basically the 
evaluation of the r() function.

\subsubsection{Lamport Clocks}

Implementing a Lamport Clock~\cite{timeclocks} is a special case of a queueing discipline as defined above.
Consider a predicate{m\_p} as defined above, but with an extra integer attribute that contains the logical transmission
time of the sender (via a message rule) of a given tuple.  For example, the sender's rule will look like: 

\begin{Dedalus}
m\_p(A, B, N)@N + r(A, B, N) \(\leftarrow\)
  send\_p(A, B)@N;
\end{Dedalus}

Note that the time suffix is projected into the last attribute of \emph{m\_p}.  The queueing discipline that implements a
Lamport clock is then:

\begin{Dedalus}

m\_p(A, B, C)@N+1 \(\leftarrow\)
  m\_p(A, B, C)@N,
  \(\lnot\) del\_m\_p(A, B, C)@N;

omin(A, min<C>)@N \(\leftarrow\)
  m\_p(A, B, C)@N;

lmin(min<C>)@N \(\leftarrow\)
  m\_p(_, _, C);

p(A, B, C)@N+1 :-
  m\_p(A, B, C)@N,
  omin(B)@N,
  lmax(L)@N,
  N > L;

del\_m\_p(A, B)@N :-
  m\_p(A, B)@N,
  omax(B)@N;
  
\end{Dedalus}

\subsection{Semantics}


\subsubsection{Static Evaluation}
\newtheorem{theorem}{Theorem}

\begin{theorem}
Every Dedalus program P with only deductive rules is equivalent to a Datalog program P'.
\end{theorem}

\begin{proof}
All rules in such a program will be in the form (shown propositionally for simplicity): 

%%\begin{Dedalus}
$p@N \leftarrow b_{1}@N, b_{2}@N, [...], b_{n}@N$
%%\end{Dedalus}

Where p is a head predicate and the $b$s are body predicates.  Note that all time suffixes are 
the same.

Because the time suffix is outside the scope of Datalog, a Datalog fact in the form:

$q(A_{1}, A_{2}, [...], A_{n});$

may be interpreted (equivalently) as persistently true (hence quantified over all logical times $N$) or instantaneously
true at some N.  If we follow the first interpretation, we have 

$q(C_{1}, C_{2}, [...], C_{n})@N;$

The variable N is now universally quantified in the program and in the EDB.  We may eliminate all occurrences of the time suffix N
in rules and facts, and are left with a Datalog program and EDB.

If we follow the second interpretation, the fact is true at some N, so we are given a ground event.  We extend every predicate in 
the program to contain an extra attribute that contains the time suffix value, and move the expression into the predicate as shown below:

$p(A_{1}, A_{2}, [...], A_{n})@N;$\\
$\rightarrow$\\
$p(A_{1}, A_{2}, [...], A_{n}, N);$

The resulting program and EDB are Datalog, and correspond to the intended semantics for the original Dedalus program.

\end{proof}


\subsubsection{Post-hoc Evaluation}

Consider a relation \emph{successor} defined in the following way.
Define first a (2nd order) predicate called \emph{event\_time} 
that contains the union of the time attributes from the EDB of events; i.e.

$event\_time(Time) \leftarrow \displaystyle\bigcup_{i}^n \pi_{Time}EDB_{i}$

\begin{Dedalus}
smax(max<N>) \(\leftarrow\) event\_time(N);
smin(min<N>) \(\leftarrow\) event\_time(N);

successor(N, N + 1) \(\leftarrow\) smin(N);

successor(S, S + 1) \(\leftarrow\) 
    successor(N, S),
    smax(M),
    N <= M;
\end{Dedalus}


\begin{theorem}
Every Dedalus program P with deductive and inductive rules and trace T is equivalent to a Datalog program P' with an EDB T'.
\end{theorem}

\begin{proof}

Extend every predicate to include a final integer attribute as shown in Theorem 1, and drop the body suffixes.  To each rule with an 
inductive head, add the subgoal 

$successor(N, S)$

To each other subgoal, set the new attribute to the variable N.  For the head, set it to S.  Rewrite the event trace in the same fashion, 
moving the event times from the suffix into the final attribute as shown above.


This gives us everything we need to simulate the history of evaluation of the program P using the program P'' and a Datalog interpreter.

\end{proof}

Note, however, that we need arithmetic functions to populate the successor relation.

\begin{theorem}
something about 'for any Dedalus program P and trace T, we may simulate its evaluation with a Datalog program P' and an EDB T'.  this program
will probably not produce side-effects (ie messages) at the same times as the original program, but the evaluation will otherwise be identical.'
\end{theorem}

introduce the $r()$ function, how we can model it using choice, and why it needs the entire successor relation to work properly.



\subsubsection{Continuous Evaluation}

Of course, we are interested in the dynamic and infinite case (\ref{fig:dedalus-time}).
Probably what we want to show is that the IDB database at any timestep of a continuous evaluation is a subset
of the post-hoc interpretation database: specifically, a partition of it on the time attribute.  (unfortunately, presumably
negation in programs can make this not so.)  therefore a constructive interpretation of the infinite sequence of time is permissible:
at each step of computation, we are given ground, a set of rules that tell us what is known now, and a counter value that increments
at each step.  this counter represents the single partition (a single row) of the infinite, totally ordered successor relation.
in some sense, we could argue that this is the only counter construct that needs to be available to the language.

To evaluate programs under the continuous interpretation, we define a special view called \emph{now} which contains the current 
time value.

\begin{Dedalus}
now()@N+1  \(\leftarrow\)
    now()@N;

prev(N)@N+1  \(\leftarrow\)
    now()@N;

panic()  \(\leftarrow\)
    now()@N,
    prev(M),
    M != (N + 1);
\end{Dedalus}

Every rule in a continuous Dedalus program can be considered to be rewritten to include a predicate

$now()@N$

such that $N$ unifies with the time variables in all predicates including \emph{successor}.  This constrains the evaluation of all deductive 
rules to a single partition (really, a single value) of \emph{successor}, and all inductive rules to consider only this and the successor partition.

\subsubsection{Persistence and Stratifiability}


The difficulty with the continuous interpretation is that we must consider the \emph{successor} relation as infinite, which clearly leads
to unsafe programs.  To make matters worse, many useful programs that mutate state will be unstratifiable, because \emph{del\_p} predicate
will be defined negatively in terms of the positive \emph{p} predicate.  For example, take the program below in which \emph{insert\_p}
and \emph{delete\_p} are external events:

\begin{Dedalus}
p(A, B, T)@N+1 \(\leftarrow\)
  p(A, B, T)@N,
  \(\lnot\)del\_p(A, B, T)@N;
  
  
p(A, B, T)@N \(\leftarrow\)
  insert\_p(A, B, T)@N;
  
del_p(A, B, T)@N \(\leftarrow\)
  p(A, B, T)@N,
  delete\_p(T)@N;
\end{Dedalus}

This reasonable program is unstratifiable because $p > del\_p \land del\_p > p$.  

We sidestep these difficulties in two ways:

\begin{enumerate}
\item By joining \emph{now}, we only consider one finite partition (really, one value) of \emph{successor} in a given fixpoint.
\item Any finite partition of \emph{successor}, including any that we may consider in the post-hoc interpretation, is locally stratified. 
\end{enumerate}

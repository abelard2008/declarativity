\section{Ordering and Asynchrony}
\label{sec:async}

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=0.75\linewidth]{figures/dedalus-time.pdf}
%   \label{fig:time}
%   %%\caption{Time moves forward in three ways: across strata, to the next fixpoint, and to some future fixpoint.}
%    \caption{Dedalus admits inferences whose consequences are visible immediately, in the next timestep, or at some unspecified timestep.}
%    
% \vspace{-8pt}
% \end{figure}

Until now we have restricted our discussion to \slang.  In this section we
introduce \lang, a superset of \slang that also admits aggregate functions
and the \emph{choice} construct.  These constructs will allow us to
express programs that establish or enforce an ordering over inputs, and to
reason about the inherent nondeterminism in communication over unreliable
networks that may delay, lose or reorder the results of logical deductions. 
%(see Figure~\ref{fig:time}).

\subsection{\lang: New Constructs}

In this section we present the Datalog extensions missing from \slang that we will need in \lang to capture important properties of practical distributed systems.  These include aggregate functions to 
capture ordering constraints, and the choice construct to capture nondeterminacy.

\subsubsection{Aggregate Functions}
\jmh{why only exemplary?  let's just do any aggs and cite appropriately}
We will consider only the class of \emph{exemplary} aggregate
functions~\cite{tag} -- an exemplary aggregate function's codomain is a subset
of its domain. 
%%-- and the \emph{count} aggregate, which is expressible using arithmetic.  
We allow exemplary %or count 
aggregate functions $\rho_1 - \rho_n$ to appear
in the head of a deductive rule of the form:

\dedalus{p(\(A_1\), \(\ldots\), \(A_n\), \(\rho_1\)(\(A_{n+1}\)), \(\ldots\), \(\rho_m\)(\(A_{n+m}\))) \(\leftarrow\)}
\linebreak\dedalus{   \(q_1\)(\(A_1\), \(\ldots\), \(A_n\)), \(\ldots\), \(q_n\)(\(A_1\), \(\ldots\), \(A_n\));}

These functions do not affect the expressivity of the language; we admit them
to simplify our discussion of ordering.  It is easy to see that the \emph{min} function,
which we subsequently use, is expressible in Datalog using negation.

%%\begin{example}
%%The query below selects, for each distinct value of the first column of $p$, the minimum 
%%value of the second column.

%%\begin{Dedalus}
%%min_p(A, min<B>) \(\leftarrow\) p(A, B);
%%\end{Dedalus}

%%The Datalog program below is equivalent:

%%\begin{Dedalus}
%%notmin_p(A, B) \(\leftarrow\) p(A, B), p(A, C), B > C;
  
%%min_p(A, B) \(\leftarrow\) p(A, B), \(\lnot\)notmin_p(A, B);
%%\end{Dedalus}
%%\end{example}




%%\dedalus{r\pos($A_1$, $A_2$, [...], $A_n$, }

%%$\rho$($A_{n+1}$)}

%%$\rho$($A_{n+2}$), [...] $\rho$($A_{n+m}$)) \(\leftarrow\) r($A_1$, $A_2$, [...], $A_n$);}



\subsubsection{Choice}

We also admit the \emph{choice} construct as defined by Greco and Zaniolo~\cite{greedychoice}.
The subgoal \dedalus{choose((\emph{$X_1$}), (\emph($X_2$))} may appear in the body of a rule, where
\emph{$X_1$} and \emph{$X_2$} are vectors whose constituent variables occur elsewhere in the body.  Such a subgoal
enforces the functional dependency \emph{$X_1$} $\to$ $X_2$, ``choosing" a single assignment of values to the variables
in \emph{$X_2$} for each variable in \emph{$X_1$}.

The choice construct is nondeterministic.  In a model-theoretic interpretation of logic programming, a nondeterministic program 
must have a multiplicity of stable models -- that is it must be unstratifiable.  Greco and Zaniolo define 
choice in precisely this fashion: the choice construct is expanded into an unstratifiable strongly connected component of rules, 
and each possible choice is associated with a different model.

\paa{significantly, for any choice, the resulting program has a unique minimal model if the program (independent of the choice expansion)
is stratifiable, locally stratifiable, etc}


\subsection{Distribution Model}

A principal motivation for \lang is modeling and implementing distributed systems.   Before we formally introduce issues from distributed computing, we give an intuitive overview of our approach.

To represent a distributed system, we consider a multiplicity of agents, each evaluating its own local program, 
asynchronously communicating with other agents via messages. 
 As with previous languages for declarative networking~\cite{Loo2009-CACM}, we will model messages as
tuples.  We will capture message transmission between programs by introducing additional ``cross-program'' rules, in which the body contains predicates of only one
agent's program, and the head atom is a predicate from another agent's program.  

\jmh{Don't talk about evaluation -- stick with the idea of multiple programs.}
We exclude agents from evaluating rules using non-local body atoms, as this computation necessarily involves communication
not modeled by \lang.  Thus, these message rules are the only manner in which data
elements derived from one agent's EDB may be visible in the IDB of another.  

This restriction is 
particularly significant to our interpretation of timestamps.  Although the \emph{successor} relation exists
at each agent according to our definition, the bindings from that relation to program variables---that is, the absolute ``times'' at which facts exist---may not be coordinated across agents.  Moreover, the natural asynchrony of distributed systems means that one agent should only be able to learn about  time values at another agent by receiving messages (with unknown delay) from that agent.  

We will enforce this strong notion of asynchrony syntactically in 
\lang.  To do so, the message rules described above will be required to  deduce a head predicate whose timestamp is independent
of the timestamps in the body predicates.  We proceed to describe these {\em asynchronous} rules, 

\subsection{Asynchronous Rules}

%%\rcs{ I touched this.  There is no longer a time predicate, we no longer admit causality violations}

In order to represent the nondeterminism introduced by distribution, we admit a
third type of rule, called an {\em asynchronous} rule.  A rule is asynchronous
if the 
%Recall our use of the distinguished variables $\Tau$ and $S$ to represent the
%time suffixes respectively in the body and head of a rule
%(Section~\ref{sec:syntaxrestrictions}).  in our discussion of \slang,
%representing the time suffixes occuring respectively in the body and head of a
%rule.
relation between the head time suffix $\SDedalus$ and the body time suffix $\Tau$ is
unknown.  Furthermore, $\SDedalus$, but not $\Tau$, may take on the special value
$\perp$ which means ``never.''  Derivation at $\perp$ indicates that the
deduction is ``lost,'' as time suffixes in rule bodies do not range over
$\perp$.

We model network nondeterminism using the \dedalus{choice} construct to choose
from a value in the special 
%%\dedalus{successors} 
\dedalus{time}
predicate, which is defined using the following datalog rules:

\begin{Dedalus}
time(\(\perp\));
time(\(\SDedalus\)) \(\leftarrow\) successor(\(\SDedalus\), _);
\end{Dedalus}


Each asynchronous rule has the following additional variables in its
body: \dedalus{time($\SDedalus$), choose((\_), ($\SDedalus$))}, where
$\SDedalus$ is the timestamp of the rule head.

\begin{example}
A well-formed asynchronous \lang rule:

\begin{Dedalus}
r(A, B, \(\SDedalus\)) \(\leftarrow\) 
  e(A, B, \(\Tau\)),
  time(\(\SDedalus\)), choose((_)), (\(\SDedalus\)));
\end{Dedalus}
\end{example}

We admit a new temporal head annotation to sugar the rule above.  The
identifier \dedalus{async} implies the rule is asynchronous, and stands in for the additional body predicates.
%%$N$ is a variable,
%%corresponding to the time suffix $\Tau$ of all predicates in the rule body and
%%optionally referenced in the head.  
The above example expressed using \dedalus{async} is:

\begin{Dedalus}
asynchronous
r(A, B)@async \(\leftarrow\) e(A, B);
\end{Dedalus}

It is easy to see that evaluation of an asynchronous rule may produce a tuple whose timestamp is less than $\Tau$, the timestamp
in the rule's antecedents. 
%%This violates our intuitive interpretation of timestamps capturing causal relations between 
%%tuples, and compromises the temporal stratifiability proof of \slang, because it is no longer the case that a ground atom
%%cannot possibly depend negatively on itself.
This violates the monotonicity assumptions upon which we based our proof of temporal stratification, and muddies our interpretation
of timestamps as capturing causal relations between tuples.


\subsubsection{Later: Causally-Constrained Asynchrony}

Ultimately, whether a particular set of temporal semantics is
desirable depends on the underlying application; for example, clever
combinations of crash-prone databases running ``read uncommitted''
transactions and asynchronous event queues can easily suffer from
grandfather paradoxes---traveling to the past to become one's own
ancestor---and other temporal impossibilities.

%%\rcs{move this, get rid of monotonic discussion?
%%We observe, however, that the order of evaluation of a Datalog program is irrelevant to the final result when the program is 
%%purely monotonic.  For such a program~\footnote{This holds also for the trivial cases of programs that ignore messages.}, 
%%deductions ``into the past" present no difficulties.
%%In fact, the ``eventual consistency" property of NDLog~\cite{loo-sigmod06} relies on the assumption that
%%programs are negation-free and hence monotonic.  Any programs with non-monotonic rules that transitively depend on
%%message tuples, however, may need to enforce an ordering discipline on such tuples.  We discuss this in detail in Section (Lamport Clocks).
%%}

The distributed systems literature typically assumes a causal ordering
of events across systems; Lamport clocks are a simple mechanism that
records the partial ordering induced by network communication between
the nodes.  With such approaches in mind, we introduce an alternative
to \dedalus{@async} called \dedalus{@later} that induces a total
ordering over all timestamps within a \lang program.  Instead of \dedalus{time}, we define \dedalus{after}:

\begin{Dedalus}
after(S, T) \(\leftarrow\) successor(S, T);
after(S, U) \(\leftarrow\) after(S, T), successor(T, U);
after(S, \(\perp\)) \(\leftarrow\) successor(S, _);
\end{Dedalus}

Intuitively, \dedalus{after(S, T)} is true if T happens after S in the
global ordering of events.  Each \dedalus{@later} rule has the
following additional variables in its body:
\dedalus{after($\Tau$, S), choose(($\Tau$), (S))}, where, as
above, $\Tau$ is the timestamp associated with the rule body, and
\dedalus{S} is the timestamp of the rule head.

Note that our addition of a global ordering does not expose a shared
synchronized clock to \lang programs.  The nondeterminism associated
with choice prevents programs from ensuring that operations are
performed in lock-step.  Instead, the timestamps simply encode some
logical clock that is equivalent to one that could be maintained by
the application.  The difference is that, by constraining
\dedalus{choose}, we can avoid reasoning about program traces that
contain paradoxes such as causality loops.  In particular, deterministic programs such as:

\begin{Dedalus}
r(1)@1;
s(1);
p(X) \(\leftarrow\) q(X), r(X);
q(X)@later \(\leftarrow\) s(X);
\end{Dedalus}
are non-deterministic if \dedalus{@later} is replaced with
\dedalus{@async}.  
\paa{the rest may stay but may also go}
The non-determinism comes from \dedalus{@sync}'s
\dedalus{choose} invocation.  However, the non-determinism also relies
on the fact that the program is, in some sense, non-monotonic; it
relies on the fact that \dedalus{r(1)} stops being true before
\dedalus{q(1)} is derived.

%%\rcs{Can we prove anything now?  It seems as though async rules are equivalent to \slang rules, as long as there is no aggregation or arithmetic.  The problem is that if %%choice derives a fact N steps in the future, we need to push the fact through N @next rules, and the number of such rules is variable.  If we admit arithmetic in the rewrite, %%%we can model async as a synchronous queue, but \slang doesn't have arithmetic...}
%%\rcs{Here to end of section is dead text}





%\dedalus{time(t)} is true if $t \in \mathbb{Z} \cup \perp$. 
%%\rcs{didn't understand the $\Theta$ thing; kill this paragraph?}
%%An asynchronous rule has the following
%%subgoals in its body: \dedalus{time(S), successors($\Theta$, S), choose(($\Theta$), (S))}, where
%%$\Theta$ is a vector containing all variables appearing in the rule body,
%%including $\Tau$.  The choice subgoal expresses that the rule head may be
%%derived at any value of \dedalus{time}.
%time value that appears in the \dedalus{successor} relation.

%%\rcs{old example:}

%%\begin{Dedalus}
%%asynchronous
%%r(A, B, S) \(\leftarrow\)
%%   e(A, B, \(\Tau\)), successor(_, S), choose((A, B), (S));
%%\end{Dedalus}


\subsubsection{Entanglement}

Consider the asynchronous rule below:

\begin{Dedalus}
p(A, B, N)@async \(\leftarrow\)
  q(A, B)@N;
\end{Dedalus}

Due to the async keywork in the rule head, the \emph{p} tuple will take some unspecified time suffix value.
Note however that the time suffix $N$ of the rule body appears also in the \emph{p} tuple, capturing a 
binding between the time value of the deduction and the time value of its consequence.  We call such a binding
an \emph{entanglement}.   Entanglement is a surprisingly powerful construct that allows a rule to 
reference the logical clock time of the deduction that produced one (or more) of its subgoals.  Note that in order
to write the rule it was necessary to not sugar away the time suffix in the rule body.  Entanglements are only 
permitted in asynchronous rules.

\subsection{Distributed Programs}

A distributed \lang program consists of a set of predicates partitioned across a set of hosts.
%%Consider two hosts $a$ and $b$ in \emph{H}, and two predicates $p$ and $q$ in \emph{P}.  Without loss of generality, 
%%we call an async rule $r$ a \emph{communication rule} if $p$ is defined at $a$ and $q$ is defined at $b$, $p$ occurs in the  
A \emph{communication rule} is an asynchronous rule whose head predicate is defined at a different host than its body predicates,
all of which are defined at a single host.  

It is easy to see that the only mechanism for sharing data between agents in a distributed system is through such communication 
rules.  Because communication rules (being asynchronous) cannot themselves capture causality relationships between tuples
via timestamps, any necessary relationship must be encoded into the tuples themselves via an entanglement.


\subsection{Ordering and distribution in Logic}

\subsubsection{Sequences}

One may represent a database sequence -- an object that retains and monotonically increases a counter value -- 
with a pair of inductive rules.  One rule increments the current counter value when some condition is 
true, while the other persists the value of the sequence when the condition is false.  We can capture the increase
of the sequence value without using arithmetic, because the infinite series of \emph{successor} has the monotonicity
property we require.  We need only to entangle the time suffix into the tuple:

\begin{Dedalus}
seq(A, N)@next \(\leftarrow\) seq(A, _)@N, event(A)@N;
  
seq(A, X)@next \(\leftarrow\) seq(A, X), \(\lnot\) event(A);
\end{Dedalus}

%%We must admit arithmetic functions into our language to express such a
%%sequence, but the pair of rules above remains temporally safe.

Clearly, to implement a sequence that increases consecutively without gaps would require using arithmetic.


\subsubsection{Queues}

%%Consider a trace of events to a 
Consider a predicate \dedalus{priority\_queue} that represents a series of tasks to be performed in some predefined order.  Its attributes are a string representing a user, a job, and an integer
indicating the position of the job in the queue:

\begin{Dedalus}
priority\_queue(``bob'', ``bash'', 200)@123;
priority\_queue(``eve'', ``john'', 1)@123;
priority\_queue(``alice'', ``ssh'', 204)@123;
priority\_queue(``bob'', ``ssh'', 205)@123;
\end{Dedalus}

Note that all the time suffixes are the same.  
%Depending on the program that implements the balance update, several behaviors
%are possible.
Given this schema, we note that a program would likely want to process
\dedalus{priority\_queue} events individually in a data-dependent order, in
spite of their coincidence in logical time.  It is difficult to express general
in-order tuple processing in Datalog, in part because the language does not
admit sequences.
%above is really what we want to say, right? -wrm
%has so
%notion of order of evaluation (except the implicit ordering implied by
%stratification).

In the program below, we define a table \dedalus{m\_priority\_queue} that
serves as a queue to feed \dedalus{priority\_queue}.  The queue must persist
across timesteps because it may take multiple timesteps to drain it.  At each
fixpoint, for each value of \textbf{A}, a single tuple is projected into
\dedalus{priority\_queue} and deleted (atomic with the projection) from
\dedalus{m\_priority\_queue}, changing the value of the aggregate calculated
at the subsequent step:

\begin{Dedalus}

m\_priority\_queue(A, B, C)@next \(\leftarrow\)
  m\_priority\_queue(A, B, C),
  notin del\_m\_priority\_queue(A, B, C);

omin(A, min<C>) \(\leftarrow\)
  m\_priority\_queue(A, _, C);

p(A, B, C)@next \(\leftarrow\)
  m\_priority\_queue(A, B, C),
  omin(A, C);

del\_m\_priority\_queue(A, B, C) \(\leftarrow\)
  m\_priority\_queue(A, B, C),
  omin(A, C);
\end{Dedalus}

Under such a queueing discipline, deductive rules that depend on
\emph{priority\_queue} are constrained to consider only one tuple per fixpoint
per value of the variable \textbf{A}, thus implementing a per-user FIFO
discipline.  To enforce a global FIFO ordering over \emph{priority\_queue}, we
may redefine \emph{omin} and any dependent rules to exclude the \textbf{A}
atttribute.

A queue establishes a mapping between the local clock and the ordering domain of the input relation. By doing so, we are able to take
advantage of the natural ordering enforced by stratification over time, to enforce an ordering property over our input that is otherwise 
very difficult to express in a logic language.

\subsubsection{Lamport Clocks}
Recall that \dedalus{@async} provides weaker semantics than
\dedalus{@later}, and can even lead to program executions that violate
causality.  In contrast, \dedalus{@later} builds a number of
assumptions about time into the language model.  This section explains
how to implement Lamport clocks~\cite{timeclocks} atop
\dedalus{@async}, ensuring that the program observes a causal ordering
of events.  Depending on the runtime environment, making use of
\dedalus{@async} and explicitly maintaining Lamport clocks may be more
or less natural than \dedalus{@later}.

Consider a rule \dedalus{p(A,B)@async \(\leftarrow\) q(A,B)}.  By
rewriting it to:

\begin{Dedalus}
persist[p, 2]
p\_wait(A, B, N)@async \(\leftarrow\) q(A, B)@N;
p\_wait(A, B, N)@next \(\leftarrow\) p\_wait(A, B, N)@M, N \(\ge\) M;
p(A, B)@next \(\leftarrow\) p\_wait(A, B, N)@M, N < M;
\end{Dedalus}

we place the derived tuple in a new relation \dedalus{p\_wait} that
stores any tuples that were ``sent into the past'' until the point in
time at which they were derived.  Conceptually, this causes the system
to evaluate a potentially large number of fixpoints (if N is
significantly less than the timestamp of the system when the tuple
arrives).  However, if the runtime is able to efficiently evaluate
timesteps when the database is quiescent (by recognizing that the
timesteps can be skipped), then instead of ``waiting'' by evaluating
timesteps, it will simply increase its logical clock to match that of
the sender.  In contrast, if the tuple is ``sent into the future,''
then it is processed using the timestep that receives it.  This
manipulation of timesteps and clock values is equivalent to
conventional descriptions of Lamport clocks.




%!TEX root = proposal.tex
% \input{preamble}
% 
% \begin{document}
%   
\vspace{-2pt}
\section*{\mytitle\\
{\normalsize PI: Joseph M. Hellerstein, U.C. Berkeley}}
% 1 page
Most architects of modern Big Data infrastructure believe that perfect distributed consistency is too expensive to guarantee in the large~\cite{ladisreport}.  This issue is often discussed in the context of data storage and retrieval, but it is also a major consideration in distributed Big Data computational infrastructure as well---be it application-level business rules~\cite{finkelstein2011} or machine learning algorithms~\cite{hogwild}.  Instead, loosely consistent approaches are often considered to be a better choice, since temporary inconsistencies across machines can often be made to work out at application level. By this reasoning, coordination mechanisms (transactions, locks, quorums, barriers, etc.) should be reserved for infrequent, mission-critical tasks.  The cost of this design pattern comes in software complexity: with loosely consistent infrastructure, application programmers must reason explicitly about distributed consistency issues for each high-level application feature.

Like many well-intentioned design maxims, loose consistency is not so easy to work with in practice; all kinds of unavoidable tactical questions pop up.  Exactly where in a multi-component system is loose consistency ``good enough,'' and when is coordination truly necessary?  How can a developer know that their ``mission-critical'' software is not tainted by others' ``best-effort'' components?  How does an architect maintain proper design maxims as software evolves? For example, how can the junior programmer in year $n$ of a project reason about whether their piece of the code maintains the system's overall consistency requirements?

In recent years we have had some initial breakthroughs in this area.  The \emph{CALM Theorem} proves that Consistency can be guaranteed---without coordination!---for programs that are Logically Monotonic. CALM analysis also leads to judicious use of coordination logic: coordination serves exclusively as a guard for non-monotonic reasoning.  Following from these ideas, we developed the \emph{Bloom} programming language.  Bloom is a ``disorderly'', data-centric language that discourages programmers from dictating the order of data and operations, since such orderings are expensive to guarantee in distributed systems.  Bloom's roots in logic programming enable simple compiler checks for monotonicity, which can be used to inform programmers about when and why to use expensive coordination logic to control order.

The goal of this proposal is to \textbf{exploit CALM theory to improve the development of software for Big Data}, making it easy for distributed programmers to relax their use of coordination and embrace distributed disorder in a natural yet principled fashion.  This goal requires significant research to extend the current instantiation of CALM theory into new engineering practices for building distributed systems.  


\vspace{6pt}
\noindent \textbf{Intellectual Merit.} Initial versions of CALM and Bloom have been steeped in a ``closed world'' of logic programming and low-level, fine-grained communication.  The work here proposes to extend this research to address challenges in a number of directions: \emph{analyzing monotonicity in familiar data types} that go beyond simple logic predicates and relations; \emph{composing encapsulated, service-oriented APIs using Bloom as a principled orchestration language} that can reason about the composition of API contracts; \emph{modeling massive distributed storage as a software component}, including a wide variety of possible consistency semantics; and \emph{providing CALM-aware software engineering tools} to back up these ideas with efficient debugging and testing frameworks that can help achieve and maintain software correctness over time.
 
\vspace{6pt}
\noindent \textbf{Broader Impacts.} Beyond the scientific and engineering impact of the Bloom languages and CALM analysis, this work is intended to improve the practice of Big Data software engineering in the field.  To promote understanding of concepts and adoption of techniques, we will run a Massive Open Online Course (MOOC), to reach out not only to Berkeley students and fellow researchers, but also to developers around the world. We will also continue to engage aggressively in industry, as we have been doing in recent years, via direct collaboration, industry talks and social media.  Given our history of releasing useful software, we plan to focus a significant fraction of this effort on releasing new versions of Bloom and its compiler analyses that can be used in academia and industry, along with the course materials and videos.

% \end{document}
\section{Introduction}
\label{sec:intro}

When a programmer sets out to implement an algorithm, he or she may go through
several iterations.  A first pass might involve establishing correct functionality, while not
worrying about performance optimizations.  A second pass might tune the code or configure it to
the specific execution environment (e.g., expected inputs, topology of the computer and/or network, etc.).  If assumptions about the distribution of inputs or topology change, then further passes may
be required to re-tune the algorithm.  Too often, performance concerns are cross-cutting; changes to
tune performance involve significantly modifying or restructuring code.  When all is said and done,
it is hard to be sure that modifications intended to tweak performance have not unintentionally
interfered with program correctness or determinism.

We propose a two-part language: one part ``algebra,'' one part ``ordering.''  Our language disentangles the specification of ordering from the specification of program logic, reminiscent of Kowalski's famed ``Algorithm = Logic + Control'' formula~\cite{alc}.  A programmer first
writes a specification of his or her program in the ``algebra'' language.  At this point, the algebra
can be executed using a default ordering.
Once the ``algebra'' is suitably specified to enable the ordering freedom a programmer desires, he or she can
tune the performance by only changing the ``ordering'' code.  This pattern has the significant
advantage that changes to the ``ordering'' code will not affect the output of the algorithm.  This
leaves programmers free to experiment with different performance optimizations, and to re-use the
same specification across many different input distributions or execution environments.


The interface between ``algebra'' and ``ordering'' is known as a ``timeline.''  A ``timeline'' intuitively specifies a particular concrete ordering of operations.  The ``ordering'' component may be any arbitrary code that generates a legal ``timeline.''  The ``algebra'' component is a restricted language, designed to ensure that program outcomes are independent of the ``ordering.''  We provide a formal static analysis for ``confluence'' of the ``algebra'' portion---i.e., when the output of the specification of the program is independent of the particular ``timeline'' (concrete ordering) chosen~\cite{this-tr}.


Computer Science is full of examples where ordering is manipulated to tune performance.  These
examples often come up in the domain of {\em space-time tradeoffs}, where the use of additional
memory, network bandwidth, or storage is traded off against the temporal characteristics of the
program's output.  In some cases, programmers may care about producing the entire output quickly.
In other cases, such as online aggregation~\cite{Hellerstein1997}, a programmer may desire the speedy computation of
{\em early returns} (partial results).  Other examples in this area include compression schemes
(e.g., run-length encoding and Nagle's algorithm), as well as deterministic Las Vegas algorithms,
where randomness is used to decorrelate inputs from performance characteristics.

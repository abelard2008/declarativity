program jobtracker;

import org.apache.hadoop.mapred.JobID;
import org.apache.hadoop.mapred.TaskID;
import org.apache.hadoop.mapred.declarative.Constants;
import org.apache.hadoop.mapred.declarative.util.JobState;
import org.apache.hadoop.mapred.declarative.util.TaskState;
import java.lang.Integer;
import java.lang.Long;
import java.lang.Enum;

/*************** TASK INIT *********************/


define(initTask, {JobID, Wrapper, String, TaskID, Enum, Integer, Wrapper, Integer, TaskState});
define(taskInputLocation, keys(0,1), {JobID, TaskID, String});
define(taskInput, {JobID, TaskID, ValueList});

initTask(JobID, JobConf, JobFile, null, null, null, null, null, null) :-
	job(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, JobState),
	JobState.state() == JobState.PREP;
	
/* Break out of the current fixpoint thread (using 'async') since taskCreate table function
   makes calls to the DFS. */
async
task(JobID, TaskID, Type, Partition, Split, MapCount, Status) :-
	taskCreate(initTask(JobID, JobConf, JobFile, TaskID, Type, Partition, Split, MapCount, Status));
	
taskInput(JobId, TaskId, Locations) :-
	task(JobId, TaskId, Type, _, Split, _, TaskState),
	TaskState.state() == TaskState.UNASSIGNED,
	Locations := new ValueList(Split.getLocations());
	
taskInputLocation(JobId, TaskId, Location) :-
	flatten(taskInput(JobId, TaskId, Locations)),
	Location := (String) Locations;
	
	
/*************** Job Status Maintenance *********************/
	
define(jobStateUpdate, {JobID});
define(jobState, {JobID, JobState});
define(jobMapCount, keys(0), {JobID, Integer});
define(jobReduceCount, keys(0), {JobID, Integer});

/* Update the job state on any change to the task table. */
jobStateUpdate(JobID) :- task(JobID);

/* Compute the job state based on task state. */
jobState(JobID, generic<(new JobState(JobID, Maps, Reduces).task(Type, TaskState)>) :-
	jobStateUpdate(JobID),
	task(JobID, _, Type, _, _, _, TaskState),
	jobMapCount(JobID, Maps), jobReduceCount(JobID, Reduces),	
	job(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, JobState);
	
/* Update the job state. */
job(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, JobState) :-
	jobState(JobID, JobState),
	job(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, _);
    
jobMapCount(JobId, count<*>) :-
	task(JobID, _, Type, _, _, _, _),
	Type == TaskTable.MAP;
	
jobReduceCount(JobId, count<*>) :-
	task(JobID, _, Type, _, _, _, _),
	Type == TaskTable.REDUCE;
	

/*************** Task Status Maintenance *********************/

define(taskStateUpdate, {JobID, TaskID});
define(taskState, {JobID, TaskID, TaskState});
	
/* Update the job state on any change to the task table. */
taskStateUpdate(JobID, TaskID) :- 
	taskAttempt(JobID, TaskID, _, _, _, _, _, _, Start, _), Start > 0;

taskState(JobID, TaskID, generic<(new TaskState(JobID, TaskID)).attempt(Progress, State, Phase, Start, Finish)>) :-
	taskStateUpdate(JobID, TaskID),
	taskAttempt(JobID, TaskID, _, Progress, State, Phase, _, _, Start, Finish)
	
task(JobID, TaskID, Type, Partition, Split, MapCount, TaskState) :-
	taskState(JobID, TaskID, TaskState),
	task(JobID, TaskID, Type, Partition, Split, MapCount, _);
	
	
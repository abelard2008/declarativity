program jobtracker;

/*************** TASK INIT *********************/

import org.apache.hadoop.mapred.JobID;
import org.apache.hadoop.mapred.TaskID;
import org.apache.hadoop.mapred.declarative.Constants;
import org.apache.hadoop.mapred.declarative.util.JobState;
import org.apache.hadoop.mapred.declarative.util.TaskState;
import java.lang.Integer;
import java.lang.Long;
import java.lang.Enum;

define(initTask, {JobID, Wrapper, String, TaskID, Enum, Integer, Wrapper, Integer, TaskState});

initTask(JobID, JobConf, JobFile, null, null, null, null, null, null) :-
	job(JobID, Name, User, JobFile, JobConf, URL, Priority, JobState),
	JobState.state() == JobStatus.PREP;
	
async
task(JobID, TaskID, Type, Partition, Split, MapCount, Status) :-
	taskCreate(initTask(JobID, JobConf, JobFile, TaskID, Type, Partition, Split, MapCount, Status));
	
	
/*************** Job Status Maintenance *********************/
	
define(JobStatus, {JobID, JobState});

jobStatus(JobID, generic<(new JobState(JobID, Maps, Reduces).task(Type, TaskState)>) :-
	task(JobID, _, Type, _, _, _, TaskState),
	jobMapCount(JobID, Maps), jobReduceCount(JobID, Reduces),	
    job(JobID, Name, User, File, JobConf, URL, Priority, _);

job(JobID, Name, User, File, JobConf, URL, Priority, JobState) :-
	jobStatus(JobID, JobState),
    job(JobID, Name, User, File, JobConf, URL, Priority, _);
    
jobMapCount(JobId, count<*>) :-
	task(JobID, _, Type, _, _, _, _),
	Type == TaskTable.MAP;
	
jobReduceCount(JobId, count<*>) :-
	task(JobID, _, Type, _, _, _, _),
	Type == TaskTable.REDUCE;
	

/*************** Task Status Maintenance *********************/

define(TaskStatus, {JobID, TaskID, TaskState});
	
taskStatus(JobID, TaskID, generic<(new TaskState(JobID, TaskID)).attempt(Progress, State, Phase, Start, Finish)>) :-
	taskAttempt(JobID, TaskID, AttemptID, Progress, State, Phase, _, _, Start, Finish)
	
task(JobID, TaskID, Type, Partition, Split, MapCount, TaskState) :-
	taskStatus(JobID, TaskID, TaskState),
	task(JobID, TaskID, Type, Partition, Split, MapCount, _);
	
	
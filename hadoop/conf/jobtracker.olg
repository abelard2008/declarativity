program jobtracker;

import org.apache.hadoop.mapred.JobID;
import org.apache.hadoop.mapred.TaskID;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobPriority;
import org.apache.hadoop.mapred.JobConf;

import org.apache.hadoop.mapred.declarative.Constants;
import org.apache.hadoop.mapred.declarative.util.JobState;
import org.apache.hadoop.mapred.declarative.util.TaskState;
import org.apache.hadoop.mapred.declarative.util.Function;
import org.apache.hadoop.mapred.declarative.util.FileInput;
import org.apache.hadoop.mapred.TaskTrackerAction;

import jol.types.basic.ValueList;
import java.lang.Integer;
import java.lang.Long;
import java.lang.Enum;

watch(job, a);
watch(task, a);
watch(taskAttempt, a);

define(jobQueue, keys(0), {JobID, JobPriority, Long, Constants.TaskType});


/*************** JobTracker Duty Cycle (PERFORMANCE HACK) *********************/
timer(minDutyCyclePeriod, physical, 5000, infinity, 0);
define(dutyCycle, {String});
define(activeJobs, keys(), {Integer});

watch(activeJobs, ae);
activeJobs(count<JobId>) :-
	job(JobId, _, _, _, _, _, _, _, FinishTime, _),
	FinishTime == 0L;
	
watch(dutyCycle, a);
/* Set semantics ensure a single duty cycle per fixpoint. 
   I could have used a logical clock here but that spin the CPU during idle periods. */
dutyCycle("Duty Cycle") :- minDutyCyclePeriod(), activeJobs(Count), Count > 0;


/*************** Task Tracker Monitor *********************/

/*
timer(checkTracker, physical, 60000, infinity, 60000);

taskTracker(TrackerName, Host, HttpPort, Constants.TaskTrackerState.FAILED, 
            Timestamp, Failures, MapCount, ReduceCount, MaxMap, MaxReduce) :-
	checkTracker(Period, TTL, Delay),
	taskTracker(TrackerName, Host, HttpPort, TrackerState, Timestamp, Failures, 
	            MapCount, ReduceCount, MaxMap, MaxReduce),
	TrackerState == Constants.TaskTrackerState.RUNNING,
	java.lang.System.currentTimeMillis() - Timestamp > Period;
	*/
	
/*************** Clean up *********************/

define(cleanup, {JobID});

cleanup(JobId) :-
	job(JobId, _, _, _, _, _, _, _, _, JStatus),
	JStatus.state() == Constants.JobState.SUCCEEDED || 
	JStatus.state() == Constants.JobState.FAILED;
	
delete
task(JobId, TaskId, Type, Partition, Input, MapCount, Status) :-
	cleanup(JobId),
	task(JobId, TaskId, Type, Partition, Input, MapCount, Status);

delete
taskAttempt(JobID, TaskID, AttemptID, Progress, TaskState, Phase, Diag, TrackerName, FileLoc, Start, Finish, Timestamp, Dirty) :-
	cleanup(JobId),
    taskAttempt(JobID, TaskID, AttemptID, Progress, TaskState, Phase, Diag, TrackerName, FileLoc, Start, Finish, Timestamp, Dirty);
    
delete
taskFileLocation(JobId, TaskId, Loc) :-
	cleanup(JobId), taskFileLocation(JobId, TaskId, Loc);


/*************** TASK INIT *********************/

define(initJob,  {JobID, String, String, JobConf, String, String, JobPriority, Long, Long, JobState});
define(initTask, {JobID, JobConf, String, TaskID, Constants.TaskType, Integer, FileInput, Integer, TaskState});
define(taskFile, {JobID, TaskID, ValueList});
define(taskFileLocation, keys(0,1), {JobID, TaskID, String});

job(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, FinishTime, Status) :-
	initJob(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, FinishTime, Status);

initTask(JobID, JobConf, JobFile, null, null, null, null, null, null) :-
	initJob(JobID, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, _, Status);
	
/* Break out of the current fixpoint thread (using 'async') since taskCreate table function
   makes blocking calls to the DFS. */
async initTask
task(JobID, TaskID, Type, Partition, Input, MapCount, Status) :-
	taskCreate(initTask(JobID, JobConf, JobFile, TaskID, Type, Partition, Input, MapCount, Status));
	
taskFile(JobId, TaskId, Locations) :-
	task(JobId, TaskId, Type, _, Input, _, Status),
	Status.state() == Constants.TaskState.UNASSIGNED,
	Type == Constants.TaskType.MAP
	{ Split := Input.split(); Locations := Function.getLocations(Split); };
	
taskFileLocation(JobId, TaskId, Location) :-
	flatten(taskFile(JobId, TaskId, Locations)),
	Location := (String) Locations;
	
	
/*************** Network Statistics  *********************/

define(distance, keys(0,1), {String, String, Integer});
define(networkDistance, keys(0,1), {String, String, Integer});

distance(Host, Host, 0) :-
	networkTopology(Host, Location, Parent, Level);
	
distance(Host, Location, 1) :-
	networkTopology(Host, Location, Parent, Level);
	
networkDistance(Location1, Location2, min<Distance>) :-
	distance(Location1, Location, Distance1),
	distance(Location2, Location, Distance2),
	Location1 != Location2,
	Distance := Distance1 + Distance2;
	

/*************** Job Status Maintenance *********************/
import java.util.Set;
	
/* Update the job state. */
public updateJobState
job(JobId, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, FinishTime, JobStatus) :-
	taskUpdate(JobId, TaskId, Type, TaskStatus),
	job(JobId, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, _, JobStatus),
	JobStatus.task(Type, TaskStatus)
	{
	FinishTime := JobStatus.state() == Constants.JobState.SUCCEEDED ? 
	              java.lang.System.currentTimeMillis() : 0L;
	};
	
define(killjob, {JobID});
killJob
job(JobId, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, FinishTime, JobStatus) :-
	killjob(JobId),
	job(JobId, JobName, JobFile, JobConf, User, URL, Priority, SubmitTime, _, JobStatus),
	JobStatus.killjob()
	{
	FinishTime := JobStatus.state() == Constants.JobState.SUCCEEDED ? 
	              java.lang.System.currentTimeMillis() : 0L;
	};
	

define(killJobOnTracker, {JobID, String});
public
killJobOnTracker(JobId, TrackerName) :-
	job(JobId, _, _, _, _, _, _, _, _, JobStatus),
	taskAttempt(JobId, TaskID, _, _, TaskState, _, _, TrackerName, _, _, _, _,_),
	JobStatus.state()  == Constants.JobState.FAILED,
	TaskState == Constants.TaskState.RUNNING;
	
taskTrackerAction(TrackerName, TaskTrackerAction.ActionType.KILL_JOB, Action) :-	
	killJobOnTracker(JobId, TrackerName),
	Action := Function.killJob(JobId);
	
    
/*************** Task Status Maintenance *********************/

define(taskUpdate, {JobID, TaskID, Constants.TaskType, TaskState});
define(lookupDirtyTaskAttempt, {Boolean});
define(lookupTask, {JobID, Constants.TaskState});

taskAttempt(JobId, TaskId, AttemptID, Progress, Constants.TaskState.FAILED, 
            Phase, Diag, TrackerName, FileLoc, Start, Finish, Timestamp, true) :-
	taskTracker(TrackerName, _, _, TrackerState, _, _, _, _, _, _),
	taskAttempt(JobId, TaskId, AttemptID, Progress, TaskState, Phase, Diag, TrackerName, FileLoc, Start, Finish, Timestamp,_),
	TrackerState != Constants.TaskTrackerState.RUNNING,
	TaskState == Constants.TaskState.RUNNING;
	
lookupTask(JobId, State) :- 
    dutyCycle(), job(JobId, _, _, _, _, _, _, _, _, JobStatus),
    jobQueue(JobId, _, _, Type),
    JobStatus.state() == Constants.JobState.RUNNING
    {
      State := Type == Constants.TaskType.MAP ? Constants.TaskState.SUCCEEDED : Constants.TaskState.COMMIT_PENDING;
    };

/*
lookupDirtyTaskAttempt(true) :- dutyCycle();
taskAttempt(JobId, TaskId, AttemptID, Progress, State, Phase, Diag, Tracker, TaskFileLoc, Start, Finish, Timestamp, false) :-
	lookupDirtyTaskAttempt(Dirty),
	taskAttempt(JobId, TaskId, AttemptID, Progress, State, Phase, Diag, Tracker, TaskFileLoc, Start, Finish, Timestamp, Dirty);
*/

delete
taskAttempt(JobId, TaskId, AttemptID, Progress, State, Phase, Diag, Tracker, TaskFileLoc, Start, Finish, Timestamp, Dirty) :-
    taskUpdate(JobId, TaskId, Type, TaskStatus), TaskStatus.state() == Constants.TaskState.SUCCEEDED,
	taskAttempt(JobId, TaskId, AttemptID, Progress, State, Phase, Diag, Tracker, TaskFileLoc, Start, Finish, Timestamp, Dirty);

watch(taskUpdate, a);
public
taskUpdate(JobId, TaskId, Type, TaskStatus) :-
	lookupTask(JobId, State),
	taskAttempt(JobId, TaskId, AttemptID, Progress, State, Phase, _, _, _, Start, Finish, _, _),
	task(JobID, TaskId, Type, _, _, _, TaskStatus),
	TaskStatus.state() != Constants.TaskState.SUCCEEDED,
	TaskStatus.attempt(AttemptID, Progress, State, Phase, Start, Finish);
	

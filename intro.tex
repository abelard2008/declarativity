The ubiquity of both Big Data and Cloud Computing are having profound effects on software development. Scalable data management and distributed computing used to be esoteric topics handled by low-level systems experts.  But these issues have now surfaced into the mainstream of software development.   The challenges of large distributed systems---concurrency and asynchrony, performance variability, and partial failure---often translate into tricky data management challenges regarding task coordination and data consistency.
Given the growing need to wrestle with these challenges, there is increasing pressure to find solutions to the difficulty of distributed programming.

There are two main bodies of work to guide programmers through these issues.  The first is the ``ACID'' foundation of distributed transactions, grounded in the theory of serializable read/write schedules and consensus protocols like Paxos and Two-Phase Commit~\cite{grayreuter}.  These techniques provide strong consistency guarantees, and can help shield programmers from much of the complexity of distributed programming. However, there is a widespread belief that the costs of these mechanisms are too high in many important scenarios where availability and/or low-latency response is critical.
As a result, there is a great deal of interest in building distributed software that avoids using these mechanisms.

The second point of reference is a long tradition of research and system development that uses application-specific reasoning to tolerate ``loose'' consistency arising from flexible ordering of reads, writes and messages (e.g., \cite{sagas,beyond,quicksand,base,bayou}). This approach enables machines to continue operating in the face of temporary delays, message reordering, and component failures.  
The challenge with this design style is to ensure that the resulting software tolerates the inconsistencies in a meaningful way, producing acceptable results in all cases.  Although there is a body of wisdom and best practices that informs this approach, there are few concrete software development tools that codify these ideas.  Hence it is typically unclear what guarantees are provided by systems built in this style, and the resulting code is hard to test and hard to trust.  

\subsection{Background: CALM and Bloom}
Ideally, we would like to have a theoretical frame of reference for high-level application-specific guarantees of consistency, much as serializability gives (inefficiently) to low-level read/write reasoning.In addition, we would like to be able to transfer this frame of reference into practical tools that could radically simplify life for developers.  In recent years, we have made significant breakthroughs on both these fronts, which represent a powerful starting point to the broader research agenda in this proposal.

First, we developed the CALM Theorem, which provides a formal connection between monotonic program logic and eventually-consistent outcomes~\cite{podskey}.  The CALM Theorem has been formalized in both operational~\cite{Ameloot2011,Abiteboul11} and model-theoretic~\cite{marczak2012} terms.    Intuitively, a monotonic program makes forward progress over time: it never “retracts” an earlier conclusion in the face of new information.   The CALM Theorem demonstrates that monotonic programs are \emph{confluent}---they produce deterministic outputs regardless of non-determinism in network delays and message ordering.  As a result, monotonic programs have the property of ``eventual consistency'': in the fullness of time, once all messages are delivered, the final state of all program replicas will be consistent with the deterministic meaning of the program.  This frees programmers from worrying about orders of operation, one of the trickiest issues to reason about and control in distributed systems.  CALM also provides insights into managing non-monotonic logic: in particular, if distributed programs \emph{coordinate} (only) before non-monotonic operations, the resulting program will be eventually consistent as well.  In short, CALM provides insights into \emph{when} and \emph{why} programmers should use expensive coordination protocols.

Second, following from CALM, we developed the Bloom language, and programmer-facing tools for verifying eventual consistency of user programs based on CALM analysis. Like many other verification tasks, consistency analysis is much more effective in a sufficiently high-level language---in this case, one where the constructs of the language can be translated into an underlying logic. Bloom is our language along these lines. 

Given a Bloom program, we can ``bless'' software modules as monotonic, and hence safe to run without coordination.  We can also identify non-monotonic \emph{points of order} in Bloom programs, which can be resolved by either (a) adding packaged coordination logic (e.g. quorum consensus) to enforce the ordering, or (b) augmenting the program to tag downstream data as “tainted” with potential inconsistency.  In addition, we can visualize a module and its points of order in a graphical debugger, to help programmers reason about restructuring their code for more efficient consistency enforcement.

\subsection{Moving Forward: Widespread CALM}
Bloom and its CALM analysis have been the subject of growing attention not only in the research community~\cite{Ameloot2011,Ameloot2012,Abiteboul2011,Green2011}, but also within industry: in addition to invited presentations at various industrial workshops~\cite{goto11,langnext12,basho12}, and extensive discussion on social media and blogs~\cite{}, Bloom was the winner of the TR10 award for ``ten technologies most likely to change our world'' in 2010~\cite{tr10}.  More practically, Bloom and its CALM analysis have enabled us to write and analyze a variety of complex distributed programs compactly and correctly~\cite{bud-sandbox}.  

However, in our initial research on applying the CALM foundations in practice, we purposely kept a narrow focus on fine-grained, interactive distributed systems written from scratch in Bloom.  This allowed us to validate the utility of our theoretical framework for building practical software in a carefully-designed language.  But it restricted our impact to developers willing to adopt Bloom at a low level of the software stack.  The goal of this proposal is to aggressively expand the impact of CALM foundations, by exploring a fundamental technical agenda driven by contemporary practices in Big Data.  We focus on four key directions:

\begin{itemize}
  \item \textbf{CALM Beyond Sets.}  The original formulation of CALM and Bloom only verifies the consistency of programs that compute sets of facts that grow over time (“set monotonicity”); that is, “forward progress” is defined according to set containment. As a practical matter, this is overly conservative: it precludes the use of common monotonically-increasing constructs such as timestamps and sequence numbers.  This presents a dilemma to developers: either they can translate traditional designs to a (potentially unnatural) set representation and benefit from fine-grained CALM analysis of monotonicity, or they can have natural, inherently monotonic code like increasing timestamps be marked conservatively as a point of order by CALM analysis.  We seek to move past this dilemma by generalizing Bloom and CALM analysis beyond sets to work on any \emph{join semi-lattice}.  (Section~\ref{lattice}).

  \item \textbf{CALM Service Composition.}  Basic CALM analysis works within the scope of a whole program written in Bloom. However, modern software is typically written by composing multiple reusable services---typically exposed via opaque APIs. While CALM analysis provides powerful new insights within a Bloom ``sandbox'', it offers no help to the practical scenario of building contemporary service-oriented architectures.  We therefore hope to modularize CALM analysis in a generic fashion, to reason about the composition of widely-used services written in traditional languages, with Bloom used as a thin layer of ``orchestration logic'' for service composition.  (Section~\ref{soa}).

  \item \textbf{Staying CALM with Distributed Storage.} The early versions of Bloom represented state exclusively in local collections of data; distributed data sets were to be explicitly implemented by programmers.  This has made Bloom unattractive for all but the lowest-level developers of Big Data systems.  We intend to expose distributed storage---and its spectrum of consistency guarantees---as a first-class construct in our development and program analysis tools.  Because the consistency semantics of distributed storage can vary widely, we would like our program analysis to capture these semantics meaningfully, and enable us to compose correct programs over these various storage semantics, relaxing consistency when acceptable, and demanding it when not.  (Section~\ref{sec:storage}).
  
  \item \textbf{CALM Software Engineering for Distributed Programs.}  Even with powerful tools like CALM analysis, programmers sometimes choose to forgo static consistency guarantees of the form provided by monotonic code and distributed coordination.  In short, they choose to ``cut corners'' with respect to formal guarantees, and rely on dynamic tests (exception handling) to deal with any problems.  This raises challenges in Quality Assurance (QA) and Software Engineering issues involving the testing and dynamic analysis of complex software.  QA over Big Data can be very difficult: there is an enormous space of possible executions to exercise, arises from (a) the non-determinism inherent in asynchronous messaging between unreliable machines, and (b) the incredible diversity of execution scenarios that arise at massive scale, where small-probability events occur on surprisingly small timescales.  We believe CALM analysis can help here to radically prune the space of scenarios to test, and provide succinct, targeted explanations of software hazards for programmers to reason about.  (Section~\ref{sec:qa}).
\end{itemize}
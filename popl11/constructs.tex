\section{Time, State and Order}
\label{sec:stateupdate}

%%\linebreak
\begin{quote}
%
\emph{Time is a device that was invented to keep everything from
happening at once.}\footnote{Graffiti on a wall at Cambridge
University~\cite{scheme}.}
%
\end{quote} 

%Recall that by an event, we mean a \lang fact.
%The transitive consequences
%(via deductive rules) of events are likewise events and hold atomically in the
%same timestep with their premises.  However,

As we showed in the previous section, logical time may be used as a 
``source of monotonicity'' to restore a meaningful, temporal interpretation to otherwise
semantically ambiguous constructs like updateable state and orderly processing.  
Many common motifs in systems programming
(distributed and otherwise) follow a similar pattern of restricted nonmonotonicity, in 
which consequences of deductions are deferred in time.  In this section, we demonstrate
the expressivity of \lang by building a collection of stateful and orderly contructs,
most of which employ the careful use of nonmonotonic reasoning deferred in time.
We also introduce a convenience notation in the form of a simple macro language
for many of these common patterns.

%%\noindent{}In an asynchronous system, the programmer will in general not be able to
%%predict when, or in what order, events arrive from other nodes.  Additionally,
%%some events may need to be handled over time \jmh{vague}, requiring state-oriented motifs
%%such as persistence and mutability.  In this section, we construct a library of
%%\lang constructs to capture these two uses of order.

%Given our definition of \lang, we now address the persistence and mutability
%of data across time: a signature feature of distributed systems---and systems
%in general.
%---for which we provide a model-theoretic foundation.

%The intuition behind \lang's \dedalus{successor} relation is that it models the
%passage of (logical) time.  In our discussion, we will say that facts with
%lower time suffixes occur ``before'' atoms with higher ones.  The constraints
%we imposed on \lang rules restrict how deductions may be made with respect to
%time.  First, rules may only refer to a single time suffix variable in their
%body, and hence {\em cannot join across different ``timesteps''}.  Second,
%rules may specify deductions that occur concurrently with their ground facts,
%\wrm{define ground fact somewhere} in the next timestep, or at some arbitrary
%time, including times before their ground facts.

%This notion of time allows us to consider the contents of the EDB---and hence
%a model of an instance---with respect to an ``instant in time'': we simply
%bind the time suffixes ($\DT$) of all body predicates to a constant.  Because
%this produces a sequence of models (one per timestep), it gives us an intuitive
%and unambiguous way to declaratively express persistence and state changes
%across time.  In this section, we give examples of language constructs
%that capture state-oriented motifs such as persistent relations,
%deletion and update, sequences, and queues.

\subsection{State in Logic}

\jmh{Back this up with formalism: can't do a flip/flop in Datalog (Chandra/Harel, right?).  This discussion does tee up the question of whether something more traditional like Datalog-neg would have been enough for us ... might be sufficient to simply toss in a result about Turing completeness of Dedalus.  I realize your point here is more practically-minded and illustrative, but then maybe this intro is off target for this section.  Still I think an expressivity subsection in the paper would be nice.}


Logic languages naturally model the accumulation of information: deduction in 
the broadest sense tells us, given what we already know, what follows from it.  However, systems
programming frequently requires us to model information that may disappear or change
over time.  In this section we model persistence, both immutable and dynamic, as
\emph{induction} over time, and provide a convenience notation for declaring certain
relations as ``persistent.''


\subsubsection{Simple Persistence}
%
A fact in predicate $p$ at time $\DT$ may provide ground for deductive rules at
time $\DT$, but may only provide ground for deductive rules in timesteps
greater than $\DT$ if it is persisted.  One way to persist all facts in a
predicate $p$ is to use a {\em simple persistence rule}:

\dedalus{p\pos($A_1$,$A_2$,[...],$A_n$)@next $\leftarrow$
p\pos($A_1$,$A_2$,[...],$A_n$);}

\noindent A rule of this form ensures that a $p$ fact true at time $i$ will be
true $\forall j \in \mathbb{N} : j >= i$.


\subsubsection{Mutable State}
\label{sec:mutable}

Simple persistence rules cannot model deletions and updates of a fact, because
they express an unbroken induction over time.  One way to allow the induction
to be broken is to add a \dedalus{p\nega} subgoal to the body of a simple
persistence rule:

\begin{dedalus}
p\_pos($A_1,A_2,[...],A_n$)@next $\leftarrow$
\end{dedalus}

\hspace{5mm}
\begin{dedalus}
p\_pos($A_1,A_2,[...],A_n$),
\end{dedalus}

\hspace{5mm}
$\lnot$
\begin{dedalus}
p\_neg($A_1,A_2,[...],A_n$);
\end{dedalus}

\noindent If, at any time $k$, we have a fact
\dedalus{p\nega($\overline{C}$)@k}, then we do not deduce a
\dedalus{p\pos($\overline{C}$)@k+1} fact.  Furthermore, we do not deduce a
\dedalus{p\pos($\overline{C}$)@j} fact for any $j > k$, unless this
\dedalus{p\pos} fact is re-derived at some timestep $j > k$ by another rule.
This corresponds to the intuition that a persistent fact, once stated, is true
until it is retracted.

%%\newtheorem{example}{Example}
\begin{example}
Consider the following \lang instance:\rcs{introduce p predicate?}

%%p\pos(A, B) \(\leftarrow\) p(A, B);
\begin{Dedalus}
p\pos(A, B)@next \(\leftarrow\) p\pos(A, B), \(\lnot\)p\nega(A, B);

p(1,2)@101;
p(1,3)@102;
p\nega(1,2)@300;
\end{Dedalus}

It is easy to see that the following facts are true: \dedalus{p(1,2)@200},
\dedalus{p(1,3)@200}, \dedalus{p(1,3)@300}.  However, \dedalus{p(1,2)@301} is
false because it was ``deleted'' at timestep \dedalus{300}.
\end{example}

Since mutable persistence occurs frequently in practice, we provide the
\dedalus{persist} template, which takes two arguments: a predicate name and
its arity.  The macro expands to the corresponding mutable persistence rule,
and rewrites the current program in such a way that any references to the given
predicate (say \dedalus{p}) in rule bodies or heads are replaced by references
to its positive relation (e.g., \dedalus{p\_pos}), except for references in the
head of a rule which prefix \dedalus{p} with the distinguished \dedalus{delete}
keyword---these are replaced with \dedalus{p\_neg}.  The above
\dedalus{p\_pos} persistence rule may be equivalently specified as
\dedalus{persist[p,  2]}.

Mutable persistence rules enable {\em updates}.  For some time $\DT$, an update
is any pair of facts:

\begin{dedalus}
p\nega($\overline{C})@\DT;$
\end{dedalus}

\begin{dedalus}
p\pos($\overline{D})@\DT+1$;
\end{dedalus}


\noindent Intuitively, an update represents deleting an old value of a
tuple and inserting a new value.  Every update is {\em atomic across
  timesteps}, meaning that the old value exists during timestep $\DT$
when the new value is derived.  During the evaluation of timestep
$\DT+1$ the new value exists, and the old does not.

\subsubsection{Assignment and Committed Choice}

The assignment primitive provided by most imperative languages is a special case
of update without deletion.  We can model the (destructive) assignment of sets
of values to keys in the following way:

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) condition(A, B);
log(A, B)@next \(\leftarrow\) log(A, B), \(\lnot\)condition(A, _);
\end{Dedalus}

The pair of rules above will cause {\em log} to associate with $A$ the ``most
recent'' set of $B$ values appearing in {\em condition}.  If {\em condition(A,
B)} respects the functional dependency $A \to B$, then \dedalus{log} will
associate only the ``most recent'' $B$ value with each $A$.

The mirror image of assignment is committed choice~\cite{committedchoice},
which associates the first
value(s) of $B$ with $A$.  Committed choice ``seals'' the value of \dedalus{B} such that ``future''
insertions into \dedalus{condition} cannot cause new rows with the same
\dedalus{A} value to be inserted.

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) log(A, B);
log(A, B)@next \(\leftarrow\) condition(A, B), \(\lnot\)log(A, _);
\end{Dedalus}
%%\subsection{``At Most Once'' event relations}

Assignment and committed choice implement ``last write wins'' and 
``first write wins'' semantics, respectively.

\subsubsection{``At Most Once``}
A common requirement for programs with side-effects outside the control
of the system is ensuring that certain events occur ``at most once.''
Consider a requirement for our shopping cart application 
that only a single checkout response should be generated, even if subsequent
inputs cause the totals to be recalculated.  Hence we want to ensure that the
predicate {\em response} ``fires'' only once, regardless of the number of times 
that {\em status} fires.  This feature can be expressed as a 
specialization of the committed choice pattern.   

\begin{Dedalus}
response(Cli, Ses, Item, Amt) \(\leftarrow\)
  amo\_event(Cli, Ses, Item, Amt);

amo\_event(Cli, Ses, Item, Amt) \(\leftarrow\)
  status(Cli, Ses, Item, Amt), 
  \(\lnot\) amo\_log(Cli, Ses, Item, _);

amo\_log(Cli, Ses, Item, Amt)@next \(\leftarrow\) 
  amo\_event(Cli, Ses, Item, Amt);

amo\_log(Cli, Ses, Item, Amt)@next \(\leftarrow\) 
  amo\_log(Cli, Ses, Item, Amt);
\end{Dedalus}

In the subprogram above, the (immutable) predicate {\em amo\_log} serves as a guard
for the predicate {\em amo\_event}, which is true only for the ``first'' assignment
of an $Amt$ value to a grouping of client, session and item identifiers.  Subsequent
occurrences of the {\em status} event for the same group will never fire the second rule.

%But perhaps surprisingly,
%``closing a world'' in this fashion ensures that \dedalus{log} has strictly
%monotonic behavior in all models
%\wrm{commenting out fancy pants diction, so neil doesn't have to}

\paa{introduce 'at most once' as a specialization of committed choice, and
present the macro, which expands to a table (say foo), a log (foo\_log) and an
event (foo\_event) which occurs once if foo occurs at all.}

\subsection{Order in Logic}

\paa{some intro text: pure logic has no notion of order.  distributed systems programming
frequently requires ordering constructs to cope with indeterminacy in message ordering
and to achieve synchronization}

\noindent{}In an asynchronous system, the programmer will in general not be able to
predict when, or in what order, events arrive from other nodes.  When the timing and 
ordering of message arrival affects program results, it may be necessary to instrument
programs with constructs that preserve or restore order at communication boundaries,
or to ensure that simultaneous arrival of messages has the same effect as serial arrival.

\subsubsection{Priority Queues}

\paa{whack this ponderous subsection.  present instead \emph{serializers},
which do what so-called queues below do: enforce 'associativity' by preventing
more that one tuple from being considered per fixpoint.  then present
\emph{ordered queues} (or perhaps the same thing with a better name)
after the discussion of sequences (since OQs use sequences), as a mechanism
for maintaining ordering across async boundaries (familiar from TCP, fifo broadcast,
etc)}

%\paa{shorten this section} While a sequence is a useful construct for
%generating or imposing an ordering on tuples \wrm{seems a bit fishy.  seems
%like it might only be useful for transferring a given order thru async,
%assuming the tuples are already ordered at sender. plus, seqs appears after
%this now}, 

\wrm{i think this might be the wrong way to present queues.  queues don't
necessarily guarantee that ``all things of priority X happen before all things
of priority Y>X''.  the two high order bits of queues are: they prevent things
of different priorities from simultaneously executing, and they enforce kind of
a loose order ``dequeue the lowest priority thing i have thus far''.  ordering
by itself isn't a high-order bit though, because i can sort in one stratum.
it's more this ``online loose order'' which is important.  didn't want to do
too much damage to this section, so i didn't rewrite it yet to conform with
this.}

Some programs will require tuples to be processed in a particular (partial)
data-dependent order, rather than all-at-once, as a set.  For example,
consider a predicate \dedalus{priority\_queue} that represents a series of
tasks.
%to be performed in some predefined order.
Its attributes are two strings---a user and a job---and an integer indicating
the priority of the job in the queue:

\begin{Dedalus}
priority\_queue('bob', 'bash', 200)@123;
priority\_queue('eve', 'ls', 1)@123;
priority\_queue('alice', 'ssh', 204)@123;
priority\_queue('bob', 'ssh', 205)@123;
\end{Dedalus}

A program may desire to serialize the jobs, despite the coincidence of the
\dedalus{priority\_queue} events in logical time.

%Depending on the program that implements the balance update, several behaviors
%are possible.
%Given this schema, we note that a program would likely want to process
%\dedalus{priority\_queue} events individually in a data-dependent order, in
%spite of their coincidence in logical time.  

%%It is difficult to express general
%%in-order tuple processing in Datalog, in part because the language does not
%%admit sequences.  \jmh{Huh?  I don't see the last clause there.  Maybe say simply that Datalog is set-oriented, but what we want here is precisely to impose an ordering on the elements of the set, which seems unnatural.  There's maybe a connection to expressibility and aggregation or arithmetic or something, but let's not try to sort that out for now.}
%above is really what we want to say, right? -wrm
%has so
%notion of order of evaluation (except the implicit ordering implied by
%stratification).

In the program below, \dedalus{priority\_queue} stores the current contents of
the queue at any given time.  The queue must persist across timesteps, as
multiple timesteps may be necessary to drain the queue.  At each timestep, for
each value of \dedalus{A}, all tuples of minimum priority are stored in
\dedalus{priority\_queue\_out} and deleted (atomic with the storage).  Note
that this will change the value of the aggregate calculated at the subsequent
timestamp, assuming no new tuples are inserted at the next timestamp with a
just-dequeued priority:

\begin{Dedalus}
persist[priority\_queue, 3]

// find the min priorities
omin(A, min<C>) \(\leftarrow\)
  priority\_queue(A, _, C);

// output min priority elements
priority_queue_out(A, B, C)@next \(\leftarrow\)
  priority\_queue(A, B, C), omin(A, C);

// delete min priority elements
delete priority\_queue(A, B, C) \(\leftarrow\)
  priority\_queue(A, B, C), omin(A, C);
\end{Dedalus}

In this example, deductive rules that depend on \dedalus{priority\_queue\_out}
are constrained to consider only min-priority tuples at each timestep per value
of the variable \dedalus{A}, thus implementing a per-user FIFO discipline.  To
enforce a FIFO ordering over all users, we may remove the \dedalus{A} column
from \dedalus{omin}.

%A queue establishes a functional dependency between a \lang timestamp and a
%given priority.

By doing so, we take advantage of the monotonic property of timestamps to enforce an ordering property over our input that is otherwise 
very difficult to express in a logic language.
%We return to this idea in our discussion of temporal ``entanglement'' Section~\ref{sec:entangle}.

%Priority queues were developed in a similar fashion in~\cite{greedybychoice}.

\subsubsection{Entanglement}
\label{sec:entangle}

It is sometimes necessary to {\em entangle} the \dedalus{successor} relation
with attributes other than the time suffix, for example to express unbounded
sequences, or to establish a global order (such as through Lamport Clocks).
Consider the asynchronous rule below:

\begin{Dedalus}
p(A, B, N)@async \(\leftarrow\)
  q(A, B)@N;
\end{Dedalus}
\noindent

Due to the \dedalus{async} keyword in the rule head, each \dedalus{p} tuple
will take some unspecified time suffix value.  Note however that the time
suffix \dedalus{N} of the rule body appears also in an attribute of \dedalus{p}
other than the time suffix, recording a binding of both the time value of the
deduction and the time value of its consequence.  We call such a binding an
{\em entanglement}.   Note that in order to write the rule it is necessary to
not sugar away the time suffix in the rule body.  

\rcs{the above discussion obscures a crucial detail: entanglement doesn't allow arbitrary access to the timestamp.  Instead, it provides a one way information flow ``out of'' the timestamp field}

\subsubsection{Sequences}
%\wrm{Maybe somehow work in the fact that sequences are really about preserving
%an already-established order (at a sender) through asynchrony at the receiver.
%Connect to entanglement}

One may represent a sequence---an object that maintains a monotonically
increasing counter value---with a pair of inductive rules.  One rule
increments the current counter value when some condition is true, while the
other persists the value of the sequence when the condition is false.  We can
capture the increase of the sequence value without using arithmetic by
entangling \dedalus{successor}:

\begin{Dedalus}
seq(B)@next \(\leftarrow\) seq(A), successor(A,B), event(_);  
seq(A)@next \(\leftarrow\) seq(A), \(\lnot\)event(_);
\end{Dedalus}

\noindent Note that these two rules produce only a single value of
\dedalus{seq} at each timestep---assuming that the sequence was originally
instantiated with a single value---but they do so in a manner slightly
different than our standard persistence template.

Sequences are useful in general for preserving an established ordering on a set
when communicating between nodes.  As a shorthand we provide the {\em sequence}
macro, which takes three arguments (sequence name, a ``trigger'' predicate
which, when true, should cause the sequence to be incremented, and the
trigger's arity) and expands them to a pair of definitions of a unary predicate
like the one defined above (e.g., \dedalus{sequence[seq, event, 1]}).

\subsubsection{Lamport Clocks}
\label{sec:lamport}
%\wrm{Clean this up and make it jibe better with sec 5}
%Recall that asynchrony allows program executions to order message timestamps
%arbitrarily, violating intuitive notions of causality by allowing deductions to
%``affect the past.'' This section explains how to implement Lamport
%clocks~\cite{timeclocks} atop \lang, which allows programs to ensure temporal
%monotonicity by reestablishing a causal order despite derivations that flow
%backwards through time.  \wrm{we haven't yet introduced stratification and all
%that.  maybe there's some better way to write the above, like ``it is often
%nice to have a global partial order for X reasons''.  then later, we can say
%``aha! a majorly important utility of a global partial order is to avoid
%contradiction.}
It is often necessary to ensure some loose synchronization between clocks of
different nodes in an asynchronous distributed system.  One way to do this is
through Lamport clocks~\cite{timeclocks}.

Consider a rule \dedalus{p(A,B)@async \(\leftarrow\) q(A,B)}.  By rewriting it
to:

\begin{Dedalus}
persist[p, 2]
p\_wait(A, B, N)@async \(\leftarrow\) q(A, B)@N;
p\_wait(A, B, N)@next \(\leftarrow\) p\_wait(A, B, N)@M, N \(\ge\) M;
p(A, B)@next \(\leftarrow\) p\_wait(A, B, N)@M, N < M;
\end{Dedalus}

\noindent we place the derived tuple in a new relation \dedalus{p\_wait} that
stores any tuples that were ``sent from the future,'' according to their
entangled time; these tuples stay in the \dedalus{p\_wait} predicate until the
point in time at which they were derived.  
%Conceptually, this causes the system to evaluate a potentially large number of
%timesteps (if N is significantly less than the timestamp of the system when
%the tuple arrives).  However, if the runtime is able to efficiently evaluate
%timesteps when the database is quiescent, then instead of ``waiting'' by
%evaluating timesteps, it will simply increase its logical clock to match that
%of the sender.  \wrm{don't think we need to be getting into the efficiency of
%evaluation of the language this early...} In contrast, if the tuple is ``sent
%into the future,'' then it is processed using the timestep that receives it.
%\wrm{yes!  we delete the above thing about efficiency, and just keep the
%below}
This manipulation of timesteps and clock values is equivalent to conventional
descriptions of Lamport clocks, except that our Lamport clock implementation
effectively ``advances the clock'' by preventing derivations until the clock is
sufficiently advanced, by temporarily storing incoming tuples in the
\dedalus{p\_wait} relation.\footnote{For ease of exposition, we elide one
detail here: Lamport clocks rely upon a ``tie-breaking'' function to ensure
that no two events have the same timestamp.  We can implement such a discipline
using queues.}

Although annotating a program execution with logical clock values has
a number of practical runtime applications (such as debugging), in our
setting it is primarily useful as a way to reconcile physical
constraints (a given program execution on real hardware will obey
causality) with our expressive language model (which is able to model
temporal paradoxes).  Crucially, we do so in a purely logical manner,
without resorting to imperative constructs outside of Datalog.  In
Section~\rcs{sec:fixme}, we take this idea a step further, and explain
how \lang programs can be restricted to treat events as serializable
transactions.  This allows us to model well-studied runtime
optimizations such as parallelizing compilers and database lock
managers with little additional complexity.

\paa{clean up, and cite netdb and the TR as examples of more complicated
synchronization constructs expressible in logic (consensus and reliable broadcast,
respectively)}

%\wrm{why can't
%we just combo a Lamport clock with a priority queue?  i don't think we need
%choice here, so i commented it out.}
%In \lang, such a function could be implemented via another use of
%\dedalus{choice}, or by a program convention like appending a unique node
%identifier to each timestamp to prevent ``ties.''

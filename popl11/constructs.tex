\section{State in Logic}
\label{sec:stateupdate}


%%\linebreak
\begin{quote}
%
\emph{Time is a device that was invented to keep everything from
happening at once.}\footnote{Graffiti on a wall at Cambridge
University~\cite{scheme}.}
%
\end{quote} 

Given our definition of \lang, we now address the persistence and mutability
of data across time---one of the two signature features of distributed systems
for which we provide a model-theoretic foundation. \wrm{we need to sync this up with the intro}

The intuition behind \lang's \dedalus{successor} relation is that it models the
passage of (logical) time.  In our discussion, we will say that ground atoms
with lower time suffixes occur ``before'' atoms with higher ones.
The constraints we imposed on \lang rules restrict how deductions may be made
with respect to time.  First, rules may only refer to a single time suffix variable in
their body, and hence {\em cannot join across different ``timesteps''}.  Second, rules may specify
deductions that occur concurrently with their ground facts or in the next
timestep---in \lang, we rule out induction ``backwards'' in time or
``skipping'' into the future. \wrm{async stuff skips into the future}

This notion of time allows us to consider the contents of the EDB---and hence
a minimal model of the IDB \wrm{IDB not defined}---with respect to an ``instant in time'': we simply
bind the time suffixes ($\DT$) of all body predicates to a constant.  Because
this produces a sequence of models (one per timestep), it gives us an intuitive
and unambiguous way to declaratively express persistence and state changes
across time.  In this section, we give examples of language constructs
that capture state-oriented motifs such as persistent relations,
deletion and update, sequences, and queues.

\subsection{Order}

\subsubsection{Simple Persistence}
A fact in predicate $p$ at time $\DT$ may provide ground for deductive rules
at time $\DT$, but may only provide ground for deductive rules in timesteps greater than $\DT$,
if it is persisted.  One way to persist all facts in a predicate $p$ is to use a {\em simple persistence rule}:

\dedalus{p\pos($A_1$,$A_2$,[...],$A_n$)@next $\leftarrow$
p\pos($A_1$,$A_2$,[...],$A_n$);}

\noindent
A rule of this form ensures that a $p$ fact true at time $i$ will be true $\forall j \in \mathbb{N} : j >= i$.


\subsubsection{Mutable State}
\label{sec:mutable}

Simple persistence rules cannot model deletions and updates of a fact, because
they express an unbroken induction over time.  One way to allow the induction to be
broken is to add a \dedalus{p\nega} subgoal to the body of a
simple persistence rule:

\begin{dedalus}
p\_pos($A_1,A_2,[...],A_n$)@next $\leftarrow$
\end{dedalus}

\hspace{5mm}
\begin{dedalus}
p\_pos($A_1,A_2,[...],A_n$),
\end{dedalus}

\hspace{5mm}
$\lnot$
\begin{dedalus}
p\_neg($A_1,A_2,[...],A_n$);
\end{dedalus}

\noindent
If, at any time $k$, we have a fact
\dedalus{p\nega($\bar{C}$)@k}, then we do not deduce a
\dedalus{p\pos($\bar{C}$)@k+1} fact.  By induction, we do not
deduce a \dedalus{p\pos($\bar{C}$)@j} fact for any $j > k$, unless
this \dedalus{p\pos} fact is re-derived at some timestep $j > k$ by another
rule.  This corresponds to the intuition that a persistent fact, once stated,
is true until it is retracted.

%%\newtheorem{example}{Example}
\wrm{we can cut this example if we're out of space}
\begin{example}
Consider the following \lang program and ground facts:

%%p\pos(A, B) \(\leftarrow\) p(A, B);
\begin{Dedalus}
p\pos(A, B)@next \(\leftarrow\) p\pos(A, B), \(\lnot\)p\nega(A, B);

p(1,2)@101;
p(1,3)@102;
p\nega(1,2)@300;
\end{Dedalus}

It is easy to see that the following facts are true: \dedalus{p(1,2)@200},
\dedalus{p(1,3)@200}, \dedalus{p(1,3)@300}.  However, \dedalus{p(1,2)@301} is
false because it was ``deleted'' at timestep \dedalus{300}.
\end{example}

\wrm{is ``macro'' the right term?  seems a bit hacky}
Since mutable persistence occurs frequently in practice, we provide the {\em
persist} macro, which takes 
two arguments: a predicate name and its arity. 
The macro
expands to the corresponding mutable persistence rule, and rewrites the current program
in such a way that any references to the given predicate (say \emph{p}) in rule bodies or heads are replaced by references
to its positive relation (e.g. \emph{p\_pos}), except for rules in which the keyword \emph{delete} \wrm{we need to explain this better}
appears before \emph{p} in the head, which are replaced with \emph{p\_neg}.  For example, the above
\dedalus{p\_pos} persistence rule may be equivalently specified as
\dedalus{persist[p,  2]}.

Mutable persistence rules enable {\em updates}.  For some time $\DT$, an
update is any pair of facts:

\begin{dedalus}
p\nega($\bar{C})@\DT;$
\end{dedalus}

\begin{dedalus}
p\pos($\bar{D})@\DT+1$;
\end{dedalus}


\noindent
Intuitively, an update represents deleting an old value of a tuple and
inserting a new value.  Every update is {\em atomic across timesteps}, meaning
that the old value ceases to exist at the same timestep in which the new value
is derived---timestep $\DT+1$ in the above definition.

\subsubsection{Assignment and Committed Choice}

The assignment primitive provided by most imperative languages is a special 
case of update without deletion.  We may very simply model the (destructive) assignment 
of sets of values to keys in the following way:

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) condition(A, B);
log(A, B)@next \(\leftarrow\) log(A, B), \(\lnot\)condition(A, _);
\end{Dedalus}

The pair of rules above will cause {\em log} to associate with $A$ the ``most recent'' set of
$B$ values appearing in {\em condition}.  If {\em condition(A, B)} respects the functional dependency $A \to B$, then
\dedalus{log} will associate only the ``most recent'' $B$ value with each $A$.

The mirror image of assignment is committed choice, which associates the first value(s)
of $B$ with $A$:

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) log(A, B);
log(A, B)@next \(\leftarrow\) condition(A, B), \(\lnot\)log(A, _);
\end{Dedalus}
%%\subsection{``At Most Once'' event relations}

Committed choice uses a fundamentally nonmonotonic \wrm{we never define monotonic vs non-mnotonic!!} construct -- self-negation --
to ``seal'' the value of $B$ such that ``future'' insertions into {\em condition} cannot
cause new rows with the same $A$ value to be inserted.  But perhaps surprisingly,
``closing a world'' in this fashion ensures that {\em log} has strictly monotonic 
behavior in all models \wrm{thsi might confuse people without precise definitions}.

\subsubsection{Queues}

\paa{shorten this section}
While sequences are useful constructs for generating or imposing an ordering on tuples, programs will in some cases require that tuples
are processed in a particular (partial) order.  To this end, we introduce a queue template, which employs 
inductive persistence and aggregate functions in rule heads to process tuples according to a data-dependent order, rather than as a set.  Aggregate functions simplify our discussion of queues.  

Consider a predicate \dedalus{priority\_queue} that represents a series of tasks to be performed in some predefined order.  Its attributes are a string representing a user, a job, and an integer
indicating the priority of the job in the queue:

\begin{Dedalus}
priority\_queue('bob', 'bash', 200)@123;
priority\_queue('eve', 'ls', 1)@123;
priority\_queue('alice', 'ssh', 204)@123;
priority\_queue('bob', 'ssh', 205)@123;
\end{Dedalus}

Observe that all the time suffixes are the same.  
%Depending on the program that implements the balance update, several behaviors
%are possible.
Given this schema, we note that a program would likely want to process
\dedalus{priority\_queue} events individually in a data-dependent order, in
spite of their coincidence in logical time.  

%%It is difficult to express general
%%in-order tuple processing in Datalog, in part because the language does not
%%admit sequences.  \jmh{Huh?  I don't see the last clause there.  Maybe say simply that Datalog is set-oriented, but what we want here is precisely to impose an ordering on the elements of the set, which seems unnatural.  There's maybe a connection to expressibility and aggregation or arithmetic or something, but let's not try to sort that out for now.}
%above is really what we want to say, right? -wrm
%has so
%notion of order of evaluation (except the implicit ordering implied by
%stratification).

In the program below, we define a table \dedalus{m\_priority\_queue} that
serves as a queue to feed \dedalus{priority\_queue}.  The queue must persist
across timesteps because it may take multiple timesteps to drain it.  At each
timestep, for each value of \textbf{A}, a single tuple is projected into
\dedalus{priority\_queue} and deleted (atomic with the projection) from
\dedalus{m\_priority\_queue}, changing the value of the aggregate calculated
at the subsequent step:

\begin{Dedalus}
persist[m\_priority\_queue, 3]

% find the min priority
omin(A, min<C>) \(\leftarrow\)
  m\_priority\_queue(A, _, C);

% feed p in the next step 
% with the items of min priority
priority_queue(A, B, C)@next \(\leftarrow\)
  m\_priority\_queue(A, B, C), omin(A, C);

% delete from the next step 
% those items of min priority
delete m\_priority\_queue(A, B, C) \(\leftarrow\)
  m\_priority\_queue(A, B, C), omin(A, C);
\end{Dedalus}

Under such a queueing discipline, deductive rules that depend on
\dedalus{priority\_queue} are constrained to consider only min-priority tuples at each timestep
per value of the variable \textbf{A}, thus implementing a per-user \wrm{whats a user?} FIFO
discipline.  To enforce a global FIFO ordering over \dedalus{priority\_queue}, we
may redefine \dedalus{omin} and any dependent rules to exclude the \textbf{A}
attribute.

A queue establishes a mapping between \lang's timesteps
and the priority-ordering attribute of the input relation. By doing so, we take advantage of the monotonic property of timestamps to enforce an ordering property over our input that is otherwise 
very difficult to express in a logic language.  
We return to this idea in our discussion of temporal ``entanglement'' Section~\ref{sec:entangle}.  \wrm{improve hte connection with entanglement}

\wrm{greco and zaniolo also have a take on priority queues.  cite them here.}

\subsubsection{Entanglement}
\label{sec:entangle}
It is sometimes necessary to {\em entangle} the \dedalus{successor} relation with attributes
other than the time suffix, for example to express unbounded sequences, or to establish
a global order (such as through Lamport Clocks).  Consider the asynchronous rule below:

\begin{Dedalus}
p(A, B, N)@async \(\leftarrow\)
  q(A, B)@N;
\end{Dedalus}
\noindent

Due to the \dedalus{async} keyword in the rule head, each \emph{p} tuple will take some unspecified time suffix value.
Note however that the time suffix $N$ of the rule body appears also in an attribute of \emph{p} other than the time suffix, recording a 
binding of both the time value of the deduction and the time value of its consequence.  We call such a binding
an \emph{entanglement}.   Note that in order
to write the rule it is necessary to not sugar away the time suffix in the rule body.  

\subsubsection{Sequences}
One may represent a sequence--an object that maintains a monotonically increasing a counter value--with a pair of inductive rules.  One rule increments the current counter value when some condition is 
true, while the other persists the value of the sequence when the condition is false.  We can capture the increase
of the sequence value without using arithmetic, by entangling \dedalus{successor}:

\begin{Dedalus}
seq(B)@next \(\leftarrow\) seq(A), successor(A,B), event(_);  
seq(A)@next \(\leftarrow\) seq(A), \(\lnot\)event(_);
\end{Dedalus}

\noindent
Note that these two rules produce only a single value of \dedalus{seq} at each timestep -- assuming that the sequence was originally instantiated with a single value -- but they do so in a manner slightly different than our standard persistence template.

The use of sequences is often fairly canonical, so as a shorthand we provide the {\em sequence}
macro, which takes three arguments (sequence name, a ``trigger'' predicate which, when true, 
should cause the sequence to be incremented, and the trigger's arity) and expands them to a pair 
of definitions of a unary predicate like the one defined above (e.g., \dedalus{sequence[seq, event, 1]}.

\subsubsection{Lamport Clocks}
\label{sec:lamport}

Recall that \lang allows program executions to order message timestamps arbitrarily, violating intuitive notions of causality by allowing deductions to ``affect the past.''
This section explains how to implement Lamport
clocks~\cite{timeclocks} atop \lang, which allows programs to ensure
temporal monotonicity by reestablishing a causal order
despite derivations that flow backwards through time.
\wrm{we haven't yet introduced stratification and all that.  maybe there's some better way to write the above, like ``it is often nice to have a global partial order for X reasons''.  then later, we can say ``aha! a majorly important utility of a global partial order is to avoid contradiction.}

Consider a rule \dedalus{p(A,B)@async \(\leftarrow\) q(A,B)}.  By
rewriting it to:

\begin{Dedalus}
persist[p, 2]
p\_wait(A, B, N)@async \(\leftarrow\) q(A, B)@N;
p\_wait(A, B, N)@next \(\leftarrow\) p\_wait(A, B, N)@M, N \(\ge\) M;
p(A, B)@next \(\leftarrow\) p\_wait(A, B, N)@M, N < M;
\end{Dedalus}
\noindent
we place the derived tuple in a new relation \dedalus{p\_wait} that
stores any tuples that were ``sent from the future,'' according to their entangled time; these tuples stay in the \dedalus{p\_wait} predicate until the point in
time at which they were derived.  Conceptually, this causes the system
to evaluate a potentially large number of timesteps (if N is
significantly less than the timestamp of the system when the tuple
arrives).  However, if the runtime is able to efficiently evaluate
timesteps when the database is quiescent, then
instead of ``waiting'' by evaluating timesteps, it will simply
increase its logical clock to match that of the sender.  \wrm{don't think we need to be getting into the efficiency of evaluation of the language this early...} In contrast,
if the tuple is ``sent into the future,'' then it is processed using
the timestep that receives it.

\wrm{yes!  we delete the above thing about efficiency, and just keep the below}
This manipulation of timesteps and clock values is equivalent to
conventional descriptions of Lamport clocks, except that our Lamport
clock implementation effectively ``advances the clock'' by preventing derivations until the clock is sufficiently advanced, by temporarily store incoming tuples
in the \dedalus{p\_wait} relation.

We gloss over one detail here: Lamport clocks rely
upon a ``tie-breaking'' function to ensure that no two events have the
same timestamp.  
\wrm{why can't we just combo a Lamport clock with a priority queue?  i don't think we need choice here, so i commented it out.}
%In \lang, such a function could be implemented via another use of \dedalus{choice}, or by a program convention like
%appending a unique node identifier to each timestamp to prevent ``ties.''

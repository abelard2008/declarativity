\section{Time, State and Order}
\label{sec:stateupdate}

%%\linebreak
\begin{quote}
%
\emph{Time is a device that was invented to keep everything from
happening at once.}\footnote{Graffiti on a wall at Cambridge
University~\cite{scheme}.}
%
\end{quote} 

%Recall that by an event, we mean a \lang fact.
%The transitive consequences
%(via deductive rules) of events are likewise events and hold atomically in the
%same timestep with their premises.  However,

As we showed in the previous section, logical time may be used as a 
``source of monotonicity'' to restore a meaningful, temporal interpretation to otherwise
semantically ambiguous constructs like updateable state and orderly processing.  
Many common motifs in systems programming
(distributed and otherwise) follow a similar pattern of restricted nonmonotonicity, in 
which consequences of deductions are deferred in time.  In this section, we demonstrate
the expressivity of \lang by building a collection of stateful and orderly constructs,
most of which employ the careful use of nonmonotonic reasoning deferred in time.
We also introduce a convenience notation in the form of a simple macro language
for many of these common patterns.

%%\noindent{}In an asynchronous system, the programmer will in general not be able to
%%predict when, or in what order, events arrive from other nodes.  Additionally,
%%some events may need to be handled over time \jmh{vague}, requiring state-oriented motifs
%%such as persistence and mutability.  In this section, we construct a library of
%%\lang constructs to capture these two uses of order.

%Given our definition of \lang, we now address the persistence and mutability
%of data across time: a signature feature of distributed systems---and systems
%in general.
%---for which we provide a model-theoretic foundation.

%The intuition behind \lang's \dedalus{successor} relation is that it models the
%passage of (logical) time.  In our discussion, we will say that facts with
%lower time suffixes occur ``before'' atoms with higher ones.  The constraints
%we imposed on \lang rules restrict how deductions may be made with respect to
%time.  First, rules may only refer to a single time suffix variable in their
%body, and hence {\em cannot join across different ``timesteps''}.  Second,
%rules may specify deductions that occur concurrently with their ground facts,
%\wrm{define ground fact somewhere} in the next timestep, or at some arbitrary
%time, including times before their ground facts.

%This notion of time allows us to consider the contents of the EDB---and hence
%a model of an instance---with respect to an ``instant in time'': we simply
%bind the time suffixes ($\DT$) of all body predicates to a constant.  Because
%this produces a sequence of models (one per timestep), it gives us an intuitive
%and unambiguous way to declaratively express persistence and state changes
%across time.  In this section, we give examples of language constructs
%that capture state-oriented motifs such as persistent relations,
%deletion and update, sequences, and queues.

\subsection{State in Logic}

%%\jmh{Back this up with formalism: can't do a flip/flop in Datalog (Chandra/Harel, right?).  This %%discussion does tee up the question of whether something more traditional like Datalog-neg %%would have been enough for us ... might be sufficient to simply toss in a result about Turing %%completeness of Dedalus.  I realize your point here is more practically-minded and illustrative, %%but then maybe this intro is off target for this section.  Still I think an expressivity subsection %%in the paper would be nice.}


Logic languages naturally model the accumulation of information: deduction in 
the broadest sense tells us, given what we already know, what follows from it.  However, systems
programming frequently requires us to model information that may disappear or change
over time.  In this section we model persistence, both immutable and dynamic, as
\emph{induction} over time, and provide a convenience notation for declaring certain
relations as ``persistent.''


\subsubsection{Simple Persistence}
%
A fact in predicate $p$ at time $\DT$ may provide ground for deductive rules at
time $\DT$, but may only provide ground for deductive rules in timesteps
greater than $\DT$ if it is persisted.  One way to persist all facts in a
predicate $p$ is to use a {\em simple persistence rule}:
\paa{wants a permanent macro}

\dedalus{p($A_1$,$A_2$,[...],$A_n$)@next $\leftarrow$
p($A_1$,$A_2$,[...],$A_n$);}

\noindent A rule of this form ensures that a $p$ fact true at time $i$ will be
true $\forall j \in \mathbb{N} : j >= i$.


\subsubsection{Mutable State}
\label{sec:mutable}

Simple persistence rules cannot model deletions and updates of a fact, because
they express an unbroken induction over time.  One way to allow the induction
to be broken is to add a \dedalus{p\nega} 
%%\wrm{\dedalus{p\nega} not defined} 
subgoal to the body of a simple
persistence rule:

\begin{dedalus}
p($A_1,A_2,[...],A_n$)@next $\leftarrow$
\end{dedalus}

\hspace{5mm}
\begin{dedalus}
p($A_1,A_2,[...],A_n$),
\end{dedalus}

\hspace{5mm}
$\lnot$
\begin{dedalus}
p\_neg($A_1,A_2,[...],A_n$);
\end{dedalus}

\noindent If, at any time $k$, we have a fact
\dedalus{p\nega($\overline{C}$)@k}, then we do not deduce a
\dedalus{p($\overline{C}$)@k+1} fact.  Furthermore, we do not deduce a
\dedalus{p($\overline{C}$)@j} fact for any $j > k$, unless this
\dedalus{p} fact is re-derived at some timestep $j > k$ by another rule.
This corresponds to the intuition that a persistent fact, once stated, is true
until it is retracted.

%%\newtheorem{example}{Example}
\begin{example}
Consider the following \lang instance:\rcs{introduce p predicate?}

%%p\pos(A, B) \(\leftarrow\) p(A, B);
\begin{Dedalus}
p(A, B)@next \(\leftarrow\) p(A, B), \(\lnot\)p\nega(A, B);

p(1,2)@101;
p(1,3)@102;
p\nega(1,2)@300;
\end{Dedalus}

It is easy to see that the following facts are true: \dedalus{p(1,2)@200},
\dedalus{p(1,3)@200}, \dedalus{p(1,3)@300}.  However, \dedalus{p(1,2)@301} is
false because it was ``deleted'' at timestep \dedalus{300}.
\end{example}

Since mutable persistence occurs frequently in practice, we provide the
\dedalus{persist} template, which takes two arguments: a predicate name and
its arity.  The macro expands to the corresponding mutable persistence rule,
and rewrites the current program in such a way that any references to the given
predicate in the
head of a rule with the distinguished \dedalus{delete}
keyword---these are replaced with \dedalus{p\_neg}.  The above
persistence rule may be equivalently specified as
\dedalus{persist[p,  2]}.

Mutable persistence rules enable {\em updates}.  For some time $\DT$, an update
is any pair of facts:

\begin{dedalus}
p\nega($\overline{C})@\DT;$
\end{dedalus}

\begin{dedalus}
p($\overline{D})@\DT+1$;
\end{dedalus}


\noindent Intuitively, an update represents deleting an old value of a
tuple and inserting a new value.  Every update is {\em atomic across
  timesteps}, meaning that the old value exists during timestep $\DT$
when the new value is derived.  During the evaluation of timestep
$\DT+1$ the new value exists, and the old does not.

\subsubsection{Assignment and Committed Choice}

The assignment primitive provided by most imperative languages is a special case
of update without deletion.  We can model the (destructive) assignment of sets
of values to keys in the following way:

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) condition(A, B);
log(A, B)@next \(\leftarrow\) log(A, B), \(\lnot\)condition(A, _);
\end{Dedalus}

The pair of rules above will cause {\em log} to associate with $A$ the ``most
recent'' $B$ value appearing in {\em condition}.  If {\em condition(A,
B)} respects the functional dependency $A \to B$, then \dedalus{log} will
associate only the ``most recent'' $B$ value with each $A$.  Otherwise, log may contain contain many $B$ values that tie for ``most recent.''

The mirror image of assignment is committed choice~\cite{committedchoice},
which associates the first
value(s) of $B$ with $A$.  Committed choice ``seals'' the value of \dedalus{B} such that ``future''
insertions into \dedalus{condition} cannot cause new rows with the same
\dedalus{A} value to be inserted.

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) log(A, B);
log(A, B)@next \(\leftarrow\) condition(A, B), \(\lnot\)log(A, _);
\end{Dedalus}
%%\subsection{``At Most Once'' event relations}

Assignment and committed choice implement ``last write wins'' and 
``first write wins'' semantics, respectively.

\subsubsection{``At Most Once``}
\label{sec:atmostonce}
A common requirement for programs with side-effects outside the control
of the system is ensuring that certain events occur ``at most once.''
Consider a requirement for our shopping cart application 
that only a single checkout response should be generated, even if subsequent
inputs cause the totals to be recalculated.  Hence we want to ensure that the
predicate {\em response} ``fires'' only once, regardless of the number of times 
that {\em status} fires.  This feature can be expressed as a 
specialization of the committed choice pattern.   

\begin{Dedalus}
response(Cli, Ses, Item, Amt) \(\leftarrow\)
  amo\_event(Cli, Ses, Item, Amt);

amo\_event(Cli, Ses, Item, Amt) \(\leftarrow\)
  status(Cli, Ses, Item, Amt), 
  \(\lnot\) amo\_log(Cli, Ses, Item, _);

amo\_log(Cli, Ses, Item, Amt)@next \(\leftarrow\) 
  amo\_event(Cli, Ses, Item, Amt);

amo\_log(Cli, Ses, Item, Amt)@next \(\leftarrow\) 
  amo\_log(Cli, Ses, Item, Amt);
\end{Dedalus}

In the subprogram above, the (immutable) predicate {\em amo\_log} serves as a guard
for the predicate {\em amo\_event}, which is true only for the ``first'' assignment
of an $Amt$ value to a grouping of client, session and item identifiers.  Subsequent
occurrences of the {\em status} event for the same group will never fire the second rule.

As a shorthand, we will make use of a {\em commitfirst} macro, which takes as arguments a name,
an arity and an integer representing the prefix of the tuple attributes that constitute the
``key'' attributes corresponding to the group that should functionally determine the remaining
attributes.  By convention, these will always precede the ``value'' attributes.  For example,
we can produce the rules above by expanding the declaration \dedalus{commitfirst[amo, 4, 3]}.

%But perhaps surprisingly,
%``closing a world'' in this fashion ensures that \dedalus{log} has strictly
%monotonic behavior in all models
%\wrm{commenting out fancy pants diction, so neil doesn't have to}

\paa{
present the macro, which expands to a table (say foo), a log (foo\_log) and an
event (foo\_event) which occurs once if foo occurs at all.}

\subsection{Order in Logic}
\label{sec:orderinlogic}


\noindent{}In an asynchronous system, the programmer will in general not be able to
predict when, or in what order, events arrive from other nodes.  When the timing and 
ordering of message arrival affects program results, it may be necessary to instrument
programs with constructs that preserve or restore order at communication boundaries,
or to ensure that simultaneous arrival of messages has the same effect as serial arrival.

We chose these examples for their simplicity and illustrative power: they represent primitive
kernels of coordination mechansims.  We have demonstrated elsewhere that robust coordination  {\em protocols}~\cite{netdb, dedalus-techr} are expressible in \lang, but omit these for 
the sake of brevity.

\subsubsection{Serializers}

Some programs will require tuples to be processed in a particular (partial)
data-dependent order, rather than all-at-once, as a set.  Moreover, it is 
common for distributed programs that process messages to be written in
a style that expects only a single message to be received at a time.   This 
is not an issue for imperative languages that explicitly dequeue messages and explicitly schedule their processing.  In distributed logic languages,
failure to account for the (often rare) possibility of simultaneous receipt of messages
can be the source of bugs.

One of the design goals of \lang is to make all semantics manifest and analyzable.
Consider the following program fragment, whose intent is to model the replacement of the 
current {\em status} value with the new values in {\em cart\_action}:

\begin{Dedalus}
status(Location, Session, CartObj) \(\leftarrow\)
    cart_update(Location,  Session, CartObj);
    
delete status(L, S, C) \(\leftarrow\)
    status(L, S, C), cart_update(L, S, _);
\end{Dedalus}

If multiple {\em cart\_action} tuples may be received in a single timestep with the same
values for $L$ and $S$, the intended behavior of updating {\em status} will not be met:
instead, multiple rows with the same values will appear.  Restoring the expected behavior
requires a \emph{serializer}: a program fragment that rules out coincidence in logical time 
for a given predicate.  For example, if we assume that $CartObj$ values are unique to each
tuple and that they come from an ordered domain, we may express a serializer as follows:

\begin{Dedalus}
persist[update_queue, 3]
omin(L, S, min<C>) \(\leftarrow\)
  update_queue(L, S, C);

update_queue_out(L, S, C)@next \(\leftarrow\)
  update_queue(L, S, C), omin(A, C);

delete update_queue(L, S, C) \(\leftarrow\)
  update_queue(L, S, C), omin(A, C);
\end{Dedalus}

In the program fragment above, we indirect {\em cart\_update} tuples through the relation
{\em update\_queue}, which stores the current contents of the ``queue''  at 
any given time.  The predicate must persist across timesteps, as multiple steps may be
necessary to drain it.  At each timestep, the tuple with the minimum value for $Cartobj$
is placed in {\em update\_queue\_out} and atomically removed from {\em update\_queue}.
This changes the value computed by the {\em min} aggregate at the next timestep.
A serializer thus takes advantage of the monotonic property of timestamps to enforce the
orderly processing of external inputs.

We provide the {\em queue} macro as a shorthand, which takes as arguments a name,
an arity and the ordinal of the ordering attribute.
For example, the above code could be generated with the statement 
\dedalus{serializer[update, 3, 0]}.

\begin{comment}
\subsubsection{Priority Queues}

\paa{whack this ponderous subsection.  present instead \emph{serializers},
which do what so-called queues below do: enforce 'associativity' by preventing
more that one tuple from being considered per fixpoint.  then present
\emph{ordered queues} (or perhaps the same thing with a better name)
after the discussion of sequences (since OQs use sequences), as a mechanism
for maintaining ordering across async boundaries (familiar from TCP, fifo broadcast,
etc)}

In the program below, \dedalus{priority\_queue} stores the current contents of
the queue at any given time.  The queue must persist across timesteps, as
multiple timesteps may be necessary to drain the queue.  At each timestep, for
each value of \dedalus{A}, all tuples of minimum priority are stored in
\dedalus{priority\_queue\_out} and deleted (atomic with the storage).  Note
that this will change the value of the aggregate calculated at the subsequent
timestamp, assuming no new tuples are inserted at the next timestamp with a
just-dequeued priority:

\begin{Dedalus}
persist[priority\_queue, 3]

// find the min priorities
omin(A, min<C>) \(\leftarrow\)
  priority\_queue(A, _, C);

// output min priority elements
priority_queue_out(A, B, C)@next \(\leftarrow\)
  priority\_queue(A, B, C), omin(A, C);

// delete min priority elements
delete priority\_queue(A, B, C) \(\leftarrow\)
  priority\_queue(A, B, C), omin(A, C);
\end{Dedalus}

In this example, deductive rules that depend on \dedalus{priority\_queue\_out}
are constrained to consider only min-priority tuples at each timestep per value
of the variable \dedalus{A}, thus implementing a per-user FIFO discipline.  To
enforce a FIFO ordering over all users, we may remove the \dedalus{A} column
from \dedalus{omin}.

%A queue establishes a functional dependency between a \lang timestamp and a
%given priority.

By doing so, we take advantage of the monotonic property of timestamps to enforce an ordering property over our input that is otherwise 
very difficult to express in a logic language.

\end{comment}

\subsubsection{Entanglement}
\label{sec:entangle}

It is sometimes necessary to {\em entangle} the \dedalus{successor} relation
with attributes other than the time suffix, for example to express unbounded
sequences, or to establish a global order (such as through Lamport Clocks).
Consider the asynchronous rule below:

\begin{Dedalus}
p(A, B, N)@async \(\leftarrow\)
  q(A, B)@N;
\end{Dedalus}
\noindent

Due to the \dedalus{async} keyword in the rule head, each \dedalus{p} tuple
will take some unspecified time suffix value.  Note however that the time
suffix \dedalus{N} of the rule body appears also in an attribute of \dedalus{p}
other than the time suffix, recording a binding of both the time value of the
deduction and the time value of its consequence.  We call such a binding an
{\em entanglement}.   Note that in order to write the rule it is necessary to
not sugar away the time suffix in the rule body.  

\rcs{the above discussion obscures a crucial detail: entanglement doesn't allow arbitrary access to the timestamp.  Instead, it provides a one way information flow ``out of'' the timestamp field}

\subsubsection{Sequences}
%\wrm{Maybe somehow work in the fact that sequences are really about preserving
%an already-established order (at a sender) through asynchrony at the receiver.
%Connect to entanglement}

One may represent a sequence---an object that maintains a monotonically
increasing counter value---with a pair of inductive rules.  One rule
increments the current counter value when some condition is true, while the
other persists the value of the sequence when the condition is false.  We can
capture the increase of the sequence value without using arithmetic by
entangling \dedalus{successor}:

\begin{Dedalus}
seq(B)@next \(\leftarrow\) seq(A), successor(A,B), event(_);  
seq(A)@next \(\leftarrow\) seq(A), \(\lnot\)event(_);
\end{Dedalus}

\noindent Note that these two rules produce only a single value of
\dedalus{seq} at each timestep---assuming that the sequence was originally
instantiated with a single value---but they do so in a manner slightly
different than our standard persistence template.

Sequences are useful in general for preserving an established ordering on a set
when communicating between nodes.  As a shorthand we provide the {\em sequence}
macro, which takes three arguments (sequence name, a ``trigger'' predicate
which, when true, should cause the sequence to be incremented, and the
trigger's arity) and expands them to a pair of definitions of a unary predicate
like the one defined above (e.g., \dedalus{sequence[seq, event, 1]}).


\subsubsection{Ordered Queues}
In a completely local execution, the serializer pattern is sufficient to implement a
priority queue:  items inserted into {\em update\_queue} will be dequeued 
according to the data-dependent ordering induced by the $Cartobj$ values.
Maintaining such orderly queueing across asynchronous boundaries is another
matter.  To ensure that a set of tuples sent across the network (and hence potentially 
``scattered'' in logical time) are processed in the correct order requires some synchronization
between sender and receiver.  In the style of FIFO messaging in network protocols, 
we may use a sequence at the receiver to ensure that it ``waits'' 
the necessary amount to ensure totally ordered processing.  Because
sequences operate over integers, we add an integer column to all relations to represent 
the sender's ``intended'' order:

\begin{Dedalus}
persist[update_queue, 4];
sequence[update_seq, del_update_queue, 4);
update_seq(B) \(\leftarrow\) bottom(B);

update(L, S, C, I) \(\leftarrow\)
  update_queue(L, S, C, I),
  update_seq(I);

delete update_queue(L, S, C, I) \(\leftarrow\)
  update(L, S, C, I);
\end{Dedalus}

Note that the sender is thus required not only to establish the ordering of tuples, but
to inform the receiver of the ``bottom'' element, in order to seed the sequence.
Tuples persist in {\em update\_queue} until such time as their $I$ value matches the 
sequence value, at which point they are dequeued, atomically with the incrementation
of the sequence and deletion from the queue relation.  This simple example illustrates
a more general pattern of order preservation across network boundaries.

We provide the macro {\em ordered\_queue}, which takes the same arguments as the serializer macro; e.g., \dedalus{ordered\_queue[update, 4, 3]}.

%Priority queues were developed in a similar fashion in~\cite{greedybychoice}.


\subsubsection{Lamport Clocks}
\label{sec:lamport}
%\wrm{Clean this up and make it jibe better with sec 5}
%Recall that asynchrony allows program executions to order message timestamps
%arbitrarily, violating intuitive notions of causality by allowing deductions to
%``affect the past.'' This section explains how to implement Lamport
%clocks~\cite{timeclocks} atop \lang, which allows programs to ensure temporal
%monotonicity by reestablishing a causal order despite derivations that flow
%backwards through time.  \wrm{we haven't yet introduced stratification and all
%that.  maybe there's some better way to write the above, like ``it is often
%nice to have a global partial order for X reasons''.  then later, we can say
%``aha! a majorly important utility of a global partial order is to avoid
%contradiction.}
It is often necessary to ensure some loose synchronization between clocks of
different nodes in an asynchronous distributed system.  One way to do this is
through Lamport clocks~\cite{timeclocks}.

Consider a rule \dedalus{p(A,B)@async \(\leftarrow\) q(A,B)}.  By rewriting it
to:

\begin{Dedalus}
persist[p, 2]
p\_wait(A, B, N)@async \(\leftarrow\) q(A, B)@N;
p\_wait(A, B, N)@next \(\leftarrow\) p\_wait(A, B, N)@M, N \(\ge\) M;
p(A, B)@next \(\leftarrow\) p\_wait(A, B, N)@M, N < M;
\end{Dedalus}

\noindent we place the derived tuple in a new relation \dedalus{p\_wait} that
stores any tuples that were ``sent from the future,'' according to their
entangled time; these tuples stay in the \dedalus{p\_wait} predicate until the
point in time at which they were derived.  
%Conceptually, this causes the system to evaluate a potentially large number of
%timesteps (if N is significantly less than the timestamp of the system when
%the tuple arrives).  However, if the runtime is able to efficiently evaluate
%timesteps when the database is quiescent, then instead of ``waiting'' by
%evaluating timesteps, it will simply increase its logical clock to match that
%of the sender.  \wrm{don't think we need to be getting into the efficiency of
%evaluation of the language this early...} In contrast, if the tuple is ``sent
%into the future,'' then it is processed using the timestep that receives it.
%\wrm{yes!  we delete the above thing about efficiency, and just keep the
%below}
This manipulation of timesteps and clock values is equivalent to conventional
descriptions of Lamport clocks, except that our Lamport clock implementation
effectively ``advances the clock'' by preventing derivations until the clock is
sufficiently advanced, by temporarily storing incoming tuples in the
\dedalus{p\_wait} relation.\footnote{For ease of exposition, we elide one
detail here: Lamport clocks rely upon a ``tie-breaking'' function to ensure
that no two events have the same timestamp.  We can implement such a discipline
using queues.}


%Although annotating a program execution with logical clock values has
%a number of practical runtime applications (such as debugging), in our
%setting it is primarily useful as a way to reconcile physical
%constraints (a given program execution on real hardware will obey
%causality) with our expressive language model (which is able to model
%temporal paradoxes).  Crucially, we do so in a purely logical manner,
%without resorting to imperative constructs outside of Datalog.  In
%Section~\rcs{sec:fixme}, we take this idea a step further, and explain
%how \lang programs can be restricted to treat events as serializable
%transactions.  This allows us to model well-studied runtime
%optimizations such as parallelizing compilers and database lock
%managers with little additional complexity.

%\rcs{move this comment to discussion}\paa{clean up, and cite netdb and the TR as examples of more complicated
%synchronization constructs expressible in logic (consensus and reliable broadcast,
%respectively)}

%\wrm{why can't
%we just combo a Lamport clock with a priority queue?  i don't think we need
%choice here, so i commented it out.}
%In \lang, such a function could be implemented via another use of
%\dedalus{choice}, or by a program convention like appending a unique node
%identifier to each timestamp to prevent ``ties.''

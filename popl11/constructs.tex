\section{State in Logic}
\label{sec:stateupdate}


%%\linebreak
\begin{quote}
%
\emph{Time is a device that was invented to keep everything from
happening at once.}\footnote{Graffiti on a wall at Cambridge
University~\cite{scheme}.}
%
\end{quote} 

Given our definition of \slang, we now address the persistence and mutability
of data across time---one of the two signature features of distributed systems
for which we provide a model-theoretic foundation.

The intuition behind \slang's \dedalus{successor} relation is that it models the
passage of (logical) time.  In our discussion, we will say that ground atoms
with lower time suffixes occur ``before'' atoms with higher ones.
The constraints we imposed on \slang rules restrict how deductions may be made
with respect to time.  First, rules may only refer to a single time suffix variable in
their body, and hence {\em cannot join across different ``timesteps''}.  Second, rules may specify
deductions that occur concurrently with their ground facts or in the next
timestep---in \slang, we rule out induction ``backwards'' in time or
``skipping'' into the future.

This notion of time allows us to consider the contents of the EDB---and hence
a minimal model of the IDB---with respect to an ``instant in time'': we simply
bind the time suffixes ($\DT$) of all body predicates to a constant.  Because
this produces a sequence of models (one per timestep), it gives us an intuitive
and unambiguous way to declaratively express persistence and state changes
across time.  In this section, we give examples of language constructs
that capture state-oriented motifs such as persistent relations,
deletion and update, sequences, and queues.

\subsection{Simple Persistence}
A fact in predicate $p$ at time $\DT$ may provide ground for deductive rules
at time $\DT$, as well as ground for deductive rules in timesteps greater than $\DT$,
provided there exists a {\em simple persistence rule} of the form:

\dedalus{p\pos($A_1$,$A_2$,[...],$A_n$)@next $\leftarrow$
p\pos($A_1$,$A_2$,[...],$A_n$);}

\noindent
A simple persistence rule of this form
ensures that a $p$ fact true at time $i$ will be true $\forall j \in \mathbb{Z} : j >= i$.



\subsection{Mutable State}
\label{sec:mutable}

To model deletions and updates of a fact, it is necessary to break the induction
in a simple persistence rule.  Adding a \dedalus{p\nega} subgoal to the body of a
simple persistence rule accomplishes this:


\begin{dedalus}
p\_pos($A_1,A_2,[...],A_n$)@next $\leftarrow$
\end{dedalus}

\hspace{5mm}
\begin{dedalus}
p\_pos($A_1,A_2,[...],A_n$),
\end{dedalus}

\hspace{5mm}
$\lnot$
\begin{dedalus}
p\_neg($A_1,A_2,[...],A_n$);
\end{dedalus}

%%\begin{definition}
%
%%A rule of the above form is known as a {\em mutable persistence rule}.
%
%%\end{definition}
\noindent
If, at any time $k$, we have a fact
\dedalus{p\nega($C_1$,$C_2$,[...],$C_n$)@k}, then we do not deduce a
\dedalus{p\pos($C_1$,$C_2$,[...],$C_n$)@k+1} fact.  By induction, we do not
deduce a \dedalus{p\pos($C_1$,$C_2$,[...],$C_n$)@j} fact for any $j > k$, unless
this \dedalus{p\pos} fact is re-derived at some timestep $j > k$ by another
rule.  This corresponds to the intuition that a persistent fact, once stated,
is true until it is retracted.  

%%\newtheorem{example}{Example}
\begin{example}
Consider the following \slang program and ground facts:

%%p\pos(A, B) \(\leftarrow\) p(A, B);
\begin{Dedalus}
p\pos(A, B)@next \(\leftarrow\) p\pos(A, B), \(\lnot\)p\nega(A, B);

p(1,2)@101;
p(1,3)@102;
p\nega(1,2)@300;
\end{Dedalus}

It is easy to see that the following facts are true: \dedalus{p(1,2)@200},
\dedalus{p(1,3)@200}, \dedalus{p(1,3)@300}.  However, \dedalus{p(1,2)@301} is
false because it was ``deleted'' at timestep \dedalus{300}.
\end{example}

Since mutable persistence occurs frequently in practice, we provide the {\em
persist} macro, which takes 
two arguments: a predicate name and its arity. 
The macro
expands to the corresponding mutable persistence rule, and rewrites the current program
in such a way that any references to the given predicate (say \emph{p}) in rule bodies or heads are replaced by references
to its positive relation (e.g. \emph{p\_pos}), except for rules in which the keyword \emph{delete}
appears before \emph{p} in the head, which are replaced with \emph{p\_neg}.  For example, the above
\dedalus{p\_pos} persistence rule may be equivalently specified as
\dedalus{persist[p,  2]}.

Mutable persistence rules enable {\em updates}.  For some time $\DT$, an
update is any pair of facts:

\begin{dedalus}
p\nega($C_1,C_2,[...],C_n)@\DT;$
\end{dedalus}

\begin{dedalus}
p\pos($D_1,D_2,[...],D_n)@\DT+1$;
\end{dedalus}


\noindent
Intuitively, an update represents deleting an old value of a tuple and
inserting a new value.  Every update is {\em atomic across timesteps}, meaning
that the old value ceases to exist at the same timestep in which the new value
is derived---timestep $\DT+1$ in the above definition.

\subsection{Assignment and Committed Choice}

The assignment primitive provided by most imperative languages is a  special 
case of update without deletion.  We may very simply model the (destructive) assignment 
of values to keys in the following way:

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) condition(A, B);
log(A, B)@next \(\leftarrow\) log(A, B), \(\lnot\)condition(A, _);
\end{Dedalus}

Assuming that {\em condition(A, B)} respects the functional dependency $A \to B$, the pair 
of rules above will cause {\em log} to associate with $A$ the ``most recent'' value of $B$
appearing in {\em condition}.

The mirror image of assignment is committed choice, which associates the ``first'' value
of $B$ with $A$:

\begin{Dedalus}
log(A, B)@next \(\leftarrow\) log(A, B);
log(A, B)@next \(\leftarrow\) condition(A, B), \(\lnot\)log(A, _);
\end{Dedalus}



\subsection{``At Most Once'' event relations}



\subsection{Sequences}
One may represent a database sequence---an object that retains and monotonically increases a counter value---with a pair of inductive rules.  One rule increments the current counter value when some condition is 
true, while the other persists the value of the sequence when the condition is false.  We can capture the increase
of the sequence value without using arithmetic, because the infinite series of \dedalus{successor} has the monotonicity
property we require:

\begin{Dedalus}
seq(B)@next \(\leftarrow\) seq(A), successor(A,B), event(_);  
seq(A)@next \(\leftarrow\) seq(A), \(\lnot\)event(_);
\end{Dedalus}

\noindent
Note that these two rules produce only a single value of \dedalus{seq} at each timestep, but they do so in a manner slightly different than our standard persistence template.

The use of sequences is often fairly canonical, so as a shorthand we provide the {\em sequence}
macro, which takes three arguments (sequence name, a ``trigger'' predicate which, when true, 
should cause the sequence to be incremented, and the trigger's arity) and expands them to a pair 
of definitions of a unary predicate like the one defined above (e.g., \dedalus{sequence[seq, event, 1]}.

\subsection{Queues}

\paa{shorten this section}
While sequences are useful constructs for generating or imposing an ordering on tuples, programs will in some cases require that tuples
are processed in a particular (partial) order associated with specific timesteps.   To this end, we introduce a queue template, which employs 
inductive persistence and aggregate functions in rule heads to process tuples according to a data-dependent order, rather than as a set.

Aggregate functions simplify our discussion of queues.  Mumick and Shmueli observe correspondences in the expressivity of Datalog with stratified negation and stratified aggregation functions~\cite{mumickshmueli}.  Adding aggregation to our language does not affect its expressive power, but is useful for writing natural constructs for distributed computing including queues and ordering.  

In \slang we will allow
aggregate functions $\rho_1 - \rho_n$ to appear
in the head of a deductive rule of the form:

%%\dedalus{p(\(A_1\), \(\ldots\), \(A_n\), \(\rho_1\)(\(A_{n+1}\)), \(\ldots\), \(\rho_m\)(\(A_{n+m}\))) \(\leftarrow\)}

\begin{dedalus}
p($A_1, \ldots, A_n, \rho_1(A_{n+1}), \ldots, \rho_m(A_{n+m})) \leftarrow$
\end{dedalus}
%%\linebreak

\hspace{5mm}
$q_1$
\begin{dedalus}
($A_1, \ldots, A_{n}, A_{n+1}), \ldots, q_m(A_1, \ldots, A_{n}, A_{n+m}$);
\end{dedalus}

According to this rule, the predicate $p$ contains one row for each satisfying assignment of $A_1, \ldots, A_n$ --- akin to the distinct ``groups'' of SQL's ``GROUP BY'' notation.



Consider a predicate \dedalus{priority\_queue} that represents a series of tasks to be performed in some predefined order.  Its attributes are a string representing a user, a job, and an integer
indicating the priority of the job in the queue:

\begin{Dedalus}
priority\_queue('bob', 'bash', 200)@123;
priority\_queue('eve', 'ls', 1)@123;
priority\_queue('alice', 'ssh', 204)@123;
priority\_queue('bob', 'ssh', 205)@123;
\end{Dedalus}

Observe that all the time suffixes are the same.  
%Depending on the program that implements the balance update, several behaviors
%are possible.
Given this schema, we note that a program would likely want to process
\dedalus{priority\_queue} events individually in a data-dependent order, in
spite of their coincidence in logical time.  

%%It is difficult to express general
%%in-order tuple processing in Datalog, in part because the language does not
%%admit sequences.  \jmh{Huh?  I don't see the last clause there.  Maybe say simply that Datalog is set-oriented, but what we want here is precisely to impose an ordering on the elements of the set, which seems unnatural.  There's maybe a connection to expressibility and aggregation or arithmetic or something, but let's not try to sort that out for now.}
%above is really what we want to say, right? -wrm
%has so
%notion of order of evaluation (except the implicit ordering implied by
%stratification).

In the program below, we define a table \dedalus{m\_priority\_queue} that
serves as a queue to feed \dedalus{priority\_queue}.  The queue must persist
across timesteps because it may take multiple timesteps to drain it.  At each
timestep, for each value of \textbf{A}, a single tuple is projected into
\dedalus{priority\_queue} and deleted (atomic with the projection) from
\dedalus{m\_priority\_queue}, changing the value of the aggregate calculated
at the subsequent step:

\begin{Dedalus}
persist[m\_priority\_queue, 3]

% find the min priority
omin(A, min<C>) \(\leftarrow\)
  m\_priority\_queue(A, _, C);

% feed p in the next step 
% with the items of min priority
priority_queue(A, B, C)@next \(\leftarrow\)
  m\_priority\_queue(A, B, C), omin(A, C);

% delete from the next step 
% those items of min priority
delete m\_priority\_queue(A, B, C) \(\leftarrow\)
  m\_priority\_queue(A, B, C), omin(A, C);
\end{Dedalus}

Under such a queueing discipline, deductive rules that depend on
\dedalus{priority\_queue} are constrained to consider only min-priority tuples at each timestep
per value of the variable \textbf{A}, thus implementing a per-user FIFO
discipline.  To enforce a global FIFO ordering over \dedalus{priority\_queue}, we
may redefine \dedalus{omin} and any dependent rules to exclude the \textbf{A}
attribute.

A queue establishes a mapping between \slang's timesteps
and the priority-ordering attribute of the input relation. By doing so, we take advantage of the monotonic property of timestamps to enforce an ordering property over our input that is otherwise 
very difficult to express in a logic language.  We return to this idea in our discussion of temporal ``entanglement'' Section~\ref{sec:entangle}.

\wrm{greco and zaniolo also have a take on priority queues.  cite them here.}

\subsection{Distribution}

The choice construct will capture the non-determinism of multiple communicating agents in a distributed system, but we want to use it in a stylized way to model typical notions of distribution.  To this end \lang adopts the ``horizontal partitioning'' convention introduced by Loo et al.\ and used in many subsequent efforts~\cite{Loo:2005}.
To represent a distributed system, we consider some number of agents,
each running a copy of the same program against a disjoint subset ({\em
  horizontal partition}) of each predicate's contents.  We require one
attribute in each predicate to be used to identify the
partitioning for tuples in that predicate. We call such an
attribute a {\em location specifier}, and prefix it with a
\dedalus{\#} symbol in Dedalus.

Finally, we constrain \lang rules so that the location specifier variable in each body predicate be the same---i.e.\ the body contains tuples from exactly one partition of the database, logically colocated (on a single ``machine'').  If the head of the rule has the same location specifier variable as the body, we call the rule ``local,'' since its results can remain on the machine where they are computed.  If the head has a different variable in its location specifier, we call the rule a {\em communication rule}.  We now proceed to our model of the asynchrony of this communication, which is captured in a syntactic constraint on the heads of communication rules.

As a syntactic constraint of \lang, the {\em communication rules} introduced in the previous section (rules that differ in head and body location specifiers) are required to be asynchronous.
This restricts our model of communication between agents in two important ways.
First, by restricting bodies to a single agent, the only communication
modeled in \lang occurs via communication rules.  Second, because
all communication rules are asynchronous, agents may only learn about
time values at another agent by receiving messages (with unbounded
delay) from that agent.  Note that this model says nothing about the
relationship between the agents' clocks; they could be
non-monotonically increasing, or they could respect a global order.

\subsection{Entanglement}
\label{sec:entangle}
Consider the asynchronous rule below:

\begin{Dedalus}
p(A, B, N)@async \(\leftarrow\)
  q(A, B)@N;
\end{Dedalus}
\noindent
Due to the \dedalus{async} keyword in the rule head, each \emph{p} tuple will take some unspecified time suffix value.
Note however that the time suffix $N$ of the rule body appears also in an attribute of \emph{p} other than the time suffix, recording a 
binding of both the time value of the deduction and the time value of its consequence.  We call such a binding
an \emph{entanglement}.   Note that in order
to write the rule it was necessary to not sugar away the time suffix in the rule body.  

Entanglement is a powerful construct.  It allows a rule
to reference the logical clock time of the deduction that produced one
(or more) of its subgoals; this supports protocols that reason about partial ordering of time across machines.  More generally, it exposes the infinite \dedalus{successor} relation to attributes other than the time suffix, allowing us to express concepts such as infinite sequences.


\subsection{Lamport Clocks}
\label{sec:lamport}

Recall that \lang allows program executions to order message timestamps arbitrarily, violating intuitive notions of causality by allowing deductions to ``affect the past.''
This section explains how to implement Lamport
clocks~\cite{timeclocks} atop \lang, which allows programs to ensure
temporal monotonicity by reestablishing a causal order
despite derivations that flow backwards through time.

Consider a rule \dedalus{p(A,B)@async \(\leftarrow\) q(A,B)}.  By
rewriting it to:

\begin{Dedalus}
persist[p, 2]
p\_wait(A, B, N)@async \(\leftarrow\) q(A, B)@N;
p\_wait(A, B, N)@next \(\leftarrow\) p\_wait(A, B, N)@M, N \(\ge\) M;
p(A, B)@next \(\leftarrow\) p\_wait(A, B, N)@M, N < M;
\end{Dedalus}
\noindent
we place the derived tuple in a new relation \dedalus{p\_wait} that
stores any tuples that were ``sent from the future'' with their sending time ``entangled''; these tuples stay in the \dedalus{p\_wait} predicate  until the point in
time at which they were derived.  Conceptually, this causes the system
to evaluate a potentially large number of timesteps (if N is
significantly less than the timestamp of the system when the tuple
arrives).  However, if the runtime is able to efficiently evaluate
timesteps when the database is quiescent, then
instead of ``waiting'' by evaluating timesteps, it will simply
increase its logical clock to match that of the sender.  In contrast,
if the tuple is ``sent into the future,'' then it is processed using
the timestep that receives it.

This manipulation of timesteps and clock values is equivalent to
conventional descriptions of Lamport clocks, except that our Lamport
clock implementation effectively ``advances the clock'' by preventing derivations until the clock is sufficiently advanced, by temporarily store incoming tuples
in the \dedalus{p\_wait} relation.

We gloss over one detail here: Lamport clocks rely
upon a ``tie-breaking'' function to ensure that no two events have the
same timestamp.  In \lang, such a function could be implemented via another use of \dedalus{choice}, or by a program convention like
appending a unique node identifier to each timestamp to prevent ``ties.''

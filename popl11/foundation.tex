\section{Foundation}
\label{sec:lang}

\lang is based in Datalog enhanced with negation and aggregation
(a.k.a.\ Datalog$\lnot$)~\cite{ullmanbook}, which hereinafter we refer to simply as Datalog.
Below, we provide a brief review of Datalog, and subsequently detail our
language in terms of Datalog.

\subsection{Datalog}
\label{sec:datalog}

A Datalog {\em program} comprises a set of {\em rules}.  A Datalog {\em rule}
is a first-order logical formula of the following form:
\dedalus{$p_0(\overline{X_0})$ :- $p_1(\overline{X_1})$, ...,
$p_j(\overline{X_j})$, $\lnot p_{j+1}(\overline{X_{j+1}})$, ..., $\lnot
p_k(\overline{X_k})$;}.  \dedalus{$p_0$, ..., $p_k$} are known as {\em
predicates}.  Each predicate, also called a {\em relation} or {\em table}, has
a fixed arity.  Predicates that appear on the left-hand side of some rule in
the program are called {\em intensional} predicates---the rest are called {\em
extensional}.  Each of $\overline{X_0}, ..., \overline{X_k}$ are lists of
arguments (constants or existentially quantified variables).
$p_0(\overline{X_0})$, ..., $p_k(\overline{X_K})$ are {\em atoms}---an atom is
a list of arguments prefixed with a predicate.  The same variable symbol may
appear in multiple atoms; in this case, we say that the atoms are {\em
unified} on the arguments that contain the duplicated variable.  An assignment of constants to all arguments in a predicate is known as a {\em
fact}---also called a {\em tuple} or {\em row}---and we often refer to ``the
facts in a predicate,'' meaning the satisfying assignment of constants to the
predicate's arguments.  The single
atom to the left of the \dedalus{:-} delimeter is the rule's {\em head}, and
the set of atoms to the right is the rule's {\em body}.  We say that the rule's
head predicate {\em depends on} each of its body predicates.   If a predicate
(resp. fact) \dedalus{p} depends on a predicate (resp. fact) \dedalus{q}, we
write \dedalus{p} $\succ$ \dedalus{q}.  A predicate (resp. fact) \dedalus{p} transitively depends on a predicate (resp. fact) \dedalus{q}---denoted
\dedalus{p} $\succ^+$ \dedalus{q}---if \dedalus{p} $\succ$ \dedalus{q}, or if
\dedalus{p} $\succ$ \dedalus{r} $\succ^+$ \dedalus{q}.  If \dedalus{p}
$\succ^+$ \dedalus{p}, then we say that \dedalus{p} is {\em recursive} or {\em
cyclic}.

In addition to atoms, a rule's body may also contain the {\em order
constraints}: $=, \geq, >, \leq, <, \neq$.  An order constraint is an infinite
binary relation that may be applied either to constants, or variables used in
the rule's body atoms.

The logical meaning of a Datalog rule is that for each
satisfying assignment of constants to variables on the right-hand side, there
exists a tuple with the corresponding satisfying assignment of constants in the
left-hand side predicate.
%\rcs{satisfies the lhs?}
A (possibly empty) set of facts for the extensional predicates is known as an
{\em EDB} or extensional data base.  A Datalog {\em instance} is a program
together with an EDB.  

The {\em Herband Universe} of an instance, written $\mathcal{H}$ is the set of all constants in the EDB and IDB.

\subsection{Aggregation}

{\em Aggregates} are functions from sets to scalar values.
We are interested in both {\em exemplary} aggregates like \dedalus{max} and \dedalus{min} that return a value
from the input set, and {\em summary} aggregates like \dedalus{count}.  An aggregate may only appear in the head
of a rule; a head atom \dedalus{p($\bar{A}, \rho<B>$)}, where $\rho$ is an 
aggregate, indicates that predicate \dedalus{p} contains one row for each 
satisfying assignment of $\bar{A}$ (the ``grouping'' attributes).  This row contains the value of the 
aggregate function over the set of assignments to $B$ for the given value of 
$\bar{A}$.

As a concrete example, consider implementing the ``checkout'' functionality for shopping carts: this requires carrying out some aggregations over the {\tt cart\_action} table.
A typical implementation counts the number of additions and deletions 
of each item.  The rule below will group by the first five attributes, and associate the
count of unique {\tt ReqId} values with the last attribute: 
%\jmh{is it clear that Type is one of ``insert'' or ``delete''?}

\noindent{}
\begin{Dedalus}

status(Serv, Cli, Ses, Item, Type, count<ReqId>) :- 
  cart\_action(Serv, Cli, Ses, Item, Type, ReqId);
\end{Dedalus}

\subsection{Non-Monotonicity}
\jmh{A little intro would be nice here: monotonic programs can be useful, but often are not expressive enough to capture program semantics.  Going beyond monotonicity involves the use of negation/aggregation, but this needs to be addressed carefully.}
A Datalog instance without negation or aggregation always has a unique {\em
minimal model}: the minimal set of facts in intensional predicates implied by
the EDB given the program, or the intensional data base ({\em
IDB})~\cite{ullmanbook}.  
\paa{the model is EDB $\cup$ IDB, right?}
We call programs that always have a unique minimal
model {\em monotonic} programs.  \jmh{I think that's defining a corollary of montonicity, no?  Or are you trying to capture non-syntactic monotonicity here?  I suspect this is a dangerous way to do that...} Adding negation or aggregation to Datalog
programs increases expressivity\wrm{cite}, but removes the guarantee of a
unique minimal model---we call these {\em non-monotonic} programs.  \jmh{already you're in trouble, since this is not symmetric with the definition of montonicity.  the way you've stated things requires a proof}  When
admitting negation or aggregation, one possibility is that a {\em
contradiction} may arise---a fact that depends on its own negation.  Consider
the Datalog program below, which represents a game where player \dedalus{X}
wins if she has a move, and player \dedalus{Y} does not have a move:

\begin{Dedalus}
win(X) :- move(X,Y), \(\lnot\) win(Y);
\end{Dedalus}

\noindent{}Consider the following EDB for the above program:

\begin{Dedalus}
move(1,1)
\end{Dedalus}

This instance has no minimal model, because it has a contradiction:
\dedalus{move(1,1)} and \dedalus{\(\lnot\) win(1)} implies \dedalus{win(1)},
and thus \dedalus{win(1)} $\succ$ \dedalus{\(\lnot\) win(1)}.  Notice that if
we required \dedalus{p} $\not\succ^+$ \dedalus{\(\lnot\) p} for all predicates
\dedalus{p}, a contradiction could never arise in any instance of any program
-- this is called {\em syntactic stratification}.  It is known that detecting
whether a program is contradiction-free for all EDBs is
undecidable~\cite{papa-yanna}, so the Datalog community has devised a spectrum
of other {\em stratification conditions}~\cite{local-strat, ross-syntactic,
modular, weak-strat} that assure acyclicity of all facts through negation---but exclude
some contradiction-free programs---in an increasingly less 
\paa{um, decreasingly?}
conservative
fashion.  \jmh{the preceding is slightly awkward} For example, adding the condition \dedalus{X < Y} to the above rule
would rule out contradictions.  Alternatively, adding a condition to
ensure that \dedalus{move} is acyclic would also exclude contradictions.  If a
program satisfies a particular stratification condition, then we call the
program {\em stratified}.

%The logic programming community has
%devised a number of increasingly less-conservative conditions called {\em
%stratification conditions}~\cite{local-strat, ross-syntactic, modular,
%weak-strat}, which ensure acyclicity of derivations through negation, but
%exclude some contradiction-free programs.  If a program meets a particular
%stratification condition, we say the program is {\em stratified}.  One
%condition is known as {\em syntactic stratification}, which excludes all
%programs where a predicate \dedalus{p} transitively depends on
%\dedalus{\(\lnot\)p}.  Clearly, this condition may exclude many useful
%programs, because such a syntactic cycle may in practice never lead to a
%contradiction.
%The semantics presented in~\cite{wellfounded} define a unique
%model for any stratified program.
Negation (non-existence in a set) and aggregates (functions defined over
sets) require their input set to be fully determined in order to produce a
correct answer.  In other words, they require {\em universal quantification}
over the set on which they are defined.  Stratification conditions impose order on the application of
rules to ensure that this universal quantification is always applied after the
input set is fully determined.  This ordering induces a unique model, under
the semantics presented in~\cite{wellfounded}.

%\paa{good!}

\subsection{Safety}

To ensure that Datalog programs are always effectively computable, the universe
of constants---and thus the model---is restricted to be finite.  This is
achieved by making the program {\em safe}---restricting the use of constructs
that can expand the universe of constants, such as summary aggregates.
\paa{I want badly to add here ", infinite relations, or arbitrary scalar functions", 
but assume there is a reason why you didn't?}  \jmh{Said differently, the above is an example, not a definition.  Also, it raises but does not address the obvious question of how we'll deal with Safety in Dedalus.}

\section{\lang}

One of our goals for \lang is
to model the inherent non-determinism of network delay in asynchronous
distributed systems.  Non-determinism in Datalog was formalized by Sacc\`{a}
and Zaniolo~\cite{sacca-zaniolo} in their \dedalus{choice} construct.  For
example, consider the rule \dedalus{p(X,Y) :- q(X,Y), choice((X), (Y));} this expresses that for each
value that variable \dedalus{X} assumes, variable \dedalus{Y} may only take on
a single {\em non-deterministically chosen} value.  Sacc\`{a} and Zaniolo provide a model-theoretic definition for \dedalus{choice} (based on cycles through negation) that preserves our ability to analyze programs using tools from Datalog. 
%   See~\cite{sacca-zaniolo}
% for the details on how \dedalus{choice} is expanded into Datalog rules that
% employ cyclic negation.

\paa{the above para is jarringly out of place here.  what was the rationale for
moving it from the previous section?}

\lang is a subset of Datalog, with \dedalus{choice}, an infinite
\dedalus{time} relation $\mathbb{N}$, and a \dedalus{successor}
%$(\mathbb{N} \cup \top)$
relation, which is isomorphic to $+1$ on $\mathbb{N}$.  The intuition behind
\lang's \dedalus{successor} relation is that it models the passage of logical
time.  In our discussion, we will say that facts with lower time suffixes occur
``before'' atoms with higher ones.  
%If we wish to model possible message loss,
%we may admit a special element $\infty$ 
%into \dedalus{time}.
We exclude message loss and node failure in this paper to
simplify the discussion, though we explicitly deal with such issues in other
work~\cite{dedalus-techr, netdb}.
We will see later how \dedalus{successor} forms the basis of a stratification
condition that we call {\em temporal stratification}.

\subsection{Syntactic Restrictions}
\label{sec:syntaxrestrictions}
\jmh{Specifically?}
Specifically, we restrict the form of predicates and rules in the following ways:

\noindent{\bf Time Suffix: }We require that the final attribute of every \lang
predicate range over the \dedalus{time} domain.  
%\lang considers this final attribute as a ``timestamp,'' so
We refer to this attribute as the \emph{time suffix} of the corresponding
predicate, and we talk about the {\em timestamp} of a fact. \rcs{Removed:''---we also refer to
facts as {\em events}.''  We need to talk about async before talking about events.  Also, we should define ``event'' as ``a tuple produced by async rules''.}

\noindent{\bf Unification on Time: }

In a well-formed \lang rule, every body predicate's time suffix contains the
same variable symbol.  This corresponds to the intuition that rules must
operate in a given time, and cannot operate across time.  
\paa{``operate in a given time'' is awkward, but not sure what to suggest}
For ease of exposition, we henceforth assume that this
variable symbol is named $\DT$.  A well-formed \lang rule must also bind the
head predicate's time suffix to a variable symbol.  We will assume the name of
this variable symbol is $\DS$.  $\DS$ may be constrained in exactly one of
three ways:

\begin{enumerate}
%
\item The rule is {\em deductive} if $\DS$ is bound to the value
$\DT$; that is, the body contains \dedalus{$\DS$ = $\DT$}.
%
\item The rule is {\em inductive} if $\DS$ is the successor of
$\DT$; that is, the body contains \dedalus{successor($\DT$, $\DS$)}.
%
\item The rule is {\em asynchronous} if $\DS$ is unrelated to $\DT$;
that is, the body contains \dedalus{time($\DS$), choose(($\overline{A}$),
($\DS$))}, where $\overline{A}$ is the set of variables occurring in the body,
including $\DT$.
%
\end{enumerate}

We will study the utility of these three types of rules later, but briefly observe here
that systems in
general only require recourse to ordering primitives for mutable state and communication.
Inductive and asynchronous rules model these cases respectively.

Usage of $S$ or $T$ outside of the time suffixes is known as {\em
entanglement}.  We will revisit this powerful construct in~\ref{sec:entangle}. 

\begin{example}
The following are examples of well-formed deductive, inductive, and asynchronous rules, respectively.
We can sugar away the time suffixes in the head and body, and the
\dedalus{successor}, \dedalus{time} and \dedalus{choice} clauses in
the body, and the equality constraints, and instead attach an identifier to the head of each
temporal rule, to indicate the change in time suffix.  In each, the sugared example appears
below.  We may also represent facts by attaching a constant time suffix, as shown below.  \jmh{We need to find an easier-to-read formatting -- perhaps side-by-side in a figure, or in a \\tabular environment that separates things out.}
\\
deductive:
\begin{Dedalus}
p(A, B, \(\DS\)) \(\leftarrow\) e(A, B, \(\DT\)), \(\DS\) = \(\DT\);
p(A, B) \(\leftarrow\) e(A, B);
\end{Dedalus}
\\
inductive:
\begin{Dedalus}
q(A, B, \(\DS\)) \(\leftarrow\) e(A, B, \(\DT\)), successor(\(\DT\), \(\DS\));
q(A, B)@next \(\leftarrow\) e(A, B);
\end{Dedalus}
\\
asynchronous:
\begin{Dedalus}
r(A, B, \(\DS\)) \(\leftarrow\) e(A, B, \(\DT\)), time(\(\DS\)),
   choose((A,B,\(\DT\)), (\(\DS\)));
r(A, B)@async \(\leftarrow\) e(A, B);
\end{Dedalus}
\\
\begin{Dedalus}
fact:
e(1,2)@3;
\end{Dedalus}
\end{example}

\paa{consider using shopping cart examples (with shorter attr names)
for the above}
\\
deductive:
\begin{Dedalus}
ca_stage(S, C, Sn, I, T, R, \(\DS\)) :- 
  action(C, Sn, I, T, \(\DT\)), 
  best_replica(C, Sn, S, \(\DT\)), s(R, \(\DT\)),
  \(\DS\) = \(\DT\);
ca_stage(S, C, Sn, I, T, R) :-
  action(C, Sn, I, T), best_replica(C, Sn, S), s(R);
\end{Dedalus}
\\
inductive:
\begin{Dedalus}
s(X + 1, \(\DS\)) \(\leftarrow\) s(X, \(\DT\))), \(\lnot\) action(_, _, _, _, _, \(\DT\)),
  successor(\(\DT\), \(\DS\));
s(X + 1)@next \(\leftarrow\) s(X) \(\lnot\) action(_, _, _, _, _);
\end{Dedalus}
\\
asynchronous:
\begin{Dedalus}
cart_action(#L, C, S, I, T, R, \(\DS\))) :- 
  ca_stage(L, #C, S, I, T, R, \(\DT\))), time(\(\DS\)),
  choose((L,#C, S, I, T, R, \(\DT\)), (\(\DS\)));
\end{Dedalus}

\paa{better (modulo formatting)?}

\noindent{\bf Positive and Negative Predicates: }
\paa{joe thinks we could probably footnote a digest of all or most of this section} \jmh{postpone p\_neg until you need it, and ignore p\_pos (you could footnote that when you talk IDB vs. EDB if you like.)  Assume this is not a language feature, it's just a design pattern you'll use.}
For every extensional predicate \dedalus{r} in a \lang program $P$, we add to
$P$ two distinguished predicates \dedalus{r\pos} and \dedalus{r\nega} with the same arity
as \dedalus{r}.  We define \dedalus{r\pos} using the following rule:\rcs{this leads to akwardness later.  perhaps we should define an \dedalus{r} and an \dedalus{r edb}}

\begin{dedalus}
r\pos($\overline{A}$,\(\DS\)) \(\leftarrow\) r($\overline{A}$,\(\DT\)), \(S\)=\(\DT\);
\end{dedalus}

% \hspace{5mm}
% \begin{dedalus}
   
% \end{dedalus}

\noindent{}That is, for every extensional predicate \dedalus{r} there is an intensional
predicate \dedalus{r\pos} that contains at least the contents of \dedalus{r}.
Intuitively, this rule allows extensional facts to serve as ground for
\dedalus{r\pos}, while enabling other rules to derive additional \dedalus{r\pos} facts.

The predicate \dedalus{r\pos} may be referenced in the body or head of any \lang rule.  
We will make use of the predicate \dedalus{r\nega} later to capture the notion of mutable state; we return to it in Section~\ref{sec:mutable}. 
Like \dedalus{r\pos}, the use of \dedalus{r\nega} in the heads and bodies of rules is unrestricted.

\vspace{1.2em}
\noindent{\bf Guarded EDB: }
No well-formed \lang rule may involve any extensional predicate, except for a rule of the form above.


\subsection{Distribution, Asynchrony and Choice}
\jmh{I don't think we need to require all agents execute the same rules.}
\lang adopts the {\em horizontal partitioning} convention introduced by Loo et
al.~\cite{Loo:2005}, where all agents execute the same rules but predicates are
partitioned based on the value of the {\em location specifier}: a column of
every relation that stores an agent's identifier.
\jmh{let's clarify that it's a schema-level decision, not a rule-level decision (despite the redundant Overlog-style syntax).}
 In \lang, we require that all
atoms in the body of a single rule use the same variable name in the location
specifier. If the location specifier of a rule's head is bound to the body's
location specifier, then we call the rule {\em local}.  Otherwise, we call the
rule a {\em communication rule}.  Note that by restricting rule bodies to a
single agent, the only communication modeled in \lang occurs via communication
rules.  
\paa{maybe we can say something about, "enforcing locality in space just as we 
enforced locality in time."  locality in space corresponds to a "scope of atomicity",
as neil pointed out in his talk}
Derivation of a fact with another agent's identifier implies sending
the fact to the agent.  Syntactically, location specifiers are prefixed with a
\dedalus{\#} symbol in Dedalus.

We use choice to model the inherent temporal nondeterminism associated with
communication in {\em asynchronous} distributed systems.  For example, messages
may be arbitrarily delayed, and a receiver cannot infer that a message will
never be sent based solely on his non-receipt of the message (it may arrive
arbitrarily far in the future).
To this end, we require that any communication rules be \dedalus{@async} rules.

%We call the set of facts, 
%\paa{ground atoms?}
%including their timestamps, derived by communication
%rules during a particular execution a {\em trace} of the program.

\jmh{the following is floating free right now}
\begin{definition}
%
For a \lang instance and a particular series of non-deterministic choices, the
set of all facts in \dedalus{async} relations, including their timestamps,
comprise a trace of the instance.
%
\end{definition}

%Each trace is associated with exactly one model of the program.

\subsection{Temporal Stratification}
\jmh{this section needs a bit of intro}
We avoid contradictions in \lang by introducing a stratification condition called {\em
temporal stratification}, defined in terms of a program's {\em predicate
dependency graph} (PDG).  The PDG contains a node $N_i$ for each distinct
predicate $P_i$ used in the program, and an edge $(N_i, N_j)$ if $P_i \succ P_j$.
The edge is annotated with a
$\lnot$ if $P_i \succ \lnot P_j$.  The
edge is annotated with a $+$ if all rules with head $P_i$ and $P_j$ in their
bodies are either inductive or async.  A \lang program is temporally
stratified if all cycles in the PDG with an $\lnot$ edge also have a $+$
edge.

The intuitive meaning of a $+$ edge $(N_i, N_j)$ is that $P_j$ derives $P_i$ at
some later time.  
\paa{for more details and a proof see the TR}
%Note that while it is possible for an \dedalus{@async} rule to
%support a fact at an earlier time, this behavior cannot occur in real distributed
%systems. 

%The careful reader will note that so far, we have not
%restricted asynchronous rules to prevent {\em time travel}---a condition where
%an asynchronous rule gives rise to derivations that precede their antecedents
%in time.  While time travel is acceptable for programs where it cannot ever
%cause a contradiction (such as programs without negation), it is undesirable in
%general, as a fact may derive its own negation (intuitively, a ``temporal
%paradox'').  Thus, an additional condition is required to exclude such
%contradictions.
%\nrc{Not sure the remainder of this para is useful: yes, real systems
%  can't allow a temporal paradox. Seems like it
%  goes without saying.} \rcs{also, it sounds like we need to actually run the lamport clock at runtime in order to avoid temporal paradoxes in execution traces...  It should be more clear that these are model theoretic issues.  I tried to clean things up a bit in the lamport clock section, and tie these ideas to serializability below.  Hopefully serializability will ground the discussion without resorting to relativistic arguments about causality and simultanaity...}
%However, we note that in a practical asynchronous distributed system, nodes are
%assumed to have their own clocks, which may run at any arbitrary speed
%\wrm{move this defnition of async distr system earlier}.  Nodes assign a
%timestamp to an incoming fact that is greater than the timestamp of any
%existing fact.  Note that this condition excludes time travel in any possible
%execution.

%\begin{example}
%\label{ex:stratsafe}
%A simple temporally stratifiable and temporally safe \slang instance that is
%neither syntactically stratifiable nor syntactically\rcs{?} safe.

%\begin{Dedalus}
%persist[p, 2]  
  
%r1
%p(A, B) \(\leftarrow\)
%  insert\_p\_req(A, B);

%r2  
%delete p(A, B) \(\leftarrow\)
%  p(A, B),
%  del\_p\_req(A);

%insert\_p(1, 2)@1;
%\end{Dedalus}
%\end{example}

%In the \slang program in Example~\ref{ex:stratsafe}, \emph{insert\_p} and
%\emph{delete\_p} are captured in EDB relations.  This reasonable program is
%unstratifiable because $p \succ p\nega \land p\nega \succ p$.  But because the
%successor relation is constrained such that $\forall A,B, successor(A, B)
%\rightarrow B > A$, any such program is modularly stratified on
%\emph{successor}.  Therefore, we have $p_{n} \not\succ^* p\_neg_{n} \not\succ^*
%p_{n+1}$; informally, earlier values do not depend on later values.
%\paa{shouldn't it be $p_{n} \succ^* p\_neg_{n} \not\succ^* p_{n+1}$ ?}

%Given this discussion, in practice we are interested in three asynchronous
%scenarios: (a) monotonic programs (even with non-monotonicity in time), (b)
%non-monotonic programs whose semantics guarantee monotonicity of time suffixes
%and (c) non-monotonic programs where we have domain knowledge guaranteeing
%monotonicity of time suffixes.  Each represents practical scenarios of
%interest.

%The first category captures the spirit of many simple distributed
%implementations that are built atop unreliable asynchronous substrates.  For
%example, in some Internet publishing applications (weblogs, online fora), it
%is possible due to caching or failure that a ``thread'' of discussion arrives
%out of order, with responses appearing before the comments they reference.  In
%many cases a monotonic ``bag semantics'' for the comment program is considered
%a reasonable interface for readers, and the ability to tolerate temporal
%anomalies simplifies the challenge of scaling a system through distribution.

%The second scenario is achieved in \slang via the use of \dedalus{successor}
%for the time suffix. The asynchronous rules of \lang require additional
%program logic to guarantee monotonic increases in time for predicates with
%dependencies.  In the literature of distributed computing, this is known as a
%{\em causal ordering} and is enforced by distributed clock protocols.  We
%review one classic protocol in the \lang context in Section~\ref{sec:lamport};
%including this protocol into \lang programs ensures temporal monotonicity.

%Finally, certain computational substrates guarantee monotonicity in both
%timestamps and message ordering---for example, some multiprocessor cache
%coherency protocols achieve this.  When temporal monotonicity is given, the
%proofs of temporal stratification and Algorithm~\ref{alg:tsn} both apply.
%\wrm{end paste}

%\dedalus{@async} is clearly more liberal than our operational semantics
%defined above.  One of our goals is formal verification of distributed
%systems.  Thus, for the particular use-case of distributed execution with the
%above operational semantics, we need to discover a logical condition that
%results in a set of models that exhibit the same set of behaviors.  It is
%necessary and sufficient for each fact to carry an entangled timestamp from
%each node.  Timestamps must be propagated through derivations \wrm{explain}.
%When a node receives a fact, it will need to delay processing of the fact
%until its current time is greater than its entangled timestamp.  Note that
%this scheme employs vector clocks.

%Note that the use of Lamport clocks enforces additional constraints by ruling
%out more possible interleavings of events than the operational semantics for
%timestamp assignment. \wrm{check if this is true} \paa{we'll put the lamport
%clock discussion here, then?}

%\subsection{Temporal Safety}

%\wrm{begin paste} In the previous section we demonstrated that \slang can
%capture intuitive notions of persistence and mutability of state via a
%stylized use of Datalog.  However, the alert reader will note that even very
%simple \slang programs make for unusual Datalog.
%%: among other concerns, 
%To begin with, Persistence rules are {\em unsafe}, meaning they produce
%derivations for an infinite number of values of the time suffix.  Traditional
%Datalog interpreters, which work against static databases, would attempt to
%enumerate these values, making this approach impractical.  Equally worrisome
%is the fact that many common patterns for state update via mutable persistence
%entail unstratifiable constructs: predicates that syntactically depend on
%their own (possibly transitive) negation.  

%However, in the context of distributed systems and networks, the need for
%non-terminating ``services'' or ``protocols'' that continually update their
%state is very common.  In this section we show that expressing distributed
%systems properties such as persistence and mutable state in logic does not
%require dispensing with familiar notions of safety and stratification: we take
%traditional notions of acceptable Datalog programs, and extend them in a way
%that admits sensible non-terminating programs.

%\subsection{Temporal Safety} Next we consider the issue of infinite results
%raised in the introduction to this section.  In traditional Datalog, this is a
%well-studied concern.  A Datalog program is considered {\em safe} if it has a
%finite minimal model, and hence has a finite execution.  Safety in Datalog is
%traditionally ensured through the following syntactic constraints:

%\begin{enumerate}
%%
%\item No functions are allowed.
%
%\item Variables are \emph{range restricted}: all attributes of the head goal
%appear in a non-negated body subgoal.
%
%\item The EDB is finite.
%
%\end{enumerate} \wrm{end paste}

\subsection{Temporal Safety}

Next we consider the issue of infinite results.  In Datalog, programs with
infinite results are traditionally ruled out, as Datalog's evaluation
algorithms fail to terminate on such programs.  Similarly, for \lang, we want
to somehow constrain programs that fail to terminate, given any bounded EDB.
Given a finite universe of constants---i.e., restricting entanglement and
summary aggregates---it is clear that modulo time, a \lang program can
only compute a finite model.  
\jmh{we can't just say ``modulo time''.  this requires more careful definition.}
The only possible termination issue then is that
a set of facts may exhibit {\em non-convergence}: oscillation in time.  Given
that the finiteness of the universe implies a finite period of oscillation, we
can either compute a finite representation of these non-convergent derivations
in the style of Chomicki et al.~\cite{chomicki-infinite} or a {\em partial
fixpoint}~\cite{abiteboul-vianu}, which regards non-convergent derivations as
false.

If finiteness of the universe cannot be guaranteed, we can fall back on
conservative syntactic conditions presented in~\cite{dedalus-techr} that
guarantee the existence of a finite model.

\rcs{wrm agreed the following paragraph needs to be moved/rewritten, but I forget where.  Note that the following only holds for analyses of confluence.  We might want to check other properties, such as invariants over a trace that we collect and process at runtime.  Such analyses are probably more interested in network events than the ultimate model.  Other analyses probably want to check other things...}

\wrm{tie in this def better}
\begin{definition}
%
An {\em incremental model} at time $T$ of trace $R$ of a \lang instance $I$,
represented by $\mathcal{M}_{I,T}(R)$, is the contents of all
relations at time $T$.
%
\end{definition}

\jmh{don't think you've introduced ``simply persisted'' yet.  Meanwhile, can't we say time $t=\infty$}
\begin{definition}
%
The {\em ultimate model} of trace $R$ of a \lang instance $I$, represented by
$\mathcal{U}_I(R)$, is the eventual contents of the simply persisted relations
(ignoring timestamps).
%
\end{definition}

In the general case, we are not interested in the full model of a trace of an
instance: facts that are only ephemerally true represent events, or intermediate
computations, which intuitively should not be considered as part of the output
of the program.  We are only interested in the program's {\em ultimate
  model}---the eventual contents of the simply persisted relations (ignoring
timestamps).
\paa{sort of.  but those ephemeral tuples provide ground for future inductive deductions, no?}
\paa{also (unrelated to previous comment) perhaps make reference to the correspondence with eventual consistency
(if it has been introduced yet}

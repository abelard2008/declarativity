\section{Properties}

blah blah blah

\subsection{Temporal Stratification}

\wrm{begin paste -- find a new home}
We first turn our attention to the semantics of
programs with negation.  As we will see, the inclusion of time introduces a
``source of monotonicity'' in programs that allows for clean minimal model
semantics in some surprising cases, and enables purely syntactic monotonicity
checks for a broad class of temporal programs.

\begin{lemma} \label{lemma:no-neg-unique}
%
A \slang program without negation 
has a unique minimal model.
%
\end{lemma}

\begin{proof} 
%
A \slang program without negation 
is a pure Datalog
program.  Every pure Datalog program has a unique minimal model. 
%
\end{proof}

We define syntactic stratification of a \slang program the same way it is
defined for a Datalog program:

\begin{definition}
%
A \slang program is \emph{syntactically stratifiable} if there
exists no cycle with a negative edge 
in the program's
predicate dependency graph.
%
\end{definition}

We may evaluate such a program in {\em stratum order} as described in the
Datalog literature~\cite{ullmanbook}.
It is easy to see that any syntactically stratified \slang instance has a
unique minimal model because it is a syntactically stratified Datalog program.
\paa{fix}

However, many programs we are interested in expressing are not syntactically
stratifiable.  Fortunately, we are able to define a syntactically checkable
notion of {\em temporal stratifiability} of \slang programs that maps to a
subset of {\em modularly stratifiable}~\cite{modular} Datalog programs.

\begin{definition} 
%
The \emph{deductive reduction} of a \slang program $P$ is
the subset of $P$ consisting of exactly the deductive rules in $P$.
%
\end{definition}

\begin{definition} 
%
A \slang program is \emph{temporally stratifiable} if its deductive
reduction is syntactically stratifiable.
%
\end{definition}

%%\newtheorem{theorem}{Theorem}
\begin{lemma}
\label{lemma:temp-strat-uniq}
%
Any temporally stratifiable \slang instance $P$ has a unique minimal model.
%
\end{lemma} 


\begin{example}
\label{ex:stratsafe}
A simple temporally stratifiable and temporally safe \slang instance that is neither syntactically stratifiable nor safe.

\begin{Dedalus}
persist[p, 2]  
  
r1
p(A, B) \(\leftarrow\)
  insert\_p\_req(A, B);

r2  
delete p(A, B) \(\leftarrow\)
  p(A, B),
  del\_p\_req(A);

insert\_p(1, 2)@1;
\end{Dedalus}
\end{example}

In the \slang program in Example~\ref{ex:stratsafe}, 
\emph{insert\_p} and \emph{delete\_p} are captured
in EDB relations.  This reasonable program is unstratifiable because $p \succ
p\nega \land p\nega \succ p$.  But because the successor relation is
constrained such that $\forall A,B, successor(A, B) \rightarrow B > A$, any
such program is modularly stratified on \emph{successor}.  Therefore, we have
$p_{n} \not\succ^* p\_neg_{n} \not\succ^* p_{n+1}$; informally, earlier values
do not depend on later values.

Given this discussion, in practice we are interested in three asynchronous scenarios: (a) monotonic programs (even with non-monotonicity in time), (b) non-monotonic programs whose semantics guarantee monotonicity of time suffixes  and (c) non-monotonic programs where we have domain knowledge guaranteeing monotonicity of time suffixes.  Each represents practical scenarios of interest.

The first category captures the spirit of many simple distributed implementations that are built atop unreliable asynchronous substrates.  For example, in some Internet publishing applications (weblogs, online fora), it is possible due to caching or failure that a ``thread'' of discussion arrives out of order, with responses appearing before the comments they reference.  In many cases a monotonic ``bag semantics'' for the comment program is considered a reasonable interface for readers, and the ability to tolerate temporal anomalies simplifies the challenge of scaling a system through distribution.

The second scenario is achieved in \slang via the use of \dedalus{successor} for the time suffix. The asynchronous rules of \lang require additional program logic to guarantee monotonic increases in time for predicates with dependencies.  In the literature of distributed computing, this is known as a {\em causal ordering} and is enforced by distributed clock protocols.  We review one classic protocol in the \lang context in Section~\ref{sec:lamport}; including this protocol into \lang programs ensures temporal monotonicity.

Finally, certain computational substrates guarantee monotonicity in both timestamps and message ordering---for example, some multiprocessor cache coherency protocols achieve this.  When temporal monotonicity is given, the proofs of temporal stratification and Algorithm~\ref{alg:tsn} both apply.
\wrm{end paste}

So far, we have not restricted asynchronous rules to prevent {\em time travel} -- a condition where an asynchronous rule gives rise to derivations that precede their antecedents in time.  While time travel is acceptable for monotonic logic, it is undesirable in general, as a fact may derive its own negation (intuitively, a ``temporal paradox.'')  Thus, an additional condition is required to exclude such contradictions.

In an asynchronous distributed system, nodes are assumed to have their own clocks, which may run at any arbitrary speed.  Nodes assign a timestamp to an incoming fact that is greater than the timestamp of any existing fact.  Note that this condition excudes time travel.

%\dedalus{@async} is clearly more liberal than our operational semantics defined above.  One of our goals is formal verification of distributed systems.  Thus, for the particular use-case of distributed execution with the above operational semantics, we need to discover a logical condition that results in a set of models that exhibit the same set of behaviors.  It is  necessary and sufficient for each fact to carry an entangled timestamp from each node.  Timestamps must be propagated through derivations \wrm{explain}.  When a node receives a fact, it will need to delay processing of the fact until its current time is greater than its entangled timestamp.  Note that this scheme employs vector clocks.

%Note that the use of Lamport clocks enforces additional constraints by ruling out more possible interleavings of events than the operational semantics for timestamp assignment. \wrm{check if this is true}
%\paa{we'll put the lamport clock discussion here, then?}

\subsection{Temporal Safety}

\wrm{begin paste}
In the previous section we demonstrated that \slang can capture
intuitive notions of persistence and mutability of state via a
stylized use of Datalog.  However, the alert reader will note that
even very simple \slang programs make for unusual Datalog.
%%: among other concerns, 
To begin with, persistence rules are unsafe, as they produce derivations for an infinite number
of values of the time suffix.  Traditional Datalog interpreters, which
work against static databases, would attempt to enumerate these
values, making this approach impractical.
Equally worrisome is the fact that many common patterns for state update via mutable
persistence entail unstratifiable constructs: predicates that syntactically depend on their
own (possibly transitive) negation.  

However, in the context of distributed systems and networks, the need
for non-terminating ``services'' or ``protocols'' that continually update their
state
is very common.  In this section we show that expressing distributed systems properties
such as persistence and mutable state in logic does not require
dispensing with familiar notions of safety and stratification: we take
traditional notions of acceptable Datalog programs, and extend them in
a way that admits sensible non-terminating programs.

\subsection{Temporal Safety}
Next we consider the issue of infinite results raised in the introduction to this section.
In traditional Datalog, this is a well-studied concern.
A Datalog program is considered {\em safe} if it has a finite minimal model, and hence has
a finite execution.  Safety in Datalog is traditionally ensured
through the following syntactic constraints:

\begin{enumerate}
%
\item No functions are allowed.
%
\item Variables are \emph{range restricted}: all attributes of the head goal
appear in a non-negated body subgoal.
%
\item The EDB is finite.
%
\end{enumerate}


\wrm{end paste}

Next we consider the issue of infinite results.  In traditional Datalog, a Datalog program is considered safe if it has a finite
minimal model, and hence has a finite execution. Safety in Datalog is ensured by requiring a finite universe of constants \wrm{cite}.

In Dedalus, the program's result is the limit of the program as time goes to infinity.  Nonconvergence is a special case that we handle in the style of a {\em partial fixpoint}: nonconvergent facts are considered to be false.  Other work has proposed the use of infinite objects to represent nonconvergent results \wrm{cite chomicki}.  Absent entanglement, the set of convergent facts is always finite and can be efficiently computed \wrm{cite the paper that has the algorithm for this}.  Additionaly, we presented conservative syntactic conditions in previous work to guarantee convergence for all EDBs \wrm{cite tech report}.

However, in this work, we regard the limit of the program as only those predicates declared {\em naively persistent}.  \wrm{how do we ensure finiteness????}

\subsection{Properties of Asynchronous Derivations}

Having ensured, via variants on traditional Datalog techniques, that there will always exist 
stable models of \lang programs that are free of contradictions and which will quiesce in the absence of input, we now turn to a problem that is specific to the domain of asynchronous
distributed systems: the effects of delay, loss and reordering of messages. We would like to
characterize a class of \lang programs that have the same semantics regardless of
the nondeterminism in {\em async} rules.  We clearly cannot rely on naive equality of stable
models, as models of the same program with different {\em async} rule applications will differ
(at least) in the timstamps of tuples.  

\paa{I don't know how to say this 'at infinity' stuff; I am back at max...}
\begin{definition}
Consider the stable model $M$ resulting from a fixpoint evaluation of a \lang program P over a finite input trace.  The \emph{ultimate model} $U$ of $M$ is the model obtained by selecting only the tuples of $M$ with the highest timestamp in $M$, dropping the timestamp attribute,
and removing duplicate tuples
\end{definition}

In other words, we may obtain the ultimate model of a \lang execution from one of its stable
models by {\em selecting} tuples corresponding to the ``end of time,'' and projecting out time.
If all stable models of a \lang program and trace produce the same ultimate model, we say that the program and trace are \emph{trace confluent}, and if a program is trace confluent for all traces we say that the program is \emph{confluent}.

We can immediately identify a subset of the class of confluent programs:
the class $D$ of negation-free \lang programs in which all predicates have basic 
persistence rules associated with them.  

\begin{definition}
The \emph{atemporal reduction} P' of a \lang program P is the program obtained by replacing 
the unified time variable in all rule bodies with a unique variable per predicate.  \paa{special case for inductive and async rules}
\end{definition}

We say a \lang program is \

\begin{lemma}
In negation-free dedalus programs
\end{lemma}

\paa{having trouble, return to this.  the point is, are there dedalus programs for which async
is always semantically insignificant?  yes, these are the monotonic dedalus programs which persist their async inputs.}

In practice, however, programs that monotonically accumulate information and never \emph{do} 
anything with it are rare in the distributed systems domain.  


\paa{below are notes}

when can we say that the ND choice of timestamp in async rules does not affect the outcome
of a computation?  in the general case, it almost always does (since 'outcome' implies finality,
and thus rules out the possibility of choosing a timestamp after the outcome that could affect the outcome.
\wrm{huh?  the ND choice of timestamp doesn't affect the outcome if it ``doesn't affect the outcome'' (i.e. regardless of the choice value, i still get the same set of facts in the naively persistent relations, for all EDBs)  are you looking for some conservative syntactic condition?}

we can reason, however, about order independence on a predicate-by-predicate basis, and this
can significantly simplify how we reason about the replication/distribution of state in the
global program.  informally, we say that any predicate all of whose possible derivations 
do not transit across async rules is order-independent \wrm{a queue doesn't involve async, but it's order dependent}, but this is vacuous b/c those derivations
are fundamentally unordered (well, order is hidden in the interpreter).  more substantively,
we may say that by default, all event predicates (all predicates to a first approximation) 
are order-dependent b/c the choice of timestamp determines all of their semantics.  
can we restore order independence?  yes: perist the predicate.  now any tuple inserted will
"be there at infinity" -- the only ordering detail of semantic significance is now the 1st 
timestamp of peristence.  and even this matters only when program logic is nonmonotonic. \wrm{you also need that the inputs are either transitively dependent on only EDB, or are persisted, right?}

a program with negation (aggregation, shipping, summarization) may decide at some time N
that a predicate is false, and conclude stuff from it, only to have the predicate become
true at some M > N \wrm{don't see a problem here}.  this means conclusions exists that are inconsistent with valuations at
infinity \wrm{don't know what this means}.  we know precisely the circumstances under which this may occur:

consider a predicate p in a dedalus program and the subgraph of the program's RGG that 
defines the predicate.  p's semantics are order-insensitive if:

1. in the global graph from EDB facts, timers etc, there are no stratum boundaries save those encapsulated in the choice expansion.

2. following each async rule, there is a simple persistence rule.  (we can generalize this some,
but not a heck of a lot.  a predicate p is 'basically' persistent of there exists a cycle in the RGG 
with exactly one inductive edge and all other edge (possibly 0) deductive, in which the 
bindings of p are preserved from p (as premise) to p (as conclusion), and in which either no other predicates participate, or in which we can show that any participating predicate is always true.

we can see that these conditions imply order-insensitivity wrt ``in-flight'' tuples bound for p.
any pair of tuples will end up in p and be there ``at some time'' if the network quiesces, at 
which time we may consider the timestamp irrelevant.  and p is order-insensitive in this respect,
though operations including join, till the next stratum boundary.

but can we weaken the conditions?  in general it looks hard.  take (1): if we have indeed crossed a stratum boundary, we have in essence decided ``at some time'' that some predicate is closed to insertion, by universally quantifying over it (to assert its complement, summarize it, ship it, whatever).  recall p() from above.  a rule that negates p() in a subgoal could succeed between 
two async insertions of p() tuples, which thus clearly do not commute.  the 'committed choice'
pattern is a rudimentary illustration of 'sealing' a nonmonotonic consequence: log is defined 
in terms of its own negation.  the 'assignment' pattern is a rudimentary example of... um, I guess a rule that isn't persistent (violates 2) b/c notin condition is clearly not "always true."  ditto the
mutable state pattern.




um, idempotence.

um, efficient lazy evaluation?  \cite{magic}

\section{Properties}
\label{sec:properties}

%guarantee the non-existence of
%nontrivially periodic derivations in a program for all EDBs.
%But what
%exactly is the result of a \lang program?  For Datalog programs, the result is
%the program's model.  However, in \lang, the program's model includes 

%We can apply a result of Chomicki et al. \wrm{cite} to prove that
%using traditional Datalog-style safety restrictions (no functions, no
%entanglement, finite EDB, range-restricted variables), we can always
%efficiently compute a {\em partial fixpoint} of a \lang program.  A partial
%fixpoint includes all {\em convergent} (forever persisted) derivations, and
%excludes all {\em nonconvergent} (nonpersistent, or nontrivially periodic
%derivations).  Other work has proposed the use of infinite objects to represent
%nonconvergent derivations \wrm{cite chomicki}.  Additionally, \wrm{cite}
%presents conservative syntactic conditions to guarantee the non-existence of
%nontrivially periodic derivations in a program for all EDBs.

Having established the existence and finiteness of an ultimate model, we now
study the effects of non-determinism on the ultimate model.  In particular, we
study under what conditions there exists a unique ultimate model for a \lang
instance.  However, we note that one may desire a more lenient criterion on the
ultimate model: for example, a programmer may settle for a guarantee that at
checkout, the shopping cart application charges the user only once---but
possibly for a subset of the items in her cart.
%We defer the study of these advanced correctness criteria to future work.

%\subsection{Properties of Asynchronous Derivations}

%We would like to characterize a class of
%asynchronous \lang programs that are deterministic in the face of this
%non-determinism.
%We clearly cannot rely on equality of models over all time, as models of the
%same program with different {\em async} rule applications will likely differ
%(at least) in the timestamps of tuples.  However, we would like to say that
%these differences do not matter, and define determinism based on the {\em
%eventual} equivalence of models at some timestamp.

%\begin{definition}
%Consider a stable model $M$ resulting from a fixpoint evaluation of a \lang
%program P over a finite input trace.  In other words, we may obtain the
%eventual model of a \lang execution from one of its stable models by {\em
%selecting} tuples corresponding to the ``end of time,'' and projecting out
%time.  If all stable models of a \lang program and EDB trace produce the same
%ultimate model, we say that the program and trace are \emph{trace confluent},
%and if a program is trace confluent for all EDBs we say that the program is
%\emph{confluent}.
%The \emph{eventual model} of a \lang instance is the eventual contents of the
%simply persisted relations (ignoring timestamps).
%
%\end{definition}

%Every safe \lang program has a finite eventual model, and there is a
%well-known decision procedure for calculating the model \wrm{cite chomikci,
%partial fixpoint stuff}. \wrm{In practice, due to magic sets, this isn't
%horribly inefficient}~\cite{magic}

%\jmh{I'd prefer if any other basic terminology used here was  defined with similar formality and formatting when first introduced.  It makes jumping into the formal stuff much quicker -- you can more easily find all the necessary defs from before.  So far I think all that's missing is the definition for `instance'}
\begin{definition}
%
If all traces of a \lang instance produce the same ultimate model, then we call
the instance {\em trace confluent}.
%
\end{definition}

\begin{definition}
%
If every instance of a program is trace confluent, then we say the program is
{\em confluent}.
%
\end{definition}

\noindent{}It is easy to see that every \lang program without \dedalus{async}
rules is confluent, as the trace is empty.

\begin{definition}
%
Two traces $R_1, R_2$ are in the same associativity class if they contain the
same facts (ignoring time), and the timestamp of fact $f$ in $R_1$ is less than
or equal to the timestamp of fact $g$ in $R_1$ if and only if the same is true
in $R_2$.
%
\end{definition}

\begin{definition}
%
Two traces are in the same commutativity class if they contain the same facts
(ignoring time), and there exists a bijection $m$ between the $t$ in $R_1$ and a
subset of $\mathbb{N}$, such that all facts in $R_1$ with timestamp $t$, exist in $R_2$ with timestamp $m(t)$.
%
\end{definition}

\begin{definition}
%
We say that a \lang program is {\em associative} if, for any instance $I$,  the
ultimate models for any two traces of $I$ in the same associativity class are
equal.
%
\end{definition}

\begin{definition}
%
We say that a \lang program is {\em commutative} if, for any instance $I$, the
ultimate models for any two traces of $I$ in the same commutativity class are
equal.
%
\end{definition}

\begin{lemma} \label{lem:assoc-comm}
%
For any two traces $R_1, R_2$ that have the same facts (ignoring timestamps),
$R_1$ is in the same commutativity class as a trace $R_3$ (with the same facts,
ignoring timestamps) , which is in the same associativity class as $R_2$.
%
\end{lemma}

\subsection{Associativity}

%\begin{definition}
%
%We say that two traces $R_1, R_2$ of a \lang instance have the same
%associativity grouping if $\forall t \in$ \dedalus{time} $\forall i,j \in
%\{1,2\} \forall F \subset \mathcal{H} \exists s \in$ \dedalus{time} $: F@t
%\subset T_i \land F \subset T_i \cap T_j \implies F@s \subset T_j$. \wrm{change
%this intersection to be an intersection modulo time}
%
%\end{definition}

\begin{definition}
%
A support of a fact $f$ in a \lang instance is a set of facts $E$ that is
necessary and sufficient to imply $f$.  If $E$ implies $F$ through negation or
aggregation, then we call $E$ a negative support.  If all $e$ in $E$ are
non-negated, then we call $E$ a positive support.
%
\end{definition}

It is clear if a fact $f$ has $\{f\}$ as its only support, then $f$ is a fact
in an extensional predicate.

\begin{definition}
%
A complete support of a fact $f$ in a \lang instance is a set of sets of facts
$\{E_1, ..., E_n\}$, such that $E_1$ is part of the EDB, and $E_1$ is a support
for $E_2$, ..., is a support for $E_n$, which is a support for $f$.
%
\end{definition}

It is clear that every fact in all incremental models of a trace of a \lang
instance without negation or aggregation has a positive support.  In a trace of
a \lang instance with negation and/or aggregation, some facts may have only
negative supports.

\begin{lemma} \label{lem:mon-assoc}
%
A \lang program without negation or aggregation is confluent if and only if it
is associative.
%
\end{lemma}
%

\begin{proof}
%
It is clear that the confluence of a \lang program implies its
associativity: if a confluent \lang program is not associative, then there is
some instance $I$ and two traces $R_1, R_2$ in the same associativity class for
which the ultimate model is not the same; this contradicts the fact that the
program is confluent.

If a negation- and aggregation-free \lang program is associative, we will show
that any arbitrary instance of the \lang program is trace confluent.   Assume
there exists a non-trace-confluent \lang instance $I$ with an associative
program.  That is, there are two traces $R_1, R_2$ for $I$, such that (without
loss of generality)
%$\exists i,j \in \{1,2\}: i \neq j \and \exists f \in \mathcal{U}_I(R_i): f
%\not\in \mathcal{U}_I(R_j)$.  Consider $g$, the ``first'' such $f$, that is
%the $f$ that no 
$\exists f \in \bigcup_{t \in \text{time}} \mathcal{M}_{I,T}(R_1) \land f
\not\in \bigcup_{t \in \text{time}} \mathcal{M}_{I,T}(R_2)$.  Let $g$ be the
$f$ that has a complete support (with a possibly different assignment of
timestamps) in $\bigcup_{t \in \text{time}} \mathcal{M}_{I,T}(R_2)$.  We know
there exists at least one such $g$, because if such a $g$ does not exist, then
either no $f$ exists or some $f$ is part of its own complete support.  Because
\lang rules must unify on time, the support of $g$ in $\bigcup_{t \in
\text{time}} \mathcal{M}_{I,T}(R_2)$ does not necessarily imply $g$ for an
abitrary program.  However, because we know that the program has no negation or
aggregation, the order of facts does not affect the ultimate model (and thus
the program is commutative), so we need only worry about associativity.  By
Lemma~\ref{lem:assoc-comm}, we know that $g$'s support in $\bigcup_{t \in
\text{time}} \mathcal{M}_{I,T}(R_2)$ is in the same commutativity class as
something in the same associativity class as $g$'s support in $\bigcup_{t \in
\text{time}} \mathcal{M}_{I,T}(R_1)$.  Because we know the program is
associative, $g$ exists in $\bigcup_{t \in \text{time}}
\mathcal{M}_{I,T}(R_2)$.  By induction, the set of $f$ is empty, which
contradicts our assumption that it was non-empty.  Thus, a negation- and
aggregation-free associative \lang program is always confluent.
%
\end{proof}

Note that a simple way to ensure associativity of a monotonic program is to
persist all relations that appear in the head of an \dedalus{@async} rule.
This ensures that all support will be true at some timestamp.  However, this
does not ensure associativity of a non-monotonic program, because a fact in a
non-monotonic program may be implied through negation or aggregation.

%Another way to ensure associativity of a monotonic program is to use a
%queue-like construct to only consider one fact derived in an \dedalus{@async}
%predicate per timestamp.  \jmh{but then the program is not monotonic.  and why are bothering to make this point?}

%Since we do not consider the time suffix as part of the ultimate model, how can
%non-determinism in time suffixes affect the ultimate model?  In purely
%monotonic programs, the only issue that can arise is that some derivations may
%not be {\em associative} -- the assignment of the same timestamp to two facts
%may cause a different result than the assignment of a distinct timestamp to
%each fact.  Intuitively, this is because we force unification on time suffixes
%in the body.  Persistence of async relations \nrc{Don't you mean ``rules'', not ``relations''?} solves this by making all
%derivations associative: there will eventually be a timestamp where all async
%derivations ever received are coincidentally true.\nrc{Don't grok this.}

% peter got freaked out by this, so i commented it out -wrm
%\wrm{provide example here?}  Concretely, consider the committed choice
%example in Section~\ref{sec:assignment-and-committed-choice}, which
%inserts the first value of \dedalus{condition(A,\_)} into \dedalus{log}.
%Careful readers may have noticed that, if multiple conflicting
%\dedalus{condition} tuples appear in the same timestamp, multiple
%conflicting values will be inserted into the \dedalus{log} relation.
%An associativity analysis would automatically detect such bugs.
%Furthermore, non-associative rules can always be transformed \rcs{true, right?}
%into associative rules by introducing {\em tie breaking} predicates
%and aggregates; in the committed choice example, we would simply
%replace the left hand side of the second rule
%(\dedalus{log(A,B)@next}) with \dedalus{log(A,min<B>)@next}.

%joe got freaked out by this, so commenting it out -wrm
%Alternatively, we can avoid the need for such rewrites by restricting
%the set of permissible executions, just as we did to disallow temporal
%paradoxes.  From a pragmatic perspective, we have found that it is
%convenient to process each arriving event atomically before processing
%the next.  Doing so ensures that our programs are trivially
%associative; two events will never arrive simultaneously.  This
%greatly simplifies our programs.

%joe got freaked out by this, so commenting it out -wrm
%From a model theoretic perspective, we apply a compile-time rewrite
%that duplicates each \dedalus{@next} rule, leaving one copy intact,
%and replacing the head of the other with \dedalus{busy(1)@next}.
%Instead of delivering tuples directly, \dedalus{@async}'s choice
%construct inserts the tuples into a queue, as in
%Section~\ref{sec:priority-queues}.  For each timestamp \dedalus{T}
%where \dedalus{busy(1)@T} is not defined, we dequeue and deliver
%exactly one tuple.\rcs{bill had some nice things to say about this approach regarding analysability, etc...}

%joe got freaked out by this, so commenting it out -wrm
%From an operational perspective, this allows \lang programs to
%leverage large bodies of existing work in database concurrency control
%and compiler optimization techniques that automatically parallelize
%code, strengthen loops, and so on.\rcs{cite two textbooks?}  \rcs{Naturally, programs that make use of imperative constructs will complicate such techniques; such issues existed in overlog, and led to semantic ambiguities that complicated earlier research.  We believe that \lang's foundation in logic will largely avoid such issues.  -- (Not sure we want so say this, or that we can back it up)}



%We can immediately identify a subset of the class of confluent \lang programs:
%the class $D$ of monotonic \lang programs, where all predicates have simple
%persistence rules.  Intuitively, any instance of a program in $D$ is trace
%confluent because its ultimate model corresponds exactly to the model of the
%Datalog program obtained by converting all temporal and async rules into
%deductive rules and evaluating a single Datalog fixpoint.  Deductions via
%async rules introduce nondeterminism into the time suffixes of predicates.
%However, the simple persistence of all predicates ensures that for
%some value of the time suffixes, all deductions that can be made will be made.

\subsection{Commutativity}

Consider the following example:

\begin{Dedalus}
persist[r,2]
persist[p,2]
persist[q,1]

r(A, B) \(\leftarrow\) p(A, B), \(\lnot\) q(A);

q(A)@async \(\leftarrow\) e(A);
p(A, B)@async \(\leftarrow\) f(A, B);

e(1)@10;
f(1, 2)@4;
f(3, 4)@11; 
\end{Dedalus} 

This example illustrates that a non-monotonic program is not necessarily
confluent, even when async predicates are simply persisted.  In addition to
associativity, {\em commutativity} is now an issue: if we swap the timestamps
of two messages, we might swap the order of existential and universal
quantification.  In the example, all traces in which \dedalus{p} is assigned a
lower timestamp than \dedalus{q} lead to an ultimate model including
\dedalus{r(1,2)}.  However, if \dedalus{q} precedes \dedalus{p}, or is
co-incident with \dedalus{p}, then \dedalus{\(\lnot\) q(A)} is false, and the
ultimate model excludes \dedalus{r(1,2)}.

\begin{lemma}
%
A \lang program is confluent if and only if it is associative and commutative.
%
\end{lemma}

\begin{proof}
%
It is clear that the confluence of a \lang program implies its associativity
and commutativity, using the same reasoning as in Lemma~\ref{lem:mon-assoc}.

If a \lang program is associative and commutative, we will show that any
arbitrary instance of the \lang program is trace confluent.  The proof is
identical to that of Lemma~\ref{lem:mon-assoc}, except instead of relying on
the monotonicity of the program to ensure commutativity, we know the program is
explicitly commutative.
%
\end{proof}

%\jmh{the next paragraph needs more time ... introduce the concern more carefully, and I think it's worth formally making the argument as a lemma, since the mode of reasoning here is important to a lot of our notions of fine-grained monotonicity.  and I don't think it's ``easy to see'' since we never explained the Sacca/Zaniolo choice thing in detail.}
At this stage, the careful reader may be concerned that our ``monotonic''
programs permit async rules, as async rules use the \dedalus{choice} construct,
which makes use of negation.  However, it is easy to see that the universal
quantification in \dedalus{choice} happens over the \dedalus{time} set, which
is always fully defined.  In other words, universal quantification of
\dedalus{time} commutes with any other operation in the program.

%In either case, nonmontonic \wrm{need to define} reasoning (which is easily
%spotted in a logic program) entails applying the \emph{closed world
%assumption} \wrm{need to define} to a predicate which, if it transitively
%depends upon an async derivation, is never really closed \wrm{need to
%clarify}.

\subsection{Identifying Points of Order}
%\jmh{tighten up this para}
The previous section provided a conservative test for confluence: all monotonic
programs with simply persisted asynchronous predicates are confluent.  In
practice, however, programs that monotonically accumulate information and never
perform some non-monotonic operation on it are rare in the distributed systems
domain.

%Non-monotonic operations in general imply universal quantification, such as
%aggregation (e.g., computing a sum) and negation (determining the
%non-existence of a fact).  Universal quantification allows the non-determinism
%of asynchronous systems to influence the ultimate model, because the universal
%quantification may occur before all messages have been received, and results
%of this ``incomplete'' quantification may be forever persisted.  Reduction in
%general implies universal quantification, whether it involves aggregation
%(e.g., computing a sum), negation (e.g., asserting that %some fact does
%\emph{not} hold because the fact does not exist in our model) or shipping a
%``final'' version of a relation to another location, and in \lang, such
%constructs can only be expressed with syntactically transparent nonmonotonic
%constructs.  

How do we maintain confluence in the presence of non-monotonicity?  We must
introduce points of order into our program.  We present a conservative
syntactic test that identifies all places where points of order may be
required.  Our test is based on the concept of a program's {\em predicate
dependency graph} (PDG) from the Datalog literature.  A \lang program's PDG is
a directed graph that has one node per predicate in the A PDG has an edge from
\dedalus{p} to \dedalus{q} if $\dedalus{p} \succ \dedalus{q}$.  If $\dedalus{p}
\succ \lnot\dedalus{q}$, then the edge is annotated with a $\lnot$.  If
$\dedalus{p} \gets \dedalus{q}$, then the edge is annotated with a $+$, and if
$\dedalus{p} \leftsquigarrow \dedalus{q}$, then the edge is annotated with a
$@$.  Note that an edge may not be annotated with both $+$ and $@$, but the
$\lnot$ annotation can coexist with either $+$ or $@$.

\begin{definition}
%
A monotonic component is a maximal connected subgraph with no $\lnot$ edges,
and all predicates at the end of $@$ edges simply persisted.
%
\end{definition}

The test consists of constructing the PDG, determining the monotonic
components, and identifying the edges between monotonic components as loci
where a point of order may be necessary.  A point of order is never necessary
within a monotonic component, because a monotonic component is confluent.
We have expressed this test in our \lang 
interpreter, using a meta-model to treat rules as data.  Later, we present graphs of programs that
identify monotonic components.  The data for these graphs was generated by our
\lang code that expresses this test.

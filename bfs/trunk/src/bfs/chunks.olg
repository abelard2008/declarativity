program bfs_chunks;

import java.lang.System;
import java.util.Set;

define(chunkSeq, keys(0), {String, Integer});
//watch(chunkSeq, ae);

/*
public
chunkSeq(Master, Top+1) :-
    bfs::self(Master),
    notin chunkSeq(Master, _);
*/

// XXX: this "timer" is a hack
timer(per, physical, 1000, 1000, 1000);
public
chunkSeq(Master, 1) :-
    bfs::self(Master),
    per(_, _, _),
    notin chunkSeq(Master, _);

// if we get a "NewChunk" request for a file, create a new chunk id
public
chunkSeq(Master, ChunkId+1) :-
    chunkSeq(Master, ChunkId),
    candidate_datanode#insert(Master, _, _, ChunkId, _);

define(candidate_datanode, keys(0, 1), {String, Integer, String, Integer, Set});
public
candidate_datanode(Master, Id, FPath, NewChunkId, set<DataNode>) :-
    bfs::request(Master, Id, _, "NewChunk", FPath),
    chunkSeq(Master, NewChunkId),
    bfs::possible_choices(Master, Cnt, DataNode, _),
    bfs::fpath(Master, FPath, FileId),
    bfs::file(Master, FileId, _, _, false),
    notin candidate_datanode(Master, Id, FPath, _, _);

// reuse the newchunk request dataflow to migrate bfs_heartbeat::chunks
// from one datanode to another
define(chunkMigration, keys(0,1,2), {String, String, Integer, Integer, Set});
watch(chunkMigration, ae);
public
chunkMigration(Master, DnWithReplica, ChunkId, CurrRepCnt, set<DataNode>) :-
    bfs_heartbeat::newReplica(Master, ChunkId, DnWithReplica, CurrRepCnt, _),
    bfs::migration_choices(Master, DataNode, ChunkId),
    bfs_heartbeat::representative_datanode(Master, ChunkId, DnWithReplica);

public
delete
bfs_heartbeat::newReplicaRequest(Master, ChunkId, DnWithReplica, CurrRepCnt, Time) :-
    bfs_heartbeat::newReplicaRequest(Master, ChunkId, DnWithReplica, CurrRepCnt, Time),
    chunkMigration#insert(Master, DnWithReplica, ChunkId, CurrRepCnt, _);

watch(send_migrate, ae);
send_migrate(@DnWithReplica, Master, ChunkId, CurrRepCnt, Dns) :-
  chunkMigration(@Master, DnWithReplica, ChunkId, CurrRepCnt, Dns);

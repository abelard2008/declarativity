program bfs_chunks;

import java.lang.System;
import java.util.Set;

define(candidate_datanode, keys(0, 1), {String, Integer, String, Set});
public
candidate_datanode(Master, Id, FPath, set<DataNode>) :-
    bfs::request(Master, Id, _, "NewChunk", FPath),
    bfs::possible_choices(Master, _, DataNode, _),
    bfs::fpath(Master, FPath, FileId),
    bfs::stasis_file(Master, FileId, _, _, false),
    notin candidate_datanode(Master, Id, FPath, _);

// reuse the newchunk request dataflow to migrate bfs_heartbeat::chunks
// from one datanode to another
define(chunkMigration, keys(0,1,2), {String, String, Integer, Integer, Set});
watch(chunkMigration, ae);
public
chunkMigration(Master, DnWithReplica, ChunkId, CurrRepCnt, set<DataNode>) :-
    bfs_heartbeat::newReplica(Master, ChunkId, DnWithReplica, CurrRepCnt, _),
    bfs::migration_choices(Master, DataNode, ChunkId),
    bfs_heartbeat::representative_datanode(Master, ChunkId, DnWithReplica);

public
delete
bfs_heartbeat::newReplicaRequest(Master, ChunkId, DnWithReplica, CurrRepCnt, Time) :-
    bfs_heartbeat::newReplicaRequest(Master, ChunkId, DnWithReplica, CurrRepCnt, Time),
    chunkMigration#insert(Master, DnWithReplica, ChunkId, CurrRepCnt, _);

watch(send_migrate, ae);
send_migrate(@DnWithReplica, Master, ChunkId, CurrRepCnt, Dns) :-
  chunkMigration(@Master, DnWithReplica, ChunkId, CurrRepCnt, Dns);

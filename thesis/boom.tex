\chapter[Declarative Scheduling]{Declarative Scheduling}
\label{ch:boom}

The Berkeley Orders Of Magnitude (BOOM) project began with an experiment in
construction, by implementing a substantial piece of distributed software in a
data-centric, declarative style.  Upon review of recent literature on
data center infrastructure (e.g.,~\cite{chubby,gfs-sosp,dynamo,mapreduce-osdi}),
we observed that most of the complexity in these systems related to the
management of various forms of asynchronously-updated state, including
sessions, protocols and storage.  Although quite complex, few of these systems
involved intricate, uninterrupted sequences of computational steps.  Hence, we
suspected that data center infrastructure might be a good initial litmus test
for our hypotheses about building distributed software.

We evaluated this hypotheses in {\em \BOOMA}: an API-compliant reimplementation
of the HDFS distributed file system and the Hadoop MapReduce
engine~\cite{boom}.  Our declarative version of these two components were named
{\em \BOOM-FS} and {\em \BOOM-MR}, respectively.  In writing \BOOMA, we
preserved the Java API ``skin'' of HDFS and Hadoop, but replaced complex
internal state with relations, and implemented key system logic with code
written in a declarative language.  In this thesis, we focus on declarative
scheduling (\BOOM-MR), rather than \BOOM-FS which was led by other members of
the \BOOMA team.  However, we do include some \BOOM-FS results --- showing its
performance is on par with HDFS --- to validate the \JOL implementation, which
was a project within this thesis.

The remainder of this chapter is organized as follows.
Chapter~\ref{ch:boom:sec:jol} describes a new Java-based \OVERLOG library,
which we used to execute \OVERLOG programs within the (Java-based) Hadoop
infrastructure.  In Chapter~\ref{ch:boom:sec:port}, we discuss the \BOOM-MR
scheduling harness; embedded in the \JT component of Hadoop.
Chapter~\ref{ch:boom:sec:hadoop} reviews the scheduling state and protocol
implemented by Hadoop version 18.2, which we modeled in our declarative code.
Chapter~\ref{ch:boom:sec:tables} captures the entities and relationships of the
Hadoop scheduler in four (catalog) tables.  Using these tables, we describe a
scheduling policy in Chapter~\ref{ch:boom:sec:scheduler} that models the Hadoop
FIFO policy.  We then extend these rules in Chapter~\ref{ch:boom:sec:late} with
the LATE policy for scheduling ``speculative'' tasks.
Chapter~\ref{ch:boom:sec:eval} evaluates the performance of jobs scheduled by
our declarative FIFO policy against those scheduled by the original
(unmodified) Hadoop scheduler.  Finally, Chapter~\ref{ch:boom:sec:relwork}
examines some of the related work and Chapter~\ref{ch:boom:sec:conclusion}
concludes with a summary of our experience with \BOOMA.

\section{Java \OVERLOG Library (JOL)}
\label{ch:boom:sec:jol}

In previous chapters we witnessed P2's lack of support for stratified Datalog
forced us to implement a number of imperative hacks, which often involved
(event) manipulations of the underlying dataflow fixpoints.  Most of these
hacks were required for detecting the termination of a group of rules, which
would have been implicitly handled by imposing a natural stratum boundary
(e.g., count aggregate).  Our workaround involved adding a number of conditions
that detected stratum boundaries, and ensured that these ``conditions'' were
evaluated in separate P2 dataflow fixpoints.  This was a hard lesson, which led
us to develop an entirely new \OVERLOG implementation that supported stratified
Datalog.  We briefly describe this new Java \OVERLOG Library (JOL), which we
used to implement the remaining \OVERLOG programs described in this thesis.

Like P2, \JOL compiled \OVERLOG programs into pipelined dataflow graphs of
operators (similar to ``elements'' in the Click modular router~\cite{click}).
\JOL provided {\em metaprogramming} support akin to P2's Evita Raced extension
(Chapter~\ref{ch:evita}): each \OVERLOG program is compiled into a
representation that is captured in rows of tables.  Program testing,
optimization and rewriting could be written concisely as metaprograms in
\OVERLOG that manipulated those tables.

The \JOL system matured when we targeted the Hadoop stack, which required tight
integration between \OVERLOG and Java code.  The latest version of \JOL
included Java-based extensibility in the model of Postgres~\cite{postgres}.  It
supported Java classes as abstract data types, allowing Java objects to be
stored in fields of tuples, and Java methods to be invoked on those fields from
\OVERLOG.  \JOL also allowed Java-based aggregation functions to run on sets of
column values, and supported Java {\em table functions}: Java iterators
producing tuples, which can be referenced in \OVERLOG rules as ordinary
relations.  We made significant use of these features in \BOOMA; using native
Hadoop data structures as column types (Chapter~\ref{ch:boom:sec:tables}), and
integrating with legacy Hadoop code (Chapters~\ref{ch:boom:sec:fifo}
and~\ref{ch:hop:sec:jolport}).

%In addition, inspired by the ideas of Evita Raced, we metaprogrammed \JOL's
%core execution loop and scheduler in \OVERLOG as well.  Rather than using a
%traditional event loop, in \JOL all inbound events (i.e., tuples) are passed
%into a single dataflow compiled from the system's runtime metaprogram.  This
%dataflow ``routes'' tuples to appropriate branches corresponding to different
%rules, using a scheduler specified in \OVERLOG.  Space prevents a thorough
%discussion of this design, but we mention it here because of our experience
%modifying the runtime rules as described in Chapter~\ref{sec:perf}.

\section{\BOOM-MR: MapReduce Scheduler}
\label{ch:boom:sec:port}

In this section, we describe our declarative version of the Hadoop MapReduce
scheduler, which we called \BOOM-MR.  Using \BOOM-MR, we explored embedding a
data-centric rewrite of a non-trivial component into an existing procedural
system.  MapReduce scheduling policies are one issue that has been treated in
recent literature (e.g.,~\cite{zaharia-late,delay-sched}).  To enable credible
work on MapReduce scheduling, we wanted to remain true to the basic structure
of the Hadoop MapReduce codebase, so we proceeded by understanding that code,
mapping its core state into a relational representation, and then writing
\OVERLOG rules to manage that state in the face of new messages delivered by
the existing Java APIs.

\subsection{Hadoop MapReduce Scheduler}
\label{ch:boom:sec:hadoop}

We briefly review the Hadoop scheduling logic that we modeled in \OVERLOG.  The
Hadoop architecture consists of a single master node called the {\em \JT} that
manages a number of worker nodes called {\em {\TT}s}.  A job is divided into a
set of map and reduce {\em tasks}.  The {\JT} assigns tasks to worker nodes.
Each map task reads an input chunk from the distributed file system, runs a
user-defined map function, and partitions output key/value pairs into hash
buckets on the local disk.  Reduce tasks are created for each hash bucket.
Each reduce task fetches the corresponding hash buckets from all mappers, sorts
locally by key, runs a user-defined reduce function and writes the results to
the distributed file system.

Each {\TT} has a fixed number of slots for executing tasks (two maps and two
reduces by default).  A heartbeat protocol between each {\TT} and the {\JT} is
used to update the {\JT}'s bookkeeping of the state of running tasks, and drive
the scheduling of new tasks: if the {\JT} identifies free {\TT} slots, it will
schedule further tasks on the {\TT}.  Also, Hadoop will attempt to schedule
{\em speculative} tasks to reduce a job's response time if it detects
``straggler'' nodes~\cite{mapreduce-osdi}.

\subsection{Table-izing MapReduce}
\label{ch:boom:sec:tables}

\BOOM-MR is a port of the Hadoop \JT code to \OVERLOG.  Here, we identify the
key state maintained by the {\JT}.  This includes both data structures to track
the ongoing status of the system and transient state in the form of messages
sent and received by the {\JT}.  We captured this information in the four
\OVERLOG relations shown in Table~\ref{ch:boom:tbl:hcatalog}.

\begin{table}
\ssp
\centering
\begin{tabular}{|l|l|p{8cm}|} \hline
\textit{Name}   & \textit{Description} & \textit{Relevant attributes} \\ \hline\hline
job         & Job definitions    & \underline{JobId}, Priority, SubmitTime, Status, JobConf \\ \hline
task         & Task definitions  & \underline{JobId}, \underline{TaskId}, Type, Partition, Status \\ \hline
taskAttempt  & Task instance   & \underline{JobId}, \underline{TaskId}, \underline{AttemptId}, Progress, State, Phase, Tracker, InputLoc, Start, Finish \\ \hline
taskTracker  & {\TT} state  & \underline{Name}, Hostname, State, MapCount, ReduceCount, MaxMap, MaxReduce\\ \hline
\end{tabular}
\caption{\BOOM-MR relations defining {\JT} state.}
\label{ch:boom:tbl:hcatalog}
\end{table}

The \ol{job} relation contains a single row for each job submitted to the
{\JT}.  In addition to some basic metadata, each job tuple contains an
attribute called the $JobConf$, which holds a Java object constructed by legacy
Hadoop code.  This object captures the configuration parameters that pertain to
a single MapReduce job.  The \ol{task} relation identifies each task within a
job using attributes that specify the task type (map or reduce), the input
``partition'' (a chunk for map tasks, a bucket for reduce tasks), and the
current running status.

A task may be attempted more than once, due to speculation or if the initial
execution attempt failed.  The \ol{taskAttempt} relation maintains the state of
each such attempt (one per row).  In addition to a progress percentage and a
state (running/completed), we maintain a task phase i.e., reduce tasks can be
in any one of three phases: copy, sort, or reduce.  The $Tracker$ attribute
identifies the {\TT} assigned to execute the task attempt.  Map tasks also need
a record containing the location of their input data, which is given by
$InputLoc$.

The \ol{taskTracker} relation identifies each {\TT} in the cluster with a
unique name.  This relation includes attributes that provide the hostname,
current running state, and the \TT workload.  Specifically, the $MapCount$ and
$ReduceCount$ attributes specify the current number of map and reduce tasks
that are executing on the \TT.  The maximum number of map and reduce tasks that
the \TT is able to support is given by the $MaxMap$ and $MaxReduce$ attributes;
this is in keeping with the Hadoop implementation, which specifies a fixed
number of slots that can execute tasks.

%Our \OVERLOG rules update these {\JT} tables by converting status updates from
%heartbeat messages to \ol{job}, \ol{taskAttempt} and \ol{taskTracker} tuples.
%These rules are mostly straightforward.  Scheduling decisions are encoded in
%the \ol{taskAttempt} table, which assigns tasks to {\TT}s.  A scheduling policy
%is simply a set of rules that join against the \ol{taskTracker} relation to
%find \TT{}s with unassigned slots, and schedules tasks by inserting tuples into
%\ol{taskAttempt}.  This architecture makes it easy for new scheduling policies
%to be defined.

\subsection{MapReduce Scheduling in \OVERLOG}
\label{ch:boom:sec:scheduler}

MapReduce scheduling has been the subject of much recent
research~\cite{delay-sched, zaharia-late, hadoopdb, asterix, aster, greenplum},
and one of our early motivations for building \BOOMA was to make this research
extremely easy to carry out.  In our initial \BOOM-MR prototype, we implemented
Hadoop's default First-Come-First-Served (or FIFO) policy for task scheduling,
which we captured in $9$ rules ($96$ lines).  We then extended these rules with
the recently-proposed LATE policy~\cite{zaharia-late} to evaluate both (a) the
difficulty of prototyping a new policy, and (b) the faithfulness of our
\OVERLOG-based execution to that of Hadoop using two separate speculation
algorithms.

\subsubsection{First-Come-First-Served Scheduling}
\label{ch:boom:sec:fifo}

\begin{figure}
\label{fig:joborder}
\ssp
\centering
\begin{lstlisting}
s1 minWaitingJobPriority(a_min<Priority>) :-
   job(JobId, Priority, Status, ...),
   Status < JobStatus.FINISHED;
	
s2 minWaitingJobPrioritySubmitTime(Priority, a_min<SubmitTime>) :-
   job(JobId, Priority, Status, SubmitTime, ...),
   Status < JobStatus.FINISHED;

s3 highestPriorityJob(JobId) :-
   minWaitingJobPriority(Priority),
   minWaitingJobPrioritySubmitTime(Priority, SubmitTime),
   job(JobId, Priority, Status, SubmitTime, ...);
\end{lstlisting}
\caption{\label{ch:boom:fig:joborder}The highest priority job that still has unscheduled tasks ($StartTime < 0$).}
\end{figure}

The FIFO policy schedules tasks from the job with the highest priority.  A
job's scheduling order is defined by its $Priority$ followed by its
$SubmitTime$ (see \ol{job} schema in Table~\ref{ch:boom:tbl:hcatalog}).  The
tasks from the job that is first in the scheduling order are scheduled before
the tasks in any other jobs.

Figure~\ref{ch:boom:fig:joborder} captures this constraint in three rules,
which identify the job whose tasks are considered first when \TT slots are
available.  Rule \ol{s1} identifies the job with the overall minimum priority,
while rule~\ol{s2} determines, for each job priority, what is the earliest
submit time.  Both rules~\ol{s1} and~\ol{s2} only consider jobs that have unscheduled
tasks, shown here by considering the \ol{Status < JobStatus.FINISHED}
predicate.  Rule \ol{s3} joins the result of rules \ol{s1} and \ol{s2} to
identify the overall highest priority job with unscheduled tasks.  The
\ol{highestPriorityJob} predicate is used to constrain task scheduling rules
to only consider unscheduled tasks from the specified job.

Scheduling individual tasks from the highest priority job occurs when a \TT
performs a heartbeat exchange with the \JT and has some number of available map
or reduce task slots.  Tasks are scheduled based on slot availability; if a
task slot is available then schedule a task from the job with the highest
priority.  To avoid data movement costs, the scheduling policy tries to
schedule the map task close to a machine that hosts its input data.  Ideally,
it schedules a map task whose input resides on the same machine or rack.  If no
such option exists then an arbitrary map task is scheduled, without considering
other queued jobs.  Concurrent to this work, Zaharia et al.\ introduced Delay
Scheduling~\cite{delay-sched}, which delayed scheduling tasks on machines that
did not offer good locality.  Their results achieved perfect locality --- all
tasks scheduled close to the input data --- and no task was delayed for more than
five seconds.

\begin{figure}
\ssp
\centering
\begin{lstlisting}
/* Assign each task a locality score on the given tracker. */
s4 mapTaskLocality(TaskId, Tracker, Locality) :-
   heartbeat(Tracker, TrackerStatus, MapSlots, ReduceSlots),
   hightestPriorityJob(JobId),
   task(JobId, TaskId, Type, _, InputSplits, StartTime, _),
   StartTime < 0, Type == ``map'',
   {
     if (InputSplits.contains(TrackerStatus.getHost())) { 
       Locality := 1; // same machine
     } else if (InputSplits.contains(TrackerStatus.getRack()) { 
       Locality := 2; // same rack
     } else {
       Locality := 3;
     }
   };
	
/* For each task tracker, list the k best map tasks to 
   schedule, where k == MapSlots.  The result of this 
   will be added to the schedule relation, which is 
   returned to the TaskTracker. */
s5 schedule(Tracker, bottomK<MapID, MapSlots>) :-
   mapTaskLocality(TaskId, Tracker, Locality),
   heartbeat(Tracker, TrackerStatus, MapSlots, ReduceSlots),
   TrackerStatus == TaskTrackerStatus.RUNNING,
   MapSlots > 0,
   MapID := new OrderedMapID(TaskId, Locality);

\end{lstlisting}
\caption{\label{ch:boom:fig:schedule} Map task locality priority scheduler.}
\end{figure}

Returning to the default Hadoop policy, Figure~\ref{ch:boom:fig:schedule} shows
two rules that together implement, a locality aware, Hadoop FIFO policy.  When
a \TT heartbeat is received, rule \ol{s4} assigns a locality metric to
unscheduled tasks that belong to the highest priority job.  \JOL supports the
ability to add Java code at the end of a rule body, delineated within brackets
\{ ...  \}.  This Java code executes last in the rule body, and will only see
those tuples that represent actual deductions.~\footnote{A useful feature for
\ol{printf} style debugging.} In rule \ol{s4}, the bracketed Java code assigns
a {\em locality} metric according to the proximity of the heartbeat \TT to the
map input data.

The result of rule \ol{s4} is evaluated in rule \ol{s5}, which schedules the
map tasks whose input resides closest to the heartbeat \TT.  The {\bf bottomK}
aggregate orders the $MapID$s from lowest to highest $Locality$ and chooses the
lowest $K$ map tasks in this order, not exceeding the number of available map
slots ($MapSlots$).  Each result tuple from rule \ol{s5} is converted, through
a few imperative steps in the Java language, into a schedule action message
that is returned to the \TT in the RPC call made to the \JT.  The reduce task
scheduling rule simply schedules reduces tasks from the highest priority job
based on the availability of reduce slots from the heartbeat \TT, as per stock
Hadoop.

\subsection{Task Speculation in \OVERLOG}
\label{ch:boom:sec:late}

\begin{figure}[p]
\ssp
\begin{lstlisting}
/* Compute progress rate per task */
l1 taskPR(JobId, TaskId, Type, ProgressRate) :-
   task(JobId, TaskId, Type, _, _, _, Status),
   Status.state() == RUNNING,
   Time := Status.finish() > 0 ? Status.finish() : 
             java.lang.System.currentTimeMillis(),
   ProgressRate := Status.progress() / (Time - Status.start());

/* For each job, compute 25th pctile rate across tasks */
l2 slowTaskThreshold(JobId, Type, a_percentile<0.25, PRate>) :-
   taskPR(JobId, TaskId, Type, PRate);

/* Compute progress rate per tracker */
l3 trackerPR(Tracker, JobId, Type, a_avg<PRate>) :- 
   task(JobId, TaskId, Type, _),
   taskAttempt(JobId, TaskId, _, Progress, State, Phase, 
               Tracker, Start, Finish),
   State != FAILED,
   Time := Finish > 0 ? Finish : java.lang.System.currentTimeMillis(),
   PRate := Progress / (Time - Start);

/* For each job, compute 25th pctile rate across all trackers */
l4 slowNodeThreshold(JobId, Type, a_percentile<0.25, AvgPRate>) :-
   trackerPR(_, JobId, Type, AvgPRate);

/* Compute available map/reduce slots that can be used for 
   speculation. */
l5 speculativeCap(a_sum<MapSlots>, a_sum<ReduceSlots>) :-
   taskTracker( ... MapCount, ReduceCount, MaxMap, MaxReduce),
   MapSlots    := java.lang.Math.ceil(0.1 * (MaxMap - MapCount)),
   ReduceSlots := java.lang.Math.ceil(0.1 * (MaxReduce - ReduceCount));
\end{lstlisting}
\caption{\OVERLOG to compute statistics for LATE.}
\label{fig:latePolicy}
\end{figure}

With the basic scheduling logic behind us, we turn now to the topic of
scheduling speculative tasks.  The LATE policy presents a scheme for scheduling
speculative tasks based on {\em straggler} tasks~\cite{zaharia-late}.  There
are two aspects to each policy: choosing which tasks to speculatively
re-execute, and choosing {\TT}s to run those tasks.  Original Hadoop
re-executes a task if its progress is more than 0.2 (on a scale of $[0..1]$)
below the mean progress of similar tasks.  LATE, on the other hand, chooses to
re-execute tasks via an {\em estimated finish time} metric that is based on the
task's {\em progress rate}.  Moreover, it avoids assigning speculative tasks to
{\TT}s that exhibit slow performance executing similar tasks, in hopes of
preventing further stragglers.

The LATE policy is specified in the paper~\cite{zaharia-late} via three lines
of pseudocode, which makes use of three performance related statistics called
$SlowNodeThreshold$, $SlowTaskThreshold$ and $SpeculativeCap$.  The first two
statistics correspond to the $25^{th}$ percentiles of progress rates across
{\TT}s and across tasks, respectively.  The $SpeculativeCap$ indicates the
maximum number of speculative tasks allowed at any given time, which is
suggested to be set at $10\%$ of the total available task slots.

We compute these thresholds via the five \OVERLOG rules shown in
Figure~\ref{fig:latePolicy}.  A task is only considered for speculation if its
progress rate falls below the $SlowTaskThreshold$ in its given category: job
identifier ($JobID$) and task type ($Type$).  Queries \ol{l1} and \ol{l2}
maintain this threshold value for each category.  Query \ol{l1} determines the
progress rate for a given task based on its current progress and running time.
Query \ol{l2} computes the $SlowTaskThreshold$, for each category, by
determining the lower $25^{th}$ percentile of the progress rates.

The LATE policy ensures that speculative tasks execute on ``fast'' nodes by
pruning \TT nodes whose rate of progress for a given task category fall below
some threshold.  Queries \ol{l3} and \ol{l4} maintain this threshold value for
each category.  The first query \ol{l3}, computes the average progress that a
given \TT has made for each task category and stores that result in the
\ol{trackerPR} table.  Query \ol{l4} computes the $SlowNodeThreshold$ for each
category by determining the 25th percentile for each category of progress rates
stored in the \ol{trackerPR} table.  Finally, query \ol{l5} counts the number
of slots that can be used for task speculation.  Integrating the rules into
\BOOM-MR required two additional \OVERLOG rules that 1) identify tasks to
speculatively re-execute, and 2) select an ideal {\TT}(s) on which to execute
those tasks, all while obeying the SpeculativeCap value.

\section{Evaluation}
\label{ch:boom:sec:eval}

We now validate our declarative specification of both Hadoop's default FIFO
policy and the LATE policy proposed by Zaharia et al.~\cite{zaharia-late}.  Our
goals were both to evaluate the difficulty of building a new policy, and to
confirm the faithfulness of our \OVERLOG-based {\JT} to the Hadoop {\JT} when
using a logically identical scheduling policy and with the additional LATE
policy.

%First, we compare our code size and development time.  Implementing the default
%FIFO policy required 9 rules (96 lines of code).  Implementing the LATE policy
%required 5 additional \OVERLOG rules (30 lines of code).  In comparison, LATE
%is specified in Zaharia et al.'s paper via just three lines of pseudocode, but
%their implementation of the policy for stock Hadoop required adding or
%modifying over $800$ lines of Java spread across $18$ Java class files --- an
%order of magnitude more than our \OVERLOG implementation.  To be fair, the
%Java-based implementation represents production quality code, which increases
%code complexity and adds to the overall development time.  Nevertheless, much
%of this complexity comes from mapping LATE to a language that focuses on
%imperative steps rather than high-level specifications.

We evaluated our \OVERLOG policies using a 101-node virtual cluster on Amazon
EC2.  One node executed the Hadoop \JT and the HDFS \NN, while the remaining
100 nodes served as ``workers'' for running the Hadoop {\TT}s and HDFS {\DN}s.  Each
{\TT} was configured to support up to two map tasks and two reduce
tasks simultaneously.  The master node ran on a ``high-CPU extra large'' EC2
instance with 7.2 GB of memory and 8 virtual cores.  Our worker nodes executed
on ``high-CPU medium'' EC2 instances with 1.7 GB of memory and 2 virtual cores.
Each virtual core is the equivalent of a 2007-era 2.5Ghz Intel Xeon processor.


\subsection{FIFO policy}

\begin{figure*}
\ssp
\centering
	\includegraphics[scale=0.75]{figures/fourgraphs}
\caption{CDFs representing the elapsed time between job startup and task
  completion for both map and reduce tasks, for all combinations of Hadoop and \BOOM-MR
  over HDFS and \BOOM-FS\@.  In each graph, the horizontal axis is
  elapsed time in seconds, and the vertical represents the percentage of tasks completed.}
\label{fig:ec2experiment}
\end{figure*}

While improved performance was not a goal of our work, we wanted to ensure that
the performance of \BOOMA was competitive with Hadoop.  The workload was a
wordcount job on a 30 GB file, using 481 map tasks and 100 reduce tasks.

Figure~\ref{fig:ec2experiment} contains four graphs comparing the performance of
different combinations of Hadoop MapReduce, HDFS, \BOOM-MR, and \BOOM-FS\@. Each
graph reports a cumulative distribution of the elapsed time in seconds from job
startup to map or reduce task completion. The map tasks complete in three
distinct ``waves.'' This is because only 2 $\times$ 100 map tasks can be
scheduled at once. Although all 100 reduce tasks can be scheduled immediately,
no reduce task can finish until all maps have been completed because each reduce
task requires the output of all map tasks.

The lower-left graph describes the performance of Hadoop running on top of HDFS,
and hence serves as a baseline for the subsequent graphs. The upper-left graph
details \BOOM-MR running over HDFS\@. This graph shows that map and reduce task
durations under \BOOM-MR are nearly identical to Hadoop 18.2. The lower-right
and upper-right graphs detail the performance of Hadoop MapReduce and \BOOM-MR
running on top of \BOOM-FS, respectively. \BOOM-FS performance is slightly
slower than HDFS, but remains competitive.


\subsection{LATE policy}

We now compare the behavior of our LATE implementation with the results
observed by Zaharia et al.\ using Hadoop MapReduce.  LATE focuses on how to
improve job completion time by reducing the impact of ``straggler'' tasks.  To
simulate stragglers, we artificially placed additional load on six nodes.  We
ran the same wordcount job on 30 GB of data; using 481 map tasks and 400 reduce
tasks, which produced two distinct ``waves'' of reduce tasks.  We ran each
experiment five times, and report the average over these runs.

Figure~\ref{fig:ec2reduce} shows the reduce task duration CDF for three
different configurations.  The plot labeled ``No Stragglers'' represents normal
load, while the ``Stragglers'' and ``Stragglers (LATE)'' plots describe
performance in the presence in stragglers using the default FCFS policy and the
LATE policy, respectively.  We omit map task durations, because adding
artificial load had little effect on map task execution --- it just resulted in
slightly slower growth from just below 100\% to completion.

\begin{figure*}
\ssp
  \centering
  \includegraphics[scale=0.75]{figures/reduce_stragglers}
  \caption{CDF of reduce task duration (secs), with and without stragglers.}
  \label{fig:ec2reduce}
\end{figure*}

The 200 reduce tasks were scheduled concurrently with the map step.  This first
wave of reduce tasks cannot enter the reduce phase until all the map tasks have
completed, which increased their duration, and resulted in the large runtime
durations indicated in the right portion of the graph.  The second wave of 200
reduce tasks did not experience this delay due to unfinished map work since
these reduce tasks were scheduled after all map tasks had finished.  The second
wave of reduce tasks are reported in the left portion of the graph.
Consequently, stragglers had less of an impact on the second wave of reduce
tasks since fewer resources (i.e., no map work) were being consumed.
Figure~\ref{fig:ec2reduce} shows this effect, and also demonstrates how the
LATE implementation in {\BOOMA} handles stragglers much more effectively than
the default Hadoop policy.  This echoes the results reported by Zaharia et
al.~\cite{zaharia-late}

\section{Related Work}
\label{ch:boom:sec:relwork}

Declarative and data-centric languages have traditionally been considered useful
in very few domains, but things have changed substantially in recent years.
MapReduce~\cite{mapreduce-osdi} has popularized functional dataflow programming
with new audiences in computing.  Also, a surprising breadth of recent research
projects have proposed and prototyped declarative languages, including overlay
networks~\cite{p2:sosp}, three-tier web services~\cite{hilda}, natural language
processing~\cite{dyna}, modular robotics~\cite{meld}, video games~\cite{cornellgames}, 
file system metadata analysis~\cite{wiscfsck}, and compiler analysis~\cite{bddbddb}.

Most of the languages cited above are declarative in the same sense as SQL: they are 
based in first-order logic. Some --- notably MapReduce, but also SGL~\cite{cornellgames} --- are
algebraic or dataflow languages, used to describe the composition of operators that produce and 
consume sets or streams of data.  Although arguably imperative, they are far closer to logic languages 
than to traditional imperative languages like Java or C, and are often amenable to set-oriented optimization 
techniques developed for declarative languages~\cite{cornellgames}. Declarative and dataflow languages 
can also share the same runtime, as demonstrated by recent integrations of MapReduce and SQL
in Hive~\cite{hive-vldb}, DryadLINQ~\cite{DryadLINQ}, HadoopDB~\cite{hadoopdb}, and products from vendors 
such as Greenplum and Aster.

Concurrent with our work, the Erlang language was used to implement a simple MapReduce framework called 
Disco~\cite{disco} and a transactional DHT called Scalaris with Paxos support~\cite{scalaris}. Philosophically, Erlang 
revolves around concurrent {\em actors}, rather than data. A closer comparison of actor-oriented and data-centric design 
styles is beyond the scope of this dissertation, but an interesting topic for future work.

\section{Summary}
\label{ch:boom:sec:conclusion}

The initial version of \BOOM-MR required one person-month of development time
and an additional two person-months debugging and tuning \BOOM-MR's performance
for large jobs.  The final version of \BOOM-MR contained declarative
specifications for the core task scheduler (9 rules), the speculative task
scheduler (5 rules), recovery from failed tasks (3 rules), and maintenance of
various job and task related statistics (5 rules).  In total, \BOOM-MR
consisted of 22 \OVERLOG rules in 156 lines of code, and 1269 lines of Java.
\BOOM-MR was based on Hadoop version 18.2; we estimate that we removed 6,573
lines of code (out of 88,863) from the \ol{org.apache.hadoop.mapred} Hadoop
package.  

%For this ``porting'' exercise, it was handy to leverage \JOL's Java interfaces
%and draw the Java/\OVERLOG boundaries flexibly.  This allowed us to focus on
%porting the more interesting Hadoop logic into \OVERLOG, while avoiding ports of
%relatively mechanical details.  For example, we chose to leave the data
%representation of the {\em jobConf} as a Java object rather than flatten it
%into a relation because it had no effect on the scheduling logic.

In the end, we found that scheduling policies were a good fit for a declarative
language like \OVERLOG.  In retrospect, this is because scheduling can be
decomposed into two tasks: {\em monitoring} the state of a system and applying
{\em policies} for how to react to changes to that state.  Monitoring is
well-handled by \OVERLOG: we found that the statistics about {\TT} state
required by the LATE policy are naturally realized as aggregate functions, and
\JOL took care of automatically updating those statistics as new messages from
{\TT}s arrived.  In the next chapter, we will look at importing statistics
taken from the output of a MapReduce job that is continuously monitoring
machine and process level statistics.  Once these near real-time monitoring
statistics have been imported into \JOL, we can build some very interesting
scheduling policies around them.

It is also unsurprisingly that a logic language should be well-suited to
specifying policy.  We found the \BOOM-MR scheduler much simpler to extend and
modify than the original Hadoop Java code, as demonstrated by our experience
with LATE\@.  Informally, the \OVERLOG code in \BOOM-MR seems about as complex
as it should be: Hadoop's MapReduce task coordination logic is a simple and
clean design, and the compactness of \BOOM-MR reflects that simplicity
appropriately.  The extensibility of \BOOM-MR benefited us when we extended the
MapReduce batch-oriented model to one that pipelined data between operators
(Chapter~\ref{ch:hop}); supporting both online aggregation~\cite{onlineagg} and
stream processing~\cite{stream} jobs.  
%Pipelining MapReduce required a more
%aggressive operator coscheduling policy that we captured in a few extra
%\OVERLOG rules, beyond those discussed here.


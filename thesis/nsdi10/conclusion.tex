\section{Conclusion and Future Work}
\label{sec:concl}
MapReduce has proven to be a popular model for large-scale parallel programming. Our Hadoop Online Prototype extends the applicability of the model to pipelining behaviors, while preserving the simple programming model and fault tolerance of a full-featured MapReduce framework.  This provides significant new functionality, including ``early returns'' on long-running jobs via online aggregation, and continuous queries over streaming data.  We also demonstrate benefits for batch processing:  by pipelining both within and across jobs, HOP can 
%achieve increased parallelism, improved system utilization, and 
reduce the time to job completion. 

In considering future work, scheduling is a topic that arises immediately.
Stock Hadoop already has many degrees of freedom in scheduling batch tasks across machines and time, and the introduction of pipelining in HOP only increases this design space.  First, pipeline parallelism is a new option for improving performance of MapReduce jobs, but needs to be integrated intelligently with both intra-task partition parallelism and speculative redundant execution for ``straggler'' handling.
%But given a fixed budget of task slots the cluster can run, pipeline depth has to be traded off against the number of concurrent partitions of a single dataflow stage (a single map or reduce).  We hope to expose these tradeoffs better via a closer analysis of the burstiness of resource consumption in stock Hadoop, and the resulting opportunity to smooth those bursts with pipelined parallelism.  
Second, the ability to schedule deep pipelines with direct
communication between reduces and maps (bypassing the distributed file
system) opens up new opportunities and challenges in carefully co-locating tasks from different jobs, to avoid communication when possible.  
%Finally, pipelining has tradeoffs with the use of map-side combiners.  As noted in Section~\ref{sec:pipelining}, for jobs that generate a small number of distinct reduce keys (e.g., genders), eager pipelining defeats the data reduction opportunities available with a blocking map-side combiner. For jobs with many reduce keys, or with no combiner available (e.g. Sort), aggressive pipelining may be a wise choice, to enable pipelined parallelism.  Since the number of distinct reduce keys is not typically known in advance, the choice of batch sizes for pipelining should be chosen in a dynamic fashion based on introspection during processing.  This introspection could be node-local, or could be a global decision fed by a continuous monitoring query of the sort illustrated in Section~\ref{sec:continuous}.  

Olston and colleagues have noted that MapReduce systems---unlike traditional databases---employ ``model-light'' optimization approaches that gather and react to performance information during runtime~\cite{olston-usenix08}.  The continuous query facilities of HOP enable powerful introspective programming interfaces for this: a full-featured MapReduce interface can be used to script performance monitoring tasks that gather system-wide information in near-real-time, enabling tight feedback loops for scheduling and dataflow optimization.  This is a topic we plan to explore, including opportunistic methods to do monitoring work with minimal interference to outstanding jobs, as well as dynamic approaches to continuous optimization in the spirit of earlier work like Eddies~\cite{eddies} and FLuX~\cite{flux-lb}.

% Inter-job pipelining brings up some interesting opportunities for optimization as well. First, if we have a chain of two jobs, we can have the
% first job write its output to the local disk instead of going to HDFS. This
% saves the HDFS overhead at the expense of the risk of local disk failure.
% Since the intermediate data is relatively ephemeral, the window of risk may be tolerable in many cases. Second, we want to try scheduling maps of second job at nodes where reduces of the first job are running. This way data pipelining will be done locally and will not have to go through the network.

% Online aggregation changes some of the scheduling criteria in cases where there are not enough slots systemwide for all of a job's tasks.  Map and reduce tasks affect an online aggregation job differently: leaving map tasks unscheduled is akin to sampling the input file, whereas leaving reduce tasks unscheduled is akin to missing certain output keys -- some of which could be from groups with many inputs.  This favors reducers over mappers, at least during early stages of processing.  

% In order to improve early results of pipelined flows (e.g., for online aggregation), it is often desirable to prioritize ``interesting'' data in the pipeline, both at the mapper and reducer.  Online reordering of data streams has been studied in the centralized setting~\cite{juggle}, but it is unclear how to expose it in the MapReduce programming framework, with multiple nodes running in parallel -- especially if the data in the input file is not well randomized.  

%Continuous queries over streams raise many specific opportunities for optimizations, including sharing of work across queries on the same streams, and minimizing the work done per query depending on windowing and aggregate function semantics.  Many of these issues were previously considered for tightly controlled declarative languages on single machines~\cite{stream,tcq-cidr}, or for wide-area pipelined dataflows~\cite{borealis,sbon}, and would need to be rethought in the context of a programmable MapReduce framework for clusters.
 % many of which have been well-studied in the literature and should port naturally to a MapReduce setting, as demonstrated in initial work on the topic~\cite{logoyocum08}.  One key issue in the literature is the sharing of work across multiple queries on the same stream~\cite{precisionsharing,huebsch}; but prior work does not necessarily map well to a MapReduce framework, and the issue deserves more investigation.  
%Introspective system monitoring is a good driving application here, since it provides a well-motivated workload that developers of the system are well-motivated to study in depth.  

As a more long-term agenda, we want to explore using MapReduce-style programming for even more interactive applications.  As a first step, we hope to revisit interactive data processing in the spirit of the CONTROL work~\cite{ieeecontrol}, with an eye toward improved scalability via parallelism.  More aggressively, we are considering the idea of bridging the gap between MapReduce dataflow programming and lightweight event-flow programming models like SEDA~\cite{seda}.  Our HOP implementation's roots in Hadoop make it unlikely to compete with something like SEDA in terms of raw performance. However, it would be interesting to translate ideas across these two traditionally separate programming models, perhaps with an eye toward building a new and more general-purpose framework for programming in architectures like cloud computing and many-core.

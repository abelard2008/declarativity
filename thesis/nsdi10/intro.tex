\section{Introduction}
\label{sec:intro}
MapReduce has emerged as a popular way to harness the power of large clusters of
computers. MapReduce allows programmers to think in a \emph{data-centric}
fashion: they focus on applying transformations to sets of data records, and
allow the details of distributed execution, network communication and fault
tolerance to be handled by the MapReduce framework.

MapReduce is typically applied to large batch-oriented computations that are
concerned primarily with time to job completion.  The Google MapReduce
framework~\cite{mapreduce-osdi} and open-source Hadoop system reinforce this
usage model through a batch-processing implementation strategy: the entire
output of each map and reduce task is \emph{materialized} to a local file
before it can be consumed by the next stage.  Materialization allows for a
simple and elegant checkpoint/restart fault tolerance mechanism that is critical
in large deployments, which have a high probability of slowdowns or failures at
worker nodes.

We propose a modified MapReduce architecture in which intermediate data is
\emph{pipelined} between operators, while preserving the programming interfaces
and fault tolerance models of previous MapReduce frameworks. To validate this
design, we developed the Hadoop Online Prototype (HOP), a pipelining version of
Hadoop.\footnote{The source code for HOP can be downloaded from \url{http://code.google.com/p/hop/}}

Pipelining provides several important advantages to a MapReduce
framework, but also raises new design challenges. We highlight the
potential benefits first:
\begin{itemize}
\item
  Since reducers begin processing data as soon as it is produced by mappers,
  they can generate and refine an approximation of their final answer during the
  course of execution. This technique, known as \emph{online
    aggregation}~\cite{onlineagg}, can provide initial estimates of results
  several orders of magnitude faster than the final results.  We
  describe how we adapted online aggregation to our pipelined MapReduce
  architecture in Section~\ref{sec:online}.

\item
  Pipelining widens the domain of problems to which MapReduce can be applied. In
  Section~\ref{sec:continuous}, we show how HOP can be used to support
  \emph{continuous queries}: MapReduce jobs that run continuously, accepting new
  data as it arrives and analyzing it immediately. This allows MapReduce to be
  used for applications such as event monitoring and stream processing.

\item
  Pipelining delivers data to downstream operators more promptly, which can
  increase opportunities for parallelism, improve utilization, and reduce
  response time. A thorough performance study is a topic for future work;
  however, in Section~\ref{sec:perf} we present some initial performance
  results which demonstrate that pipelining can reduce job completion times by
  up to 25\% in some scenarios.
\end{itemize}

Pipelining raises several design challenges. First, Google's attractively simple
MapReduce fault tolerance mechanism is predicated on the materialization of
intermediate state. In Section~\ref{sec:ft}, we show that this can coexist with
pipelining, by allowing producers to periodically ship data to consumers in
parallel with their materialization.  A second challenge arises from the greedy
communication implicit in pipelines, which is at odds with batch-oriented
optimizations supported by ``combiners'': map-side code that reduces network
utilization by performing pre-aggregation before
communication. We discuss how the HOP design addresses this issue in
Section~\ref{sec:intra-pipe}.  Finally, pipelining requires that producers and
consumers are co-scheduled intelligently; we discuss our initial work on this
issue in Section~\ref{sec:pipeline-sched}.

\subsection{Structure of the Paper}
In order to ground our discussion, we present an overview of the Hadoop
MapReduce architecture in Section~\ref{sec:background}.  We then develop the
design of HOP's pipelining scheme in Section~\ref{sec:pipelining}, keeping the
focus on traditional batch processing tasks.  In Section~\ref{sec:online} we
show how HOP can support online aggregation for long-running jobs and illustrate
the potential benefits of that interface for MapReduce tasks.  In
Section~\ref{sec:continuous} we describe our support for continuous MapReduce
jobs over data streams and demonstrate an example of near-real-time cluster
monitoring.  We present initial performance results in
Section~\ref{sec:perf}. Related and future work are covered in
Sections~\ref{sec:relwork} and~\ref{sec:concl}.

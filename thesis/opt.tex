\chapter[Declarative Optimization]{Declarative Optimization}
\label{ch:opt}

Previous chapters described the Evita Raced declarative architecture and its
reuse of the query executor in a stylized fashion to serve as the engine
beneath the query compilation process.  This resulted in an {\em economy of
mechanism}~\cite{Saltzer75theprotection} not afforded by earlier extensible
optimizers (i.e., EXODUS~\cite{exodus}, Starburst~\cite{phh92},
Volcano~\cite{volcano}, OPT++~\cite{opt++}).  In Chapter~\ref{ch:magic}, we
presented our first optimization stage; the magic-sets rewrite, which we
declaratively expressed as a transitive closure over the rule/goal graph of an
\OVERLOG program.

In this chapter we turn our attention to cost-based optimizations, which are
commonly based on dynamic programming algorithms.  We begin in
Section~\ref{ch:opt:sec:related} with a short review of literature on
extensible query optimizers, with further details described in the two
optimizations we discuss.  Section~\ref{ch:opt:sec:systemr} describes a dynamic
programming optimizer stage akin to that of System R.  In
Section~\ref{ch:opt:sec:cascades}, we present a declarative version of the
Cascades branch-and-bound optimizer, which is structured around a dynamic
programming algorithm called ``memoization.'' Based on our experience, we
believe that declarative metacompilation is a clean, architecturally
parsimonious way to build the next generation of extensible query optimizers
for a wide variety of emerging application domains, where the relevant
optimizations are likely to evolve over time.  We conclude in
Section~\ref{ch:opt:sec:summary} with some final thoughts and a summary of our
overall experience with the Evita Raced work.

\section{Related Work}
\label{ch:opt:sec:related}

The pioneering work on extensible query optimizer architectures was done in the
EXODUS~\cite{exodus} and Starburst~\cite{lohman,phh92} systems, which provided
custom rule languages for specifying plan transformations.  The EXODUS
optimizer generator used a forward-chaining production rule language to iteratively
transform existing query plans into new ones.  Follow-on work
(Volcano~\cite{volcano} and Cascades~\cite{cascades}) exposed more interfaces
to make the search in this space of transformations more efficient.  Starburst
had two rule-based optimization stages.  The SQL Query Rewrite stage provided a
production rule execution engine, for ``rules'' that were written imperatively
in C; it included a precedence ordering facility over those rules.  The
cost-based optimizer in Starburst was more declarative, taking a grammar-based
approach to specifying legal plans and subplans.

While all of this work was rule-based and extensible, most of it only exposed
individual plan transformations to extensibility; the actual search algorithms
or transformation orderings of EXODUS, Volcano, Cascades, and the Starburst
cost-based optimizer were confined to procedural code.  By contrast, Evita
Raced does not embed a search algorithm, instead leaving that open to
specification as needed.  As we show in Section~\ref{ch:opt:sec:systemr}, both
the System R bottom-up strategy and the Cascades top-down strategy naturally
fit to a Datalog-based rule language.

Another interesting extensible query optimizer is Opt++~\cite{kabradewitt},
which exploits the object-oriented features of C++ to make an optimizer
framework that was easy to customize in a number of ways.  A specific goal of
Opt++ was to make the search strategy extensible, enabling not only top-down
vs.  bottom-up state-space enumeration, but also randomized search algorithms.
Evita Raced embraces these additional dimensions of extensibility introduced by
Opt++, but provides them in a higher-level declarative programming framework.


\section{System R Optimization}
\label{ch:opt:sec:systemr}

The System R optimizer paper by Selinger, et al.  is the canonical textbook
framework for database query optimization~\cite{selinger}.  The paper laid out
for the first time the notion that query optimization can be decomposed into
two basic parts: query plan cost estimation and plan enumeration.  While this
algorithm is traditionally implemented inside the heart of a database system
via a traditional procedural programming language, both of these tasks are
naturally specified in a declarative query language.  To perform cost
estimation, System~R requires data statistics like relation cardinalities and
index selectivities, which can be packaged into a relational format, and
thereby accessible in the \OVERLOG language.

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
  {\bf def} \ol{optimize}($PREDS$)
    \begin{algorithmic}[1]
	\STATE Let $AM = \emptyset$ be a set of access methods to single relations
  	\FORALL{relations $r \in PREDS$}
		\STATE $AM$ = $AM \bigcup$ all access methods on $r$
  	\ENDFOR
	\STATE
	\STATE $GRP_{AM}$ = GroupBy(f\_equivalent, $AM$)
	\STATE $GRP_{AM}$ = $GRP_{AM} - $ uninteresting ordered groups $\in GP_{AM}$
	\STATE $bestplan[1]$ = ArgMin(f\_cost, $GRP_{AM}$)
	\STATE $BP$ = \ol{search}($bestplan$, $PREDS$, f\_sizeof($PREDS$)) 
	\STATE $bp$ = ArgMin(f\_cost, $BP$) // best overall plan
	\STATE
	\IF{query contains a \ol{group by} or \ol{order by} clause}
		\STATE $bop$ = best ordered plan relative to the clause attributes
		\RETURN Min(f\_sort?($bp$), f\_sort?($bop$))
	\ELSE
	 	\RETURN $bp$
	\ENDIF
    \end{algorithmic}
  {\bf end}
  \\
  \\
  /* Returns a set containing the best size $k$ plans. */ \\
  {\bf def} \ol{search}($bestplan$, $PREDS$, $k$)
    \begin{algorithmic}[1]
  	\IF{$plans[k] = \emptyset$}
	\STATE $BP_{k-1}$ = \ol{bestplan}($bestplan$, $PREDS$, $k-1$)
	\STATE Let $P_{k} = \emptyset$ be a set of size $k$ plans
	\FORALL{plans $bp \in BP_{k-1}$} 
		\FORALL{predicates $p \in PREDS$}
		\STATE $M_k$ = all methods (e.g., join) that take 
			       plan $bp$ (outer) and include $p$ (inner)
		\STATE $P_{k} = P_{k} \bigcup M_k$ 
		\ENDFOR
	\ENDFOR
	\STATE
	\STATE $GRP_{k}$ = GroupBy(f\_equivalent, $P_{k}$)
	\STATE $GRP_{k}$ = $GRP_{k} - $ uninteresting ordered groups $\in GP_{k}$
	\STATE $plan[k]$ = ArgMin(f\_cost, $GRP_{k}$)
	\ENDIF
	\RETURN $plans[k]$ // best plans of size $k$
      \end{algorithmic}
    {\bf end}
\end{boxedminipage}
\caption{\label{ch:opt:fig:systemr}Sketch of the System R optimizer algorithm.}
\end{figure*}

Our focus in this section is on the basic dynamic programming algorithm for the
state-space enumeration at the heart of the System R optimizer.  A sketch of
the System R search strategy is given in Figure~\ref{ch:opt:fig:systemr}, which
finds the optimal plan for a query consisting of a set of predicates (called
$PREDS$).  We focus here on the search strategy, which enumerates query plans for
increasingly-large subgoals of the query optimizer.  It fills in a dynamic
programming table (i.e., $bestplan$ array) with the best plans that cover a given
number of (relational algebra) predicates that appear in the query.  The
dynamic programming task is to fill in this table with the
lowest-estimated-cost query plan among all plans producing an {\em equivalent}
output relation (i.e., plans composed of the same predicates), and among the
plans that produce an ``interesting order.'' If the plan produces tuples in an
order that is relevant to a later join condition, or an ``group/order by''
clause, then it is considered to be an {\em interesting order}~\cite{selinger}.

The \ol{optimize} procedure in Figure~\ref{ch:opt:fig:systemr} takes the set of
predicates mentioned in the query.  For plans of size $1$, we find the optimal
access methods to any relations mentioned in the query.  Note that in P2 the
initial plan (of size one) is the event predicate assigned to the rule by the
delta rewrite (Chapter~\ref{ch:evita:sec:delta}).  The event predicate is used
to initialize the optimization, instead of the traditional approach shown here
as table access methods.  The \ol{bestplan} procedure captures the essence of
generating {\emph plans} of size $k$, and pruning away those plans that are not
optimal, nor interesting.  The \ol{optimize} procedure makes the ``top-level''
call, requesting the best plans containing all predicates in the query.  The
return value contains the set of overall best plans; among each interesting
ordered and unordered plans.  If the query contains a \ol{group by} or
\ol{order by} clause, then we may require sorting depending on the best plan
order.  Moreover, the ideal interesting ordered plan may reduce the cost of, or
even eliminate, this final sort.  In the absence of any ordering constraints,
we simply return the overall optimal plan, regardless of order.

In the System R optimizer, the {\em principle of optimality} is assumed to
hold: the lowest-cost solution to some plan is constructed from the optimal
solutions to subplans.  Thus dynamic programming can conveniently proceed in a
``bottom-up'' fashion.  For a given rule, the optimizer generates plans of size
$k$ terms by appending a single (unused) term from the rule body to an optimal
plan of size $k-1$ terms, as shown in the first loop of \ol{bestplan} in
Figure~\ref{ch:opt:fig:systemr}.  There are a few additional details that we
have chosen to gloss over in the pseudocode.  For instance, avoid combining a
k-way plan with a 1-way plan if there is no join condition between them, unless
all other predicates with join conditions have been used (i.e., postpone
Cartesian products).  We handle this case in our \OVERLOG rules by ensuring the
cost of such an option is greater than any other option that has joining
variables.  Also, in the context of a P2 program, each rule's event predicate
is the ``outermost'' streaming relation in a query plan for the rule.  The
event predicate effectively represents the access method in our declarative
System R rules.

We now turn to describe the \OVERLOG rules for plan generation and conclude
with the rules for best plan selection.  Our declarative optimizer adds two new
tables (\ol{plan} and \ol{bestPlan}) to the Metacompiler Catalog.  The
\ol{plan} table identifies the subgoal and join method for evaluating that
subgoal as the ``inner'' relation.  Each \ol{plan} tuple contains an
identifier, which the \ol{bestPlan} table uses to reference optimal plans.  For
a given rule body term, the $Planner$ stage generates a physical dataflow plan
based on the position and join method assigned in the relevant term relation
(i.e., \ol{sys::predicate}, \ol{sys::assign} and \ol{sys::select}).

Section~\ref{ch:opt:sec:plangen} presents our System R rules for generating
plans (\ol{plan} tuples) from the predicates in the rule body.  Our rules for
selecting a best plan are discussed in Section~\ref{ch:opt:sec:bestplan}, which
also includes a description of how we estimate selectivities.  We then conclude
with our termination rules in Section~\ref{ch:opt:sec:termination}.

\subsection{Plan Generation}
\label{ch:opt:sec:plangen}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr1 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    systemr::programEvent}(@A, Pid, ...),
    sys::predicate}(@A, PredID, Rid, ..., Schema, Pos, ...),
    Pos == $1$,
    PlanID := f_cons(``delta'', PredID),
    Group := f_cons(PredID, null),
    Sort := null,
    Card := 1, Cost := 1.
\end{lstlisting}
\caption{\label{ch:opt:fig:planseed}Plan seed rule.}
\end{figure*}

Figure~\ref{ch:opt:fig:systemr} presents the System R algorithm for plan
generation in two phases.  The first phase generates all access methods, for all
relations mentioned in the query (e.g., in the ``from'' clause).  Subsequent to
that, the second phase enumerates all possible join orders and methods.  Recall
from Section~\ref{ch:evita:sec:delta} that P2 converts a rule into an
event-condition-action (ECA) form, where the event predicate represents a
stream of tuples from the table reference.  As a consequence of this dataflow
design, our first phase simply generates a plan that listens for such event
tuples.  The reader can assume the delta rewrite stage executes before the
System R optimizer stage, and that the delta predicate is in the first rule
position.  

Figure~\ref{ch:opt:fig:planseed} contains the single rule that creates an
initial plan, from each rule in the program, using the delta predicate.  A
\ol{plan} tuple represents a query plan for a given rule, and the plan's
\ol{size} reflects the number of term identifiers covered in the $Group$
attribute (i.e., the number of leaves in the plan tree).  The optimizer listens
on the \ol{systemr::programEvent} event stream in rule \ol{sr1}, which
initiates the optimization process.  The \ol{systemr::programEvent} tuple is
joined with the \ol{sys::rule} table along the $Pid$ (program identifier)
attribute to obtain the set of rules defined in the input program.  The result
set of rule tuples are joined with the \ol{sys::predicate} table along the
$Rid$ (rule identifier) attribute; producing a tuple for each predicate term
defined by a given rule.  The predicate term assigned to position~$1$ ($Pos ==
1$) is by convention the event predicate term.  For each \ol{sys::predicate}
tuple, that references an event predicate, a \ol{plan} of ``size~$1$'' is
derived by rule~\ol{sr1}.  We further note, the $Group$ attribute represents
the initial list of terms (i.e., $PredID$), and the $PlanID$ contains the plan
definition.  As plan generation proceeds, we append new values to the $Group$
and $PlanID$ lists.

The \OVERLOG optimizer defines a set of plan generation rules that together
perform the induction step of the dynamic program.  These rules extend a best
plan of $k$ terms with a $(k+1)^{st}$, thus far unused term from the rule body.
If the new term considered is a table predicate, then the new plan is annotated
with an appropriate join method, which takes the optimal subplan and ``joins
it'' with the predicate table.  The join methods supported by P2 include
scanned and index-nested-loop join, as well as sort-merge join.  A plan tuple
also carries with it an associated cost, which only considers CPU costs since
all P2 relations reside in memory.  We now turn to the description of the rules
that generate plans for nested-loop-join, index nested-loop-join, and
sort-merge join methods.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr2 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :- 
    bestPlan(@A, Pid, Rid, PlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::predicate(@A, PredID, Rid, ..., Tid, PSchema, Pos, ...),
    Pos > 1,
    sys::table(@A, Tid, ..., TCard, Sort),
    f_contains(PredID, OGroup) == false,
    PlanID := f_cons(``nested-loop'', OPlanId, PredID),
    Group  := f_cons(PredID, OGroup),
    Schema := f_joinSchema(OSchema, PSchema),
    Sort   := OSort,
    Card   := OCard * TCard / 10,
    Cost   := OCost + (OCard * TCard).
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen1}nested-loop join method.}
\end{figure*}

Any table predicate appearing in a rule body is given a nested-loop join plan,
derived by rule~\ol{sr2} in Figure~\ref{ch:opt:fig:plangen1}.  The rule is
triggered on an update to the \ol{bestPlan} relation (described in
Section~\ref{ch:opt:fig:bestplan}), which contains the plan identifier
($PlanID$) used to select the reference (optimal) subplan in the \ol{plan}
relation.  Each ``outer'' \ol{plan} tuple contains a list ($OGroup$) of the
predicate identifiers that already appear in it.  This list is used to prune
\ol{sys::predicate} tuples that already participate in the subplan.

The next step is to extend the \ol{plan} tuple with a ``new'' table predicate,
which is done by joining with the \ol{sys::predicate} relation along the same
rule identifier ($Rid$).  The result of this join operation produces all
predicates mentioned in the rule.  To get cardinality information we join with
the \ol{sys::table} predicate.  The selection predicate $PredPos > 1$ ensures
that we do not consider the rule head predicate (the zeroth term by convention)
or the delta predicate (the first term position).  The function $f\_contains$
tests for containment of the predicate in the subplan (outer plan).  The tuples
that meet the constraints imposed thus far, represent new table predicates that
can be used to extend the optimal plan.  These new \ol{plan} tuple deductions
contain the desired join method (``nested-loop'') referenced by the $PlanID$
variable, an associated cost (based on example cardinality estimates), a
new predicate list (see $Group$ variable), and a new schema (see $Schema$
variable).  Finally, the order that the results of this plan exhibit is
identical to the order of the outer plan, which is referenced by the $OSort$
variable.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr3 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    bestPlan(@A, Pid, Rid, PlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::predicate(@A, PredID, Rid, ..., Tid, PSchema, Pos, ...),
    PredPos > 1,
    sys::table(@A, Tid, ..., TCard, Sort),
    sys::index(@A, Iid, Tid, Key, Type, Selectivity),
    f_contains(PredID, OGroup) == false,
    f_indexMatch(OSchema, PSchema, Key),
    PlanID := f_cons(``index-loop'', OPlanID, PredID, Iid),
    Group  := f_cons(PredID, OGroup),
    Sort   := OSort,
    Card   := OCard * (Selectivity * TCard),
    Cost   := OCost + Card.
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen2}index-nested-loop join method.}
\end{figure*}

An index-nested-loop join plan is generated by rule \ol{sr3} in
Figure~\ref{ch:opt:fig:plangen2}.  Like rule~\ol{sr2}, it joins the
\ol{bestPlan}, \ol{plan}, \ol{sys::predicate}, and \ol{sys::table} predicates
to get all table predicates and cardinality estimates for predicates that do
not appear in the $OGroup$.  That result is subsequently joined with the
(additional) \ol{sys::index} predicate, which adds index information to the
result tuples.  The function {\em f\_indexMatch} tests if the index can be used
to perform the join using attributes from the outer plan schema ($OSchema$) and
attributes from the inner predicate table ($PSchema$).  Any resulting tuples
are assigned example cardinality and cost estimates, which now use the
additional {\em index} selectivity information given by the $Selectivity$
\ol{sys::index} predicate variable.  We also support range predicates in our
index-nested-loop join plans but do not discuss them in detail as they are
quite similar to the nested-loop cases above.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr4 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    bestPlan(@A, Pid, Rid, PlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::predicate(@A, PredID, Rid, .. ., Tid, PSchema, Pos, ...),
    PredPos > 1,
    sys::table(@A, Tid, ..., TCard, TSort),
    f_contains(PredID, OGroup) == false,
    JM     := f_sortPlan(OSort, OSchema, PSchema, TSort),
    PlanID := f_cons(``sort-merge'', OPlanID, PredID, JM),
    Group  := f_cons(PredID, OGroup),
    Sort   := f_sortJoinAttributes(OuterSort, OuterSchema, 
                                   PredSchema, TableSort),
    Schema := f_sortMerge(Sort, OuterSchema, PredSchema),
    Card   := OuterCard * (TCard / 10),
    Cost   := f_sortCost(JM, OuterCard, TCard).
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen3}sort-merge join method.}
\end{figure*}

Figure~\ref{ch:opt:fig:plangen3} shows the rule for generating a sort-merge
join plan, which considers a best plan and a new table predicate joined along
some sorting attribute.  The tuples from the outer plan and the inner table
predicate can be ordered by the sorting attribute, or not.  We note that the
$TSort$ attribute in the \ol{sys::table} table identifies the sorting attribute
of the inner relation, while $OSort$ refers to the order of the outer tuples.
The join method variable $JM$ is given a value that indicates the need to
presort the inner relation, or not.  In our implementation of the sort-merge
join operator, we decided not to sort the outer relation by first draining all
of its tuples, sorting them, and then merging with the sorted inner
relation.~\footnote{This would have added significant complexity to the P2
dataflow architecture, which is optimized for tuple at a time processing.}
Instead, each outer tuple is used in a binary search on the sorted inner
relation, which returns any tuples that join along the relevant attributes.  If
we know that the tuples from the outer result will be given in order, then we
can optimize this binary search to be like a merge-join.~\footnote{We maintain
a cursor state on the inner relation that tells us where the last join match
occurred.} These costs are considered by the {\em f\_sortCost} function, which
takes the assigned join method and the input cardinalities and returns a plan
cost.  The output of a sort-join operation includes the join attribute in the
$Sort$ variable.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr5 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    bestPlan(@A, Pid, Rid, PlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::select(@A, Sid, Rid, BoolExpr, ...),
    f_contains(Sid, OGroup) == false,
    f_filter(OSchema, BoolExpr) == true,
    PlanID := f_cons(``filter'', OPlanID, Sid),
    Group  := f_cons(Sid, OGroup),
    Sort   := OSort,
    Schema := OSchema,
    Cost   := OCost,
    Card   := OCard / 3.
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen4}selection predicate filter plan.}
\end{figure*}

Figure~\ref{ch:opt:fig:plangen4} contains a rule that creates a plan out of any
selection predicates in the rule body.  A selection predicate plan is created
when all variables mentioned in its boolean expression ($BoolExpr$) are bounded
by the current outer plan schema ($OSchema$).  Applying a selection filter does
not change the sorting attribute of the outer plan, nor does it effect its
schema.  We assume the cost of a function is negligible, but could easily add a
function that considers certain operational costs.  Furthermore, we use a
generic cardinality estimation but could associate meta-data (e.g., attribute
distributions and min/max values) with the \ol{plan} relation, or some other,
that would allow a more palatable estimator.

\subsection{Best plan selection}
\label{ch:opt:sec:bestplan}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr6 bestOverallCost(@A, Pid, Rid, a_min<Cost>) :-
    plan(@A, Pid, Rid, ..., Cost, ..., Sort).

sr7 bestOrderCost(@A, Pid, Rid, Sort, a_min<Cost>) :-
    interestingOrder(@A, Pid, Rid, PlanID),
    plan(@A, Pid, Rid, PlanID, ..., Cost, ..., Sort).

sr8 interestingOrder(@A, Pid, Rid, PlanID) :-
    plan(@A, Pid, Rid, PlanID, ..., PlanSchema, ..., Sort),
    sys::rule(@A, Rid, Pid, HeadPredID, ...),

    /* The head predicate */
    sys::predicate(@A, Pid, Rid, HeadPredID, ..., HeadPredSchema, ...),

    /* A rule body predicate */
    sys::predicate(@A, Pid, Rid, BodyPredID, ..., BodyPredSchema, ...),
    HeadPredID != BodyPredID,

    /* participates in a later join OR 
       is a prefix of a grouping attribute */
    (f_contains(BodyPredID, Plan) ==  false && 
     f_contains(f_joincond(PlanSchema, BodyPredSchema), Sort)) ||
    f_isPrefix(Sort, HeadPredSchema) ==  true.

sr9 bestPlan(@A, Pid, Rid, PlanID) :-
    bestOverallCost(@A, Pid, Rid, Cost),
    plan(@A, Pid, Rid, PlanID, ..., Cost),

sr10 bestPlan(@A, Pid, Rid, PlanID) :-
     bestOrderCost(@A, Pid, Rid, Sort, Cost),
     plan(@A, Pid, Rid, PlanID, ..., Cost, Sort),
\end{lstlisting}
\caption{\label{ch:opt:fig:bestplan}Best plan selection.}
\end{figure*}

Figure~\ref{ch:opt:fig:bestplan} shows the rules that select the best plan from
a set of equivalent plans, in terms of the output they produce and the order in
which it comes.  The \ol{bestOverallCost} predicate of rule~\ol{sr6} identifies
the plan with the minimum cost from the set of equivalent plans, regardless of
order.  This is followed by rule~\ol{sr7}, which queries the \ol{plan} and
\ol{interestingOrder} relations for the minimum cost plans for each equivalent
interesting order.  Note the purpose of rule~\ol{sr6} is to ensure that an
ordered plan, that is not ``interesting'' but is optimal, is considered.

Rule~\ol{sr8} determines if a plan that is sorted on a given attribute is
interesting.  This occurs in P2 when the plan is sorted along an attribute that
participates in a later join or is a prefix of the grouping attributes.  The
body of this rule joins a \ol{plan} tuple with the \ol{predicate} table, twice,
to get the head predicate and a body predicate that does not already exist in
the plan.  The final selection predicate in this rule checks the necessary
conditions, and if met the rule will deduce an \ol{interestingOrder} tuple for
the given $PlanID$.  The remaining two rules (\ol{sr9} and \ol{sr10}) populate
the \ol{bestPlan} table with the actual optimal plan information.

\subsubsection{Improving Selectivity Estimation}

For equality selection predications, our System R rules above support
selectivity estimates using a uniform distribution estimator given by the
index.  For more precise estimates and to handle range predicates, we have
defined declarative rules that produce equiwidth histograms ({\em
ew-histograms}); additional histogramming rules could be added analogously.
The creation of an ew-histogram is triggered by the installation of a fact in a
metadata table of the ew-histograms defined in the system.  The metadata table
contains the parameters of the histogram (i.e., the table name, the attribute
position, and the number of buckets).  For example, the fact \[
\ol{sys::ewhistogram::metadata}(@LOCALHOST, "pred", 3, 10).  \] creates a ten
bucket equi-width historgram on table \ol{pred} for the attribute in the third
position.

Each fact in the ew-histogram table triggers Evita Raced rules that themselves
generate new rules to create ew-histograms (determining bucket boundaries based
on the bucket count and the min and max values of the attribute), and to
maintain bucket counts (performing a count aggregation over the table
attributes, grouped by the bucket boundaries).  The compiler stage that
generates ew-histograms in this fashion consists of $23$ rules ($92$ lines).
The histogram data is stored in relational format with each row corresponding
to a single bucket.  To exploit these histograms, the cost and selectivity
estimation in the \ol{plan} generation rules in
Figures~\ref{ch:opt:fig:plangen1} and~\ref{ch:opt:fig:plangen2} are modified to
incorporate a join with the histogram data relation, and based on the bucket
boundaries obtain density estimations for a given selection predicate.

\subsection{Termination}
\label{ch:opt:sec:termination}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr11 rules(@A, Pid, a_count<Rid>) :-
     systemr::programEvent(@A, Pid, ...),
     sys::rule(@A, Rid, Pid, ...).

sr12 completeRule(@A, Pid, Rid) :-
     bestPlan(@A, Pid, Rid, _, _, Size, Cost),
     sys::rule(@A, Rid, Pid, ..., Goals),
     Size == Goals - 1.

sr13 completeRuleCount(@A, Pid, a_count<Rid>) :-
     completeRule(@A, Pid, Rid).

sr14 sys::program(@A, Pid, Name, Rewrite, ``systemr'', Text, Msg, 
                  P2DL, Src) :-
     completeRuleCount(@A, Pid, Count),
     rules(@A, Pid, Count),
     sys::program(@A, Pid, Name, Rewrite, Stage, Text, Msg, P2DL, Src).
\end{lstlisting}
\caption{\label{ch:opt:fig:systemrend}System R termination rules.}
\end{figure*}

Figure~\ref{ch:opt:fig:systemrend} presents our rules for terminating the
System R optimizer stage.  Rule~\ol{sr11} counts the number of rules in the target
program.  This count will be used to check for our end condition, which occurs
when all rules have been given a \ol{bestPlan} tuple with a plan size equal to
the number of subgoals.  Rule~\ol{sr12} identifies the completion of a rule based
on this end condition, while rule~\ol{sr13} counts the number of completed rules
for a given program.  Finally, when the counts in \ol{completeRuleCount} and
\ol{rules} are equal, rule~\ol{sr14} generates the termination signal for a given
program by inserting a new tuple into the \ol{program} program with the ``systemr''
stage name.

\section{Cascades Optimization}
\label{ch:opt:sec:cascades}

The bottom-up, dynamic programming search strategy described in
Section~\ref{ch:opt:sec:systemr} is a natural fit to a Datalog-based rule
language.  One might think a top-down Cascades-style optimization
strategy~\cite{cascades} would be difficult to implement since \OVERLOG, like
Datalog, is evaluated in a bottom-up fashion.  This is partially true but still
relatively painless.  Since the System R search strategy conforms to the
\OVERLOG evaluation strategy, we did not write explicit rules for traversing
through its plan space.  That is, the System R search strategy was implicitly
implemented by the \OVERLOG bottom-up evaluation.  A top-down search strategy,
on the other hand, requires extra logic to guide the search through the plan
space in a top-down order.  The logic of a top-down search strategy follows a
dynamic programming technique called memoization, which turns out to be just as
natural and intuitive in \OVERLOG, and hence easily implemented in Evita Raced.

In this section, we describe our implementation of the Cascades
branch-and-bound algorithm expressed in \OVERLOG.  We begin in
Section~\ref{ch:opt:sec:overview} with a short description of the Cascades
branch-and-bound algorithm.  This is followed by a detailed description of our
declarative rules that we install into Evita Raced.  Our rules are divided
into three modules: search strategy
(Section~\ref{ch:opt:sec:cascades_search}), plan generation
(Section~\ref{ch:opt:sec:cascades_plan}) and winner selection
(Section~\ref{ch:opt:sec:cascades_winner}).  The rules for plan generation and
winner selection may remind the reader of the plan generation and best plan
rules in the previous System R discussion.  However, the rules for search strategy
are unique to this optimizer, and will be the focus our attention.

\subsection{Overview}
\label{ch:opt:sec:overview}

Our description of the Cascades optimizer follows the notation of Shapiro, et
al.~\cite{Shapiro-opt}.  Cascades' plans are classified into {\em groups},
which is an equivalence class of expressions (i.e., predicates) that produce
the same result.  During the optimization, each group (e.g., [ABC]) represents
a container that references physical plans (e.g., \{[AB] sort-merge-join
[C]\}, \{[B] nested-loop-join [AC]\}, \ldots) over subexpressions in that
group.  In order to keep the search space small, a group only references
top-level plans through {\emph multiexpressions}, which are expressions whose
operator takes other groups as input. For example, the multiexpression \{[AB]
sort-merge-join [C]\}, takes groups [AB] and [C] as input, instead of the,
possibly many, individual plans for these groups.  

Associated with each group is a {\emph winner's circle}, which identifies the
optimal plan within a given group, and will be the plan chosen to represent the
group, referenced by top-level multiexpressions.  In the discussion that follows,
when we indicate a {\emph plan} we mean a multiexpression within a group.

At a high level, the branch-and-bound algorithm that drives the Cascades
optimizer performs the following actions.  The search strategy generates groups
in a top-down order, and within each group it performs a bottom-up search for
the cheapest plan, which is called the {\em winner}.  An upper bound,
initialized to $infinity$, is also assigned to each group.  This upper bound is
updated as new (cheaper) plans for the given group are discovered.  A plan (and
all of its subplans) is pruned if its cost exceeds the group upper bound.  The
optimization terminates when a root group (containing all expressions in the
query) has been fully explored, and a winner chosen.  We now ready to describe
our declarative specification of the Cascades branch-and-bound optimization.

\subsection{Search strategy}
\label{ch:opt:sec:cascades_search}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
/* Initialize the top-level group */
bb1 group(@A, Rid, a_list<PredID>, a_list<Schema>) :-
    systemr::programEvent(@A, Pid, ...),
    sys::predicate(@A, PredID, Rid, ..., Schema, Pos, ...),
    Pos > 1. /* Exclude the head and event predicates */

/* Initialize a new branch and bound on the given group. */
bb2 branch(@A, Rid, Group, Schema, 0, Bound) :-
    group(@A, Rid, Group, Schema),
    Bound := infinity.

%* /* Extract the subgroup of predicates that don't include position $Pos$ */ *)
bb3 group(@A, Rid, SubGroup, SubSchema) :-
    branch(@A, Rid, Group, Schema, Pos, Bound),
    Pos < f_sizeof(Group),
    SubGroup  := f_cdr(Group, Pos),
    SubSchema := f_cdr(Schema, Pos).

%* /* Extract the subgroup of consisting of the predicate at position $Pos$ */ *)
bb4 group(@A, Rid, SubGroup, SubSchema) :-
    branch(@A, Rid, Group, Schema, Pos, Bound),
    Pos < f_sizeof(Group),
    SubGroup := f_car(Group, Pos),
    SubSchema := f_car(Schema, Pos).

/* Move the branch position forward when the branch group is complete. */
bb5 branch(@A, Rid, Group, Schema, Pos+1, Bound) :-
    branchComplete(@A, Rid, Group, Pos, Cost),
    branch(@A, Rid, Group, Schema, Pos, OldBound),
    Pos < f_sizeof(Group),
    Bound := Cost < OldBound ? Cost : OldBound.

%* /* A branch for a specific group is complete when we receive an update to the  \\
   \ol{plan} relation. */ *)
bp6 branchComplete(@A, Rid, Group, Pos, Cost) :-
    plan(@A, Rid, Group, Method, PlanID, InnerGroup, OuterGroup, 
          Card, Cost),
    branch(@A, Rid, Group, Schema, Pos, _).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_top_down} Cascades top-down search strategy rules.}
\end{figure*}

The optimization begins when the root group (e.g., [ABC]) is inserted into the
\ol{group} table, and a \ol{branch} tuple is created to initiate a depth-first
traversal over the plan space.  This is initiated by rule~\ol{bb1} of
Figure~\ref{ch:opt:fig:cascades_top_down}, when the \ol{cascades::programEvent}
tuple is received.  The rule subsequently aggregates lists of the predicate
identifiers and predicate schemas, along each rule in the program.  The
predicate identifier list will represent the group identifier, containing all
the predicates in the rule body.  Rule~\ol{bb2} is triggered when such an
update occurs in the \ol{group} relation.  The rule creates a \ol{branch} tuple
containing the group information, an initial branch position, and an initial
bound ($\infty$) for this branch group.  Rules~\ol{bb3} and \ol{bb4} take
action by creating new subgroups, the first excluding the predicate at the
branch position $Pos$, and the second including only it.

The \ol{branch} tuples will trigger the generation of \ol{plan} tuples using
the rules described in Section~\ref{ch:opt:sec:cascades_plan}.  Here, we must
ensure that we do not update the branch position until all plans for the
current branch position are present.  We can detect this by simply waiting for
an update to the \ol{plan} relation that is related to the current \ol{branch}
group.  If even one \ol{plan} tuple for a given group exists in the \ol{plan}
relation then all \ol{plan} tuples for that group are present.  This is
because, in the next section, we will ``concurrently'' derive all the \ol{plan}
tuples for a given group.  Until we get to those rules, assume that
rule~\ol{bp6} creates a \ol{branchComplete} tuple when any \ol{plan} tuple that
is derived for the given group.  This will prompt rule~\ol{bb5} to move the
\ol{branch} tuple position forward by one, with a bound that considers the cost
of the \ol{plan} tuple in the previous branch.

\subsection{Plan Generation}
\label{ch:opt:sec:cascades_plan}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
bp7 plan(@A, Rid, Group, PlanID, Sort, OuterGroup, InnerGroup, 
         Card, Cost) :-
    branch(@A, Rid, Group, Schema, Pos, Bound),
    f_sizeof(Group) == 1,
    PlanID := f_cons(``delta'', Group),
    Sort := null,
    OuterGroup := Group,
    InnerGroup := null,
    Card := 1,
    Cost := 1.

bp8 plan(@A, Rid, Group, PlanID, OuterSort, OuterGroup, InnerGroup, 
         Card, Cost) :-
    branch(@A, Rid, Group, Schema, Pos, Bound),
    winner(@A, Rid, OuterGroup, OuterPlanId),
    plan(@A, Rid, OuterGroup, OuterPlanID, OuterSort, ..., 
          OuterCard, OuterCost),
    group(@A, Rid, OuterGroup, OuterSchema),

    group(@A, Rid, InnerGroup, InnerSchema),
    sys::table(@A, Tid, TableName, ..., InnerCard, InnerSort),
    f_sizeof(InnerGroup) == 1 && f_get(InnerGroup, 0) == TableName,
    f_combine(OuterGroup, InnerGroup) == Group,
    Cost := f_joinsWith(OuterSchema, InnerSchema) ?
              OuterCost + (OuterCard * InnerCost) : infinity,
    Cost < Bound,
    Card := f_joinsWith(OuterSchema, InnerSchema) ?
              (OuterCard * InnerCard) / 3 : (OuterCard * InnerCard),
    PlanId := f_cons(``nested-loop'', OuterPlanID, Tid).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_plan1} Cascades plan generation rules for event
predicates and nested-loop join method.}
\end{figure*}

In this section, we present our rules for generating \ol{plan} tuples for the
group indicated by a \ol{branch} tuple.  In this discussion, a \ol{plan} tuple
is related a multiexpression, described in Section~\ref{ch:opt:sec:overview}.
Figure~\ref{ch:opt:fig:cascades_plan1} presents our first group of rules the
derive \ol{plan} tuples.  Rule~\ol{bp7} handles the case of a single predicate
identifier in the $Group$ attribute.  The plan in this case consists of the
single streaming delta predicate, with appropriate cardinality and cost values.
This delta plan is assigned the single predicate group as the outer group, and
$null$ as its inner group.

Rule~\ol{bp8} is the our first rule that generates a \ol{plan} tuple involving
a join method, specifically nested-loop join.  A \ol{branch} tuple with a
group, containing at least two predicates, is ``joined with'' the \ol{winner}
relation.  The \ol{winner} relation is described in the following section, but
its purpose is to identify the winning plan, for each interesting order, in its
group.  In rule~\ol{bp8}, we use a ``winning'' {\em subplan} as the ``outer
plan'', and join it with a table predicate that when combined with the outer
subgroup, formulates the branch group under consideration.  The sorting order
produced by this plan is the same as the order of the ``outer plan.'' Like the
strategy used in the System R \ol{plan} generation rules, we use the plan
identifier ($PlanID$) to hold the actual plan.  In both cases, another stage is
used to annotate the relevant term relations (\ol{sys::predicate},
\ol{sys::assign} and \ol{sys::select}) with the desired order and join method.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
bp9 plan(@A, Rid, Group, PlanID, OuterSort, OuterGroup, InnerGroup, 
         Card, Cost) :-
    branch(@A, Rid, Group, Schema, Pos, Bound),
    winner(@A, Rid, OuterGroup, OuterPlanId),
    plan(@A, Rid, OuterGroup, OuterPlanID, OuterSort, ..., 
         OuterCard, OuterCost),
    group(@A, Rid, OuterGroup, OuterSchema),

    group(@A, Rid, InnerGroup, InnerSchema),
    sys::table(@A, Tid, TableName, ..., InnerCard, InnerSort),
    sys::index(@A, Iid, Tid, Key, Type, Selectivity),
    f_sizeof(InnerGroup) == 1 && f_get(InnerGroup, 0) == TableName,

    f_combine(OuterGroup, InnerGroup) == Group,
    f_joinCol(OuterSchema, InnerSchema) == f_get(InnerSchema, Key),
    Cost := OuterCost + OuterCard,
    Cost < Bound,
    Card := OuterCard * (InnerCard * Selectivity),
    PlanId := f_cons("index-loop", OuterPlanID, Tid, Iid).

bp10 plan(@A, Rid, Group, PlanID, Sort, OuterGroup, InnerGroup, 
          Card, Cost) :-
     branch(@A, Rid, Group, Schema, Pos, OldBound),
     winner(@A, Rid, OuterGroup, OuterPlanId),
     plan(@A, Rid, OuterGroup, OuterPlanID, OuterSort, ..., 
          OuterCard, OuterCost),
     group(@A, Rid, OuterGroup, OuterSchema),
     group(@A, Rid, InnerGroup, InnerSchema),
     sys::table(@A, Tid, TableName, ..., InnerCard, InnerSort),
     f_sizeof(InnerGroup) == 1 && f_get(InnerGroup, 0) == TableName,
     f_combine(OuterGroup, InnerGroup) == Group,
     Sort := f_joinAttribute(OuterSort, OuterSchema, 
                            InnerSort, InnerSchema),
     Cost := f_sortJoinCost(OuterSort, OuterCard, 
                            InnerSort, InnerCard),
     Cost < Bound,
     Card := (OuterCard * InnerCard) / 3,
     PlanId := f_cons(``sort-merge'', OuterPlanID, Tid, Sort).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_plan2} Cascades plan generation rules for index-loop
and sort-merge join methods.}
\end{figure*}

Figure~\ref{ch:opt:fig:cascades_plan2} contains the remaining \ol{plan}
generation rules that cover are remaining index-loop and sort-merge join
methods.  As in the respective System R rules, we need to consider various
properties of these joins.  In rule~\ol{bp9} we consider an index-loop join on
the outer ``winning'' plans with an inner table predicate that includes an
index definition relevant to the joining attributes.  In rule~\ol{bp10}, the
sort-merge join along the same set of predicates is derived.  The cost of this
plan depends on the order of the outer and inner tuples.  The output is ordered
by the join attributes used for these two inputs.  One other rule, that we omit
here, handles selection predicates in a manner nearly identical to rule~\ol{sr5} 
in Figure~\ref{ch:opt:fig:plangen4}. 

\subsection{Winner Selection}
\label{ch:opt:sec:cascades_winner}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
/* Determine the best overall cost for a given plan. */
bb11 bestOverallCost(@A, Rid, Group, a_min<Cost>) :-
     branch(@A, Rid, Group, Schema, Pos, OldBound),
     f_sizeof(Group) == Pos,
     plan(@A, Rid, Group, ..., Cost).

/* Determine the best cost plan for each ordered result. */
bb12 bestOrderCost(@A, Rid, Group, Sort, a_min<Cost>) :-
     branch(@A, Rid, Group, Schema, Pos, OldBound),
     f_sizeof(Group) == Pos,
     plan(@A, Rid, Group, PlanID, Sort, ..., Cost),
     interestingOrder(@A, Pid, Rid, PlanID).

/* Identify interesting ordered plans. */ 
bb13 interestingOrder(@A, Pid, Rid, PlanID) :-
     plan(@A, Rid, Group, PlanID, Sort, OuterGroup, InnerGroup, 
          Card, Cost),
     sys::rule(@A, Rid, Pid, HeadPredID, ...),
     /* The head predicate */
     sys::predicate(@A, Pid, Rid, HeadPredID, ..., HeadPredSchema, ...),
     /* A rule body predicate */
     sys::predicate(@A, Pid, Rid, BodyPredID, ..., BodyPredSchema, ...),
     HeadPredID != BodyPredID, 
     /* Participates in a later join OR 
        is a prefix of a grouping attribute. */
     (f_contains(BodyPredID, Plan) ==  false &&
      f_contains(f_joincond(PlanSchema, BodyPredSchema), Sort)) ||
     f_isPrefix(Sort, HeadPredSchema) ==  true.

/* Choose a winner based on the best overall cost. */
bb14 winner(@A, Rid, Group, PlanId) :-
     bestOverallCost(@A, Rid, Group, Cost),
     plan(@A, Rid, Group, PlanID, Sort, ..., Card, Cost).

/* Choose a winner from each interesting ordered plans. */
bb15 winner(@A, Rid, Group, PlanId) :-
     bestOrderCost(@A, Rid, Group, Sort, Cost),
     plan(@A, Rid, Group, PlanID, Sort, ..., Card, Cost).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_winner} Cascades winner selection rules.}
\end{figure*}

The rules in Figure~\ref{ch:opt:fig:cascades_winner} select a {\emph winner}
plan from the plans deduced for a given group.  We begin at rule~\ol{bb11},
which determines the cost of the optimal plan regardless of order.  The
\ol{bestOverallCost} tuple ensures that an ordered plan that is also optimal is
chosen regardless of its order being interesting.  Rule~\ol{bb12} follows by
determining the best cost plan for each interesting order.  These two rules
identify the best cost plans for a given group.  The familiar rule~\ol{bb13},
also appearing as the \ol{sr8} System R rule, determines the orders that are
interesting, based on grouping and joining attributes.

Due to P2's lack of stratified Datalog support, we must predicated the
evaluation of rules~\ol{bb11} and~\ol{bb12} on the \ol{branch} tuple's group
position attribute.  When a group has been fully explored its \ol{branch}
position ($Pos$) is equal to the number of terms in the $Group$ variable.  If
we omit this constraint, then we would prematurely derive \ol{winner} tuples in
the final two rules: rule~\ol{bb14} ensures that the best overall plan is part
of the \ol{winner} relation, and rule~\ol{bb15} derives a \ol{winner} tuple for
each interesting orders.

\subsection{Termination}
\label{ch:opt:sec:cascadesend}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
bb16 rules(@A, Pid, a_count<Rid>) :-
     cascades::programEvent(@A, Pid, ...),
     sys::rule(@A, Rid, Pid, ...).

bb17 completeRule(@A, Pid, Rid) :-
     winner(@A, Rid, Group, PlanId),
     sys::rule(@A, Rid, Pid, ..., Goals),
     f_sizeof(Group) == Goals - 1.

bb18 completeRuleCount(@A, Pid, a_count<Rid>) :-
     completeRule(@A, Pid, Rid).

bb19 sys::program(@A, Pid, Name, Rewrite, ``cascades'', Text, Msg, 
                  P2DL, Src) :-
     completeRuleCount}(@A, Pid, Count),
     rules(@A, Pid, Count),
     sys::program(@A, Pid, Name, Rewrite, Stage, Text, Msg, P2DL, Src).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascadesend}Cascades termination rules.}
\end{figure*}

Figure~\ref{ch:opt:fig:cascadesend} contains the four rules used to detect the
termination condition of this optimization stage.  These rules resemble the
System R termination rules in Figure~\ref{ch:opt:fig:systemrend}.  The first
rule (\ol{bb16}) counts the total number of rules in the target program.
Rules~\ol{bb17} and \ol{bb18} count how many rules have been assigned a
``winning'' plan consisting of all predicates in the rule body.  Some number of
fixpoints later, when the \ol{completeRuleCount} reaches the total \ol{rules}
count, rule~\ol{bb19} terminates the optimization stage.  The result being a
new \ol{program} tuple with the stage attribute set to ``cascades.''

\section{Discussion}
\label{ch:opt:sec:discussion}

When we started this work, the vision of declaratively specified query
optimization was appealing thanks to its elegance and its promise of usability
and maintainability.  Although we remain convinced on this front, our optimism
has been tempered by the pragmatics of developing software within a
continuously changing system prototype.  Here we reflect on some of the (hard)
lessons we learned while conducting this research.

P2's notion of consecutive Datalog-style fixpoints, especially in networked
environments, still has many rough edges, both on the design and on the
engineering front.  Because deep down P2's runtime is an event-driven execution
engine, its basic unit of atomicity is akin to a single iteration through a
recursive query evaluation strategy like semina\"{\i}ve evaluation, generating a
set of derived actions (tuples to be inserted, deleted, transmitted remotely,
or evaluated locally for further deduction) from a single incoming event, and
committing changes to the database atomically upon completion of such a
step~\cite{LuThesis}.  P2's Datalog-style fixpoints are implemented as
sequences of such single-event iterations.  As a result, the system's design
shares both event-driven and logic-style flavors, with some remaining
unresolved conflicts (e.g., stratified Datalog).
%, and no explicit language constructs to bridge between the two.

%One example is the notion of \ol{delete} rules, the semantics of which are
%unclear.  How is one to handle delete rules triggered by the \emph{deletion} of
%a base tuple?  The system certainly does not support -- semantically or
%operationally -- the ``undeleting'' of tuples that were originally deleted due
%to a base fact that is no longer in the database.  Similarly, the semantics for
%multiple updates to the same tuple within the same fixpoint are undefined and a
%local tie breaking rule is chosen to decide on a consistent ordering among
%same-fixpoint updates to the same relation.  Compiler stages that do static
%analysis might catch such dangerous rules and alert the user.

Second, as in most prototypes, the programmer interface is not polished.
Debugging is difficult, especially since the logic language makes it tough to
understand which value corresponds to which formal attribute in a long tuple of
a dozen or more attributes.  Though concise, declaratively specified
optimizations pack a punch in terms of density of concepts, which only becomes
deadlier due to the (otherwise desirable) arbitrary order of rule execution.
Certainly a better thought-out system to debug declarative programs --
optimizations, no less -- would have made the job easier.  To be fair, however,
our experience with building monolithic optimizers in production database
management systems in the past was not a great deal rosier.  It is hard to
debug code when the output's correctness (e.g., minimality of cost) is too
expensive to verify.

Third, the evolution of the \OVERLOG language has a long way to go.  The P2
version of the language offers no modularity, making it tough to isolate and
reuse logically distinct components.  It does have a rudimentary concrete type
system, but has poor support for structured types like matrices and lists.
\OVERLOG still ``cuts corners'' on the proper set-orientation of Datalog; since
program stratification is not present in the system, dealing with streaming
aggregates required us to resort to imperative tricks like matching ``counts'',
computed in separate ``dataflow fixpoints'', to determine that state was ready
to be finalized.

Beyond particular characteristics of P2, one hard lesson we learned was that
extensibility and ease of use at the top often comes at the expense of
complexity below the extensibility layer.  The tabularization of compiler state
to enable declarative optimizations also meant that even imperative compiler
stages such as our bootstrap stages implemented in C++ had to use tables,
foregoing their familiar interaction with C++ data structures.  Building glue
libraries that ease this interaction may relieve this pain.

Nevertheless, despite these complaints, we were able to get all of our desired
optimizations expressed in \OVERLOG in a highly compact way, as promised by the
various earlier papers on P2.  By contrast, the initial version of P2 had no
query optimizations of interest beyond localization, which was really a
requirement imposed by the P2 dataflow architecture on rules containing
distributed predicates.

\section{Conclusion} 
\label{ch:opt:sec:summary} 

The Evita Raced metacompilation framework allows \OVERLOG compilation tasks to
be written in \OVERLOG and executed in the P2 runtime engine.  It provides
significant extensibility via a relatively clean declarative language.  Many of
the tasks of query optimization -- dynamic programming, dependency-graph
construction and analysis, statistics gathering -- appear to be well served by
a recursive query language.  The notion of metacompilation also leads to a very
tight implementation with significant reuse of code needed for runtime
processing.

Even with the caveats expressed in Section~\ref{ch:opt:sec:discussion}, we are
convinced that a declarative metacompiler is much easier to program and extend
than the monolithic query optimizers we have worked on previously.  We are now
at a point where we can add significant features (e.g., histograms, broadcast
rewrites, stratification tests) in an hour or two, where they would otherwise
have taken days or weeks of work in a traditional implementation.

One surprising lesson of our work was the breadth of utility afforded by the
metacompilation framework.  Although motivated by performance optimizations, we
have used Evita Raced for a number of unforeseen tasks.  These include:
automatically expanding user programs with instrumentation and monitoring
logic; generating pretty-printers for intermediate program forms; language
wrappers for secure networking functionality in the manner of
SecLog~\cite{abadi-netdb07}; stratification detectors and other static code
analysis.  None of these are performance optimizations per se, but all fit well
within an extensible, declarative program manipulation framework.  More
generally, we believe that metacompilation is a good design philosophy not only
for our work, but for the upcoming generation of declarative engines being
proposed in many fields.


\chapter[Declarative Optimization]{Declarative Optimization}
\label{ch:opt}

Previous chapters described the Evita Raced declarative architecture and its
reuse of the query executor in a stylized fashion to serve as the engine
beneath the query compilation process.  This resulted in an {\em economy of
mechanism}~\cite{Saltzer75theprotection} not afforded by earlier extensible
optimizers (i.e., EXODUS~\cite{exodus}, Starburst~\cite{phh92},
Volcano~\cite{volcano}, OPT++~\cite{opt++}).  In Chapter~\ref{ch:magic}, we
presented our first declarative optimization; the magic-sets rewrite, which is
based on a transitive closure traversal over the rule/goal graph of an \OVERLOG
program.

We now turn our attention to cost-based optimizations, which are commonly based
on dynamic programming techniques.  Section~\ref{ch:opt:sec:systemr} discusses
a dynamic programming optimizer stage akin to that of System R.  In
Section~\ref{ch:opt:sec:cascades}, we present a declarative version of the
Cascades optimizer, which is structured around a dynamic programming technique
called ``memoization.'' Based on our experience, we believe that declarative
metacompilation is a clean, architecturally parsimonious way to build the next
generation of extensible query optimizers for a wide variety of emerging
application domains, where the relevant optimizations are likely to evolve over
time.  We begin with a review of literature surrounding extensible query
optimizers (Section~\ref{ch:opt:sec:related}) and conclude with some final
thoughts on the Evita Raced work (Section~\ref{ch:opt:sec:summary}).

\section{Related Work}
\label{ch:opt:sec:related}

The pioneering work on extensible query optimizer architectures was done in the
EXODUS~\cite{exodus} and Starburst~\cite{lohman,phh92} systems, which provided
custom rule languages for specifying plan transformations.  The EXODUS
optimizer generator used a forward-chaining production rule language to iteratively
transform existing query plans into new ones.  Follow-on work
(Volcano~\cite{volcano} and Cascades~\cite{cascades}) exposed more interfaces
to make the search in this space of transformations more efficient.  Starburst
had two rule-based optimization stages.  The SQL Query Rewrite stage provided a
production rule execution engine, for ``rules'' that were written imperatively
in C; it included a precedence ordering facility over those rules.  The
cost-based optimizer in Starburst was more declarative, taking a grammar-based
approach to specifying legal plans and subplans.

While all of this work was rule-based and extensible, most of it only exposed
individual plan transformations to extensibility; the actual search algorithms
or transformation orderings of EXODUS, Volcano, Cascades, and the Starburst
cost-based optimizer were confined to procedural code.  By contrast, Evita Raced
does not embed a search algorithm, instead leaving that open to specification
as needed.  As we show in Section~\ref{ch:opt:sec:systemr}, both the dynamic programming
bottom-up strategy and the Cascades top-down strategy naturally fit to a
Datalog-based rule language.

Another interesting extensible query optimizer is Opt++~\cite{kabradewitt},
which exploits the object-oriented features of C++ to make an optimizer
framework that was easy to customize in a number of ways.  A specific goal of
Opt++ was to make the search strategy extensible, enabling not only top-down
vs.  bottom-up state-space enumeration, but also randomized search algorithms.
Evita Raced embraces these additional dimensions of extensibility introduced by
Opt++, but provides them in a higher-level declarative programming framework.

The cyclic dataflow used for stage scheduling in Evita Raced
(Section~\ref{ch:evita:sec:stages}) resembles the continuous query engine of
TelegraphCQ, with our StageScheduler and Demux elements working together to
behave somewhat like the TelegraphCQ {\em eddy} operator~\cite{tcq-cidr}.  This
connection occurred to us long after we developed our design, but in retrospect
the analogy is quite natural: Evita Raced stages are akin to TelegraphCQ's
``installed'' continuous queries, and P2's \OVERLOG queries are akin to data
streaming into TelegraphCQ.


\section{System R Optimization}
\label{ch:opt:sec:systemr}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
  {\bf def} optimizer($Q$)
    \begin{algorithmic}[1]
      	\STATE /* Base case: access methods to relations in Q */
  	\FORALL{base relations $R \in Q$}
		\STATE Find all access methods to $R$ and store in $AM$
		\STATE Include index scans iff there exists sargable predicates 
  	\ENDFOR
	\STATE
  	\FORALL{$p \in AM$}
		\IF{$p$ is the cheapest unordered access method \OR 
		    $p$ is the cheapest access method for some "interesting order"}
			\STATE $plans[1] = plans[1] \bigcup p$ 
		\ENDIF
 	\ENDFOR
	\STATE
	\STATE $bp$ = bestplan($|Q|$) /* Get best plans for query Q */
	\IF{$Q$ contains a GROUP BY or ORDER BY}
	 	\STATE $cp$ = cheapest plan $p \in bp$ w.r.t. relevant interesting order 
		\IF{$cp == null$}
			\STATE $cp$ = cheapest overall plan $p \in bp$ + sort operator
		\ENDIF
		\RETURN $cp$
	\ELSE
	 	\RETURN cheapest overall plan $p \in cp$ /* irrespective of ``interesting orders'' */ 
	\ENDIF
    \end{algorithmic}
  {\bf end} \\
  \\
  {\bf def} bestplan(n)
    \begin{algorithmic}[1]
  	\IF{$plans[n] = \emptyset$}
		\FORALL{$p_1 \in plans[1]$} 
			\STATE $P_{n-1}$ = bestplan(n -1)
			\FORALL{$p_{n-1} \in P_{n - 1}$}
			\STATE /* if $p_1$ and $p_{n-1}$ have non-overlapping query predicates */
				\IF{$p_1 \bigcap p_{n-1} = \emptyset$}
					\STATE $plans[n] = plans[n] \bigcup$ all (left-outer) join methods for $p_1$ and $p_{n-1}$
				\ENDIF
			\ENDFOR
		\ENDFOR
		\STATE
		\FORALL{$p \in plans[n]$}
			\IF{$p$ is not the cheapest unordered plan among its equivalent plans \OR
			    $p$ is not the cheapest ``interesting ordered'' plan among its equivalent plans}
				\STATE delete $p$ from $plans[n]$
			\ENDIF
		\ENDFOR
	\ENDIF
	\RETURN plans[n]
      \end{algorithmic}
    {\bf end}
\end{boxedminipage}
\caption{\label{ch:opt:fig:systemr}System R optimizer algorithm.}
\end{figure*}

The System R optimizer paper by Selinger, et al.  is the canonical textbook
framework for database query optimization~\cite{selinger}.  The paper laid out
for the first time the notion that query optimization can be decomposed into
two basic parts: query plan cost estimation and plan enumeration.  While this
algorithm is traditionally implemented inside the heart of a database system
via a traditional procedural programming language, both of these tasks are
naturally specified in a declarative query language.  To perform cost
estimation, System~R requires data statistics like relation cardinalities and
index selectivities; \OVERLOG is a fitting language to collect these
statistics, especially in a distributed fashion over all relation partitions.

Our focus in this section is on the basic dynamic programming algorithm for the
state-space enumeration at the heart of the System R optimizer.
Figure~\ref{ch:opt:fig:systemr} gives a (simplified) sketch of this
algorithm.  It enumerates query plans for increasingly-large subgoals of the
query optimizer.  It fills in a dynamic programming table (e.g., $plans$ in
Figure~\ref{ch:opt:fig:systemr}) with plans that cover a given number of
(relational algebra) predicates that appear in the query.  The dynamic
programming task is to fill in this table with the lowest-estimated-cost query
plan among all plans producing an {\em equivalent} output relation (i.e., plans
composed of the same terms).  The \ol{bestplan} procedure in
Figure~\ref{ch:opt:fig:systemr} captures the essence of generating and
choosing optimal plans with a given number of predicates.

In the System R optimizer, the {\em principle of optimality} is assumed to
hold: the lowest-cost solution to some plan will be built from the optimal
solutions to subplans.  Thus dynamic programming can proceed in ``bottom-up''
fashion.  In a given program $P$ to be optimized, each rule's event predicate
is the ``outermost,'' streaming relation in a query plan for the rule.  For a
given rule $r \in P$, the optimizer generates plans of size $k$ terms by
appending a single (thus unused) term from the rule body to the optimal plan of
size $k-1$ terms, as shown in the first loop of \ol{bestplan} in
Figure~\ref{ch:opt:fig:systemr}.  There are many additional details that we
have chosen to gloss over in the pseudocode.  For instance, avoid combining a
k-way plan with a 1-way plan if there is no join predicate between them, unless
all predicates have been used up (i.e., postpone Cartesian products).  We
handle this in our \OVERLOG rules by ensuring the cost of such an option is
greater than any other option that includes join predicates.  

We now turn to describe the \OVERLOG rules for plan generation and conclude
with the rules for best plan selection.  Our declarative optimizer adds two new
tables (\ol{plan} and \ol{bestPlan}) to the Metacompiler Catalog.  The
\ol{plan} table identifies the subgoal and method (i.e., join) for evaluating
that subgoal.  Each \ol{plan} tuple contains an identifier, which the
\ol{bestPlan} table uses to reference optimal plans.  The $Planner$ stage will
generate the physical dataflow plan based on the access and join methods
contained in these relations.  Section~\ref{ch:opt:sec:plangen} presents our
System R rules for generating plans (\ol{plan} tuples) from the predicates in
the rule body.  Are rules for selecting a best plan are discussed in
Section~\ref{ch:opt:sec:bestplan}.  We then conclude with a description of
estimating selectivities our termination rules in
Section~\ref{ch:opt:sec:termination}.

\subsection{Plan Generation}
\label{ch:opt:sec:plangen}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
pg1 {\bf plan}(@A, Pid, Rid, PlanID, SubPlanID, Type, TypeID, \\
\datalogspace \xspace \xspace Plan, Schema, Card, Cost, Pos, AM, Sort) :- \\
\datalogspace {\bf systemr::programEvent}(@A, Pid, \_, \_, \_, \_, \_, \_),\\
\datalogspace {\bf sys::predicate}(@A, PredID, Rid, \_, \_, \_, \_, Schema, Pos, \_, \_),\\
\datalogspace Pos == $1$,\\
\datalogspace PlanID := {\em f\_idgen()}, SubPlanID := $null$,\\
\datalogspace Type := "Predicate", TypeID := PredID,\\
\datalogspace Plan := {\em f\_cons}(PredID, $null$),\\
\datalogspace Card := $1$, Cost := $1$,\\
\datalogspace AM := "STREAM", Sort := $null$.
\end{boxedminipage}
\caption{\label{ch:opt:fig:planseed}Plan seed rule.}
\end{figure*}

Figure~\ref{ch:opt:fig:systemr} presents the System R algorithm for plan
generation in two phases.  The first is generating all access methods for a
given relation mentioned in the query (e.g., in the ``from'' clause).
Subsequent to that, a second phase enumerates all possible join orders and
methods.  Recall in Section ? that P2 converts a rule into an
event-condition-action (ECA) form, where the event predicate represents a
stream of tuples from the table reference.  As a consequence of this dataflow
design, our first phase simply generates a plan that listens for such event
tuples.  Extending this rule to consider access methods would entail adding a
predicate that references all access methods to a given relation.

Figure~\ref{ch:opt:fig:planseed} shows the optimizer rule that creates the
initial plan for each rule from the event predicate.  The \ol{plan} tuple
contains a query plan for a given rule, and the plan's \ol{size} reflects the
number of term identifiers in the $Plan$ attribute (i.e., the number of leaves
in the plan tree).  The optimizer listens on the \ol{programEvent} event stream
in rule \ol{pg1}, which initiates the optimization process.  The
\ol{programEvent} tuple is subsequently joined with the \ol{sys::rule} table along
the $Pid$ (program identifier) attribute to obtain the set of rules defined in
the input program.  The resulting set of rule tuples are each joined with the
\ol{sys::predicate} table along the $Rid$ (rule identifier) attribute.  The result
of this join produces a tuple for each predicate term defined by a given rule.
The predicate term assigned to position~$1$ ($Pos == 1$) is by convention the
event predicate term.  For each event \ol{sys::predicate} tuple in each rule of the
input program, rule \ol{pg1} adds a new plan to the \ol{plan} table.  The
$Plan$ attribute represents the initial plan list, starting with the term
identifier ($PredID$) that identifies streaming predicates.  Plan generation
proceeds by appending term identifiers to this list when constructing new plans
from optimal subplans.

The \OVERLOG optimizer defines a set of plan generation rules that together
perform the induction step of the dynamic program.  Each rule extends a best
plan of $k$ terms with a $(k+1)^{st}$, thus far unused term from the rule body.
If the new term considered is a table predicate, then the new plan
annotated with an appropriate join method, which takes the optimal subplan and
``joins it'' with the predicate table.  The join methods supported by P2
include scanned and index-nested-loop-join, as well as merge-join.  A plan
tuple also carries with it an associated cost, which only considers CPU costs
since all P2 relations reside in memory.  We now turn to the description of the
rules that generate plans for nested-loop-join, index nested-loop-join, and
sort-merge join methods.

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
\linenumbers
pg2 {\bf plan}(@A, Pid, Rid, {\em f\_idgen()}, PlanID, "Predicate", PredID, \\
\datalogspace \xspace Plan, Schema, Card, Cost, OuterPos+$1$, JM, $null$) :-\\
\datalogspace {\bf bestPlan}(@A, Pid, Rid, PlanID),\\
\datalogspace {\bf plan}(@A, Pid, Rid, PlanID, \_, \_, \_, OuterPlan, \\
\datalogspace \datalogspace OuterSchema, OuterCard, OuterCost, OuterPos, \_, \_),  \\   
\datalogspace {\bf sys::predicate}(@A, PredID, Rid, \_, \_, Tid, \_, PredSchema, PredPos, \_, \_),\\
\datalogspace {\bf sys::rule}(@A, Rid, Pid, \_, \_, \_, \_, TermCount), \\
\datalogspace $PredPos < TermCount$,\\
\datalogspace {\bf sys::table}(@A, Tid, \_, \_, \_, \_, TCard, \_),\\
\datalogspace {\em f\_contains}(PredID, OuterPlan) == $false$,\\
\datalogspace Card := OuterCard * TCard / $10$,\\
\datalogspace Cost := OuterCost + (OuterCard * TCard),\\
\datalogspace JM := NESTED\_LOOP, \\
\datalogspace Plan := {\em f\_cons}(PredID, OuterPlan), \\
\datalogspace Schema := {\em f\_merge}(OuterSchema, PredSchema).\\
\end{boxedminipage}
\caption{\label{ch:opt:fig:plangen1}nested-loop join method.}
\end{figure*}

Any table predicate appearing in a rule body is given a nested-loop-join plan,
shown by rule~\ol{pg2} in Figure~\ref{ch:opt:fig:plangen1}.  The rule is
triggered on an update to the \ol{bestPlan} relation (described in
Section~\ref{}), which contains the plan identifier ($PlanID$) used to select
the reference plan in the \ol{plan} relation.  Each plan tuple contains a list
of the predicate identifiers that already appear in it.  This list is
referenced by the $OuterPlan$ variable in the \ol{plan} predicate of
rule~\ol{pg2}.

The next step is to extend the \ol{plan} tuple with a ``new'' table predicate,
which is done by joining with the \ol{sys::predicate} relation along the same rule
identifier ($Rid$).  The result of this join operation produces all predicates
mentioned in the rule.  To get only the table predicates we join with the
\ol{table} predicate.  The selection predicate $PredPos < TermCount$ ensures that
we do not consider the rule head predicate (last in the rule's terms by
convention).  The function $f\_contains$ tests for containment of the predicate
in the subplan (outer plan).  The tuples that meet the constraints imposed thus
far represent new table predicates that can be used to extend the optimal plan.
We need only assign annotate the new (projected) plan tuple with a join method
(NESTED\_LOOP), associated cost (based on cardinality estimates), a new
predicate list (see $Plan$ variable), and a new schema (see $Schema$ variable).

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
pg3 {\bf plan}(@A, ...) :-\\
\datalogspace {\bf bestPlan}(@A, Pid, Rid, PlanID),\\
\datalogspace {\bf plan}(@A, Pid, Rid, PlanID, \_, \_, \_, OuterPlan, \\
\datalogspace \datalogspace OuterSchema, OuterCard, OuterCost, OuterPos, \_, \_),  \\   
\datalogspace {\bf sys::predicate}(@A, PredID, Rid, \_, \_, Tid, \_, PredSchema, PredPos, \_, \_),\\
\datalogspace {\bf sys::rule}(@A, Rid, Pid, \_, \_, \_, \_, TermCount), \\
\datalogspace $PredPos < TermCount$,\\
\datalogspace {\bf sys::table}(@A, Tid, \_, \_, \_, \_, TCard, \_),\\
\datalogspace {\bf sys::index}(@A, Iid, Tid, Key, Type, Selectivity),\\
\datalogspace {\em f\_contains}(PredID, OuterPlan) == $false$,\\
\datalogspace {\em f\_indexMatch}(OuterSchema, PredSchema, Key),\\
\datalogspace Card   := OuterCard * (Selectivity * TCard),\\
\datalogspace Cost   := OuterCost + Card,\\
\datalogspace AM := {\em f\_cons}(Type, Iid),\\
\datalogspace ...
\end{boxedminipage}
\caption{\label{ch:opt:fig:plangen2}index-nested-loop join method (diff from Figure~\ref{ch:opt:fig:plangen1}).}
\end{figure*}

An index-nested-loop join plan is generated by rule \ol{pg3} in
Figure~\ref{ch:opt:fig:plangen2}.  Like rule~\ol{pg2}, it joins the
\ol{bestPlan}, \ol{plan}, \ol{sys::predicate}, and \ol{sys::table} predicates to
get all table predicates referenced by the target rule.  That result is
subsequently joined with the (additional) \ol{index} predicate, which adds
index information to the result tuples.  The function {\em f\_indexMatch} tests
if the index can be used to perform the join using attributes from the best
plan schema ($OuterSchema$) and attributes from the predicate table
($PredSchema$).  Any tuple results from this plan are assigned cardinality and
cost estimates based on some cost function, which uses the additional index
selectivity information given by the $Selectivity$ \ol{index} predicate
attribute.  We also support range predicates in our index-nested-loop join
plans but do not discuss them in detail as they are quite similar to the
nested-loop cases above.

A merge-join performs a join of a plan with a table predicate mentioned in the
rule body along some sorting attribute.  The tuple set from the outer plan and
the predicate table must be ordered by the sorting attribute.  The output of a
merge-join operation preserves the sorting attribute order.  Therefore, the
\ol{plan} predicate generated by the merge-join rule includes the sorting
attribute in the value of the $Sort$ \ol{plan} predicate.  We note that the
$Sort$ attribute in the \ol{table} plan table identifies the sorting attribute
of the table.  A $null$ valued $Sort$ attribute, in either the outer relation
\ol{plan} predicate or the inner relation \ol{table} predicate, means that the
relation is not known to be ordered, and must be presorted prior to the
merge-join operator.  The cost of a merge-join operator depends on need to
presort either relation.

\subsection{Best plan selection}
\label{ch:opt:sec:bestplan}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
bp1 {\bf bestCostPlan}(@A, Pid, Rid, Plan, Sort, {\small \bf a\_min}<Cost>) :- \\
\datalogspace {\bf plan}(@A, Pid, Rid, \ldots, Plan, \ldots, Cost, \ldots, Sort). \\

bp2 {\bf bestPlan}(@A, Pid, Rid, PlanID, Plan2, Cost) :- \\
\datalogspace {\bf bestCostPlan}(@A, Pid, Rid, Plan1, Sort, Cost), \\
\datalogspace {\bf plan}(@A, Pid, Rid, PlanID, \ldots, Plan2, \ldots, Cost, \ldots, Sort), \\
\datalogspace Sort == $null$.\\

bp3 {\bf interestingOrder}(@A, Pid, Rid, PlanID) :- \\
\datalogspace {\bf plan}(@A, Pid, Rid, PlanID, \ldots, PlanSchema, \ldots, Sort), \\
\datalogspace {\bf sys::rule}(@A, Rid, Pid, HeadPid, \ldots), \\
\datalogspace // The head predicate \\
\datalogspace {\bf sys::predicate}(@A, Pid, Rid, HeadPredID, \ldots, HeadPredSchema, \ldots),\\
\datalogspace // A rule body predicate \\
\datalogspace {\bf sys::predicate}(@A, Pid, Rid, BodyPredID, \ldots, BodyPredSchema, \ldots),\\
\datalogspace $HeadPredID != BodyPredID$ \\
\datalogspace // participates in a later join OR is a prefix of a grouping attribute \\ 
\datalogspace ({\em f\_contains}(BodyPredID, Plan) ==  $false$ \&\& \\
\datalogspace f\_contains(f\_joincond(PlanSchema, BodyPredSchema), Sort)) $||$ \\
\datalogspace f\_isPrefix(Sort, HeadPredSchema) ==  $true$.  \\

bp4 {\bf bestPlan}(@A, Pid, Rid, PlanID, Plan2, Cost) :- \\
\datalogspace {\bf bestCostPlan}(@A, Pid, Rid, Plan1, Sort1, Cost), \\
\datalogspace {\bf plan}(@A, Pid, Rid, PlanID, \_, \_, \_, Plan2, \_, \_, Cost, \_, \_, Sort2, \_), \\
\datalogspace {\bf interestingOrder}(@A, Pid, Rid, PlanID), \\
\datalogspace {\em f\_setequals}(Plan1, Plan2), Sort1 == Sort2.
\end{boxedminipage}
\caption{\label{ch:opt:fig:bestplan}Best plan selection.}
\end{figure*}

Figure~\ref{ch:opt:fig:bestplan} shows the rules that select the best plan
from a set of equivalent plans, in terms of the output result set and the
ordering properties of the result set.  The \ol{bestCostPlan} predicate of
rule~\ol{bp1} contains the plan with the minimum cost from the set of
equivalent plans.  This aggregation query groups along the program identifier,
rule identifier, plan list~\footnote{The plan lists are actually sets of
predicate identifiers, which forces the grouping operator to use a set
comparison method to test for equivalence.}, and sort attribute.  

The remaining three rules populate the \ol{bestPlan} table with the optimal
unordered and interestingly ordered plans.  Rule~\ol{bp2} selects the best
unordered plan (no ordering attributes $Sort == null$).  Rule~\ol{bp3}
determines if a plan that is sorted on a given attribute is interesting.  This
occurs in P2 when the plan is sorted along an attribute that participates in a
later join or is a prefix of the grouping attributes.  The body of this rule
joins a \ol{plan} tuple with the \ol{predicate} table, twice, to get the head
predicate and a body predicate that does not already exist in the plan.  The
final selection predicate in this rule checks the necessary conditions, and if
met the rule will deduce an \ol{interestingOrder} tuple for the given $planID$.
The \ol{inerestingOrder} predicate is used in rule~\ol{bp4} to choose the best
plan for a given order.

\subsubsection{Improving Selectivity Estimation}

For equality selection predications, our System R rules above support
selectivity estimates using a uniform distribution estimator given by the
index.  For more precise estimates and to handle range predicates, we have
defined declarative rules that produce equiwidth histograms ({\em
ew-histograms}); additional histogramming rules could be added analogously.
The creation of an ew-histogram is triggered by the installation of a fact in a
metadata table of the ew-histograms defined in the system.  The metadata table
contains the parameters of the histogram (i.e., the table name, the attribute
position, and the number of buckets).  For example, the fact \[
\ol{sys::ewhistogram::metadata}(@LOCALHOST, "pred", 3, 10).  \] creates a ten
bucket equi-width historgram on table \ol{pred} for the attribute in the third
position.

Each fact in the ew-histogram table triggers Evita Raced rules that themselves
generate new rules to create ew-histograms (determining bucket boundaries based
on the bucket count and the min and max values of the attribute), and to
maintain bucket counts (performing a count aggregation over the table
attributes, grouped by the bucket boundaries).  The compiler stage that
generates ew-histograms in this fashion consists of $23$ rules ($92$ lines).
The histogram data is stored in relational format with each row corresponding
to a single bucket.  To exploit these histograms, the cost and selectivity
estimation in the \ol{plan} generation rules in
Figures~\ref{ch:opt:fig:plangen1} and~\ref{ch:opt:fig:plangen2} are modified to
incorporate a join with the histogram data relation, and based on the bucket
boundaries obtain density estimations for a given selection predicate.

\subsection{Termination}
\label{ch:opt:sec:termination}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
t1 {\bf rules}(@A, Pid, a\_count$<$Rid$>$) :-\\
\datalogspace {\bf programEvent}(@A, Pid, \ldots), \\
\datalogspace {\bf sys::rule}(@A, Rid, Pid, \ldots). \\

t2 {\bf completeRule}(@A, Pid, Rid) :- \\
\datalogspace {\bf bestPlan}(@A, Pid, Rid, \_, \_, Size, Cost), \\
\datalogspace {\bf sys::rule}(@A, Rid, Pid, \ldots, Goals), \\
\datalogspace $Size\ ==\ Goals - 1$. \\

t3 {\bf completeRuleCount}(@A, Pid, a\_count$<$Rid$>$) :- \\
\datalogspace {\bf completeRule}(@A, Pid, Rid). \\

t4 {\bf sys::program}(@A, Pid, Name, Rewrite, ``systemr'', Text, Msg, P2DL, Src) :- \\
\datalogspace {\bf completeRuleCount}(@A, Pid, Count), \\
\datalogspace {\bf rules}(@A, Pid, Count), \\
\datalogspace {\bf sys::program}(@A, Pid, Name, Rewrite, Stage, Text, Msg, P2DL, Src).

\end{boxedminipage}
\caption{\label{ch:opt:fig:systemrend}System R termination rules.}
\end{figure*}

Figure~\ref{ch:opt:fig:systemrend} presents our rules for terminating the
System R optimizer stage.  Rule~\ol{t1} counts the number of rules in the target
program.  This count will be used to check for our end condition, which occurs
when all rules have been given a \ol{bestPlan} tuple with a plan size equal to
the number of subgoals.  Rule~\ol{t2} identifies the completion of a rule based
on this end condition, while rule~\ol{t3} counts the number of completed rules
for a given program.  Finally, when the counts in \ol{completeRuleCount} and
\ol{rules} are equal, rule~\ol{t4} generates the termination signal for a given
program by inserting a new tuple into the \ol{program} program with the ``systemr''
stage name.

\section{Cascades Optimization}
\label{ch:opt:sec:cascades}

The bottom-up, dynamic programming search strategy described in
Section~\ref{ch:opt:sec:systemr} is a natural fit to a Datalog-based rule
language.  One might think a top-down Cascades-style optimization
strategy~\cite{cascades} would be hard to implement since \OVERLOG, like
Datalog, is evaluated in a bottom-up fashion.  This is partially true.  Since
the System R search strategy conforms to the \OVERLOG evaluation strategy, it
did not require explicit rules for its traversal through the plan space.  That is,
the System R search strategy was implicitly implemented by the \OVERLOG
bottom-up evaluation.  A top-down search strategy, on the other hand, requires
extra logic to guide the search through the plan space in
a top-down order.  The logic of a top-down search strategy follows a dynamic
programming technique called memoization, which turns out to be just as natural
and intuitive in \OVERLOG, and hence easily implemented in Evita
Raced.  In this section, we describe our implementation of the Cascades
branch-and-bound algorithm in \OVERLOG.
%, consisting of a mere $33$ rules ($204$ lines).

The remainder of this section is organized as follows.  In
Section~\ref{ch:opt:sec:overview} we provide a short description of the
Cascades branch-and-bound optimization.  We then move to the detailed
description of our declarative rules for performing this optimization.  Our
rules are divided into three modules, the search strategy
(Section~\ref{ch:opt:sec:cascades_search}), plan generation
(Section~\ref{ch:opt:sec:cascades_plan}), and winner selection
(Section~\ref{ch:opt:sec:cascades_winner}).  The rules for plan generation and
winner selection may remind the reader of the plan generation and best plan
selection System R rules in the previous section.  However, the rules for
search strategy are unique to this optimizer, and will be the focus our
attention.

\subsection{Overview}
\label{ch:opt:sec:overview}

Our description of the Cascades optimizer follows the notation of Shapiro, et.
al~\cite{Shapiro-opt}.  In Cascades, plans are classified into {\em groups},
which is an equivalence class of expressions (predicates) that produce the same
result.  During the optimization, each group (e.g., [ABC]) represents a
container that references all physical plans (e.g., \{[AB] sort-merge-join
[C]\}, \{[B] nested-loop-join [AC]\}, \ldots) that make up the group.  In order
to keep the search space small, a group only references top-level plans through
{\emph multiexpressions}, which are expressions whose operator takes other
groups as input (e.g., multiexpression \{[AB] sort-merge-join [C]\} takes groups [AB] and
[C] as input).  Associated with each group is a {\emph winner's circle}, which
identifies the optimal plan within a given group, and will be the plan chosen
to represent a given group referenced by a multiexpression.  In the discussion
that follows, a when we indicate a {\emph plan} we mean a given multiexpression
within a group.

At a high level our declarative rules for implementing the Cascades optimizer
perform the following deductions.  The optimizer generates groups in a top-down
order and within each group it performs a bottom-up search for the cheapest
plan, called the {\em winner}.  An upper bound is assigned to each group,
contained in the \ol{branch} table, and initialized to $inifinty$, which is
updated as new (cheaper) plans for the given group are discovered.  A plan (and
all its subplans) is pruned if its cost exceeds the group upper bound.  The
optimization terminates when a root group (containing all expressions in the
query) has been fully explored and a winner has been chosen. 

The schema for our Cascades optimizer differs from prior Evita Raced stages.
In order to provide a cleaner implementation, some of our attributes are
actually objects that encapsulate related values and functions. 


\subsection{Search strategy}
\label{ch:opt:sec:cascades_search}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
cst1 {\bf group}(Group, Schema) :- \\
\datalogspace {\bf branch}(Group, \_, Cursor, Bound), \\
\datalogspace $Cursor != null$, \\
\datalogspace Group := Cursor.current(), \\
\datalogspace Schema := Group.schema(). \\
\\
cst2 {\bf branch}(Group, 0, Cursor, Bound) :- \\
\datalogspace {\bf group}(Group, Schema), \\
\datalogspace Cursor := Group.cursor(), \\
\datalogspace Bound  := $infinity$. \\
\\
cst3 {\bf branch}(Group, BranchId+1, Cursor, Bound) :- \\
\datalogspace {\bf bestBranchCost}(Group, BranchId, Cost), \\
\datalogspace {\bf branch}(Group, BranchId, Cursor, OldBound), \\
\datalogspace $Cursor != null$, \\
\datalogspace Cursor := Cursor.next(), \\
\datalogspace Bound := $Cost < OldBound$ ? Cost : OldBound. \\
  
\end{boxedminipage}
\caption{\label{ch:opt:fig:cascades_top_down} Cascades top down search strategy rules.}
\end{figure*}

The optimization begins when the root group (e.g., [ABC]) is inserted into the
\ol{group} table.  A \ol{group} tuple contains an object, as its first
attribute, that provides a cursor to the underlining predicates in the group.
The cursor will generating all subgroups of the given group (e.g., cursor for
group [ABC] will generate subgroups [AB], [BC], [AC]~\footnote{The subgroup
cursors will further generate groups [A], [B], and [C].}).  Rule~\ol{cs2} in
Figure~\ref{ch:opt:fig:cascades_top_down} creates a \ol{branch} tuple from
the initial \ol{group} tuple, using the {\emph cursor} method to create an
initial cursor at position $0$.  A branch contains an upper bound (initialized
to infinity) that is used to prune the cost of plans contained within the given
group.  An insertion into the \ol{branch} table triggers rule~\ol{cst1}, which
inserts the ``current'' subgroup referenced by the cursor object, should one
exists (i.e., no cursor exists for groups containing a single predicate).  When
all plans for the current subgroup have been explored, and a winner selected,
rule~\ol{cst3} advances the cursor to the next subgroup.  This process
completes when the group cursor contains no more subgroups, at which point a
winner can be chosen for the group.


\subsection{Plan Generation}
\label{ch:opt:sec:cascades_plan}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
p1 {\bf plan}(PlanId, Group, BranchId, "tablescan", null, null, Card, Cost) :- \\
\datalogspace {\bf branch}(Group, BranchId, Cursor, Bound), \\
\datalogspace {\bf table}(Name, $\ldots$, Size), \\
\datalogspace $Group.size() == 1$, \\
\datalogspace $Group.tablePredicate() == Name$, \\
\datalogspace PlanId := "tablescan" + Group.id(), \\
\datalogspace Card := Size, \\
\datalogspace Cost := Size. \\
\\
p2 {\bf plan}(PlanId, Group, ``nested-loop'', OuterGroup, InnerGroup, Card, Cost) :- \\
\datalogspace {\bf branch}(Group, BranchId, Cursor, Bound), \\
\datalogspace {\bf winner}(OuterGroup, OuterPlanId, OuterCard, OuterCost), \\
\datalogspace {\bf winner}(InnerGroup, InnerPlanId, InnerCard, InnerCost), \\
\datalogspace {\bf group}(OuterGroup, OuterSchema), \\
\datalogspace {\bf group}(InnerGroup, InnerSchema), \\
\datalogspace $OuterGroup.insersect(InnerGroup) ==  null$, \\
\datalogspace $OuterSchema.joinsWith(InnerSchema) ==  true$, \\
\datalogspace $InnerGroup.size() == 1$, \\
\datalogspace Cost := $OuterSchema.joinsWith(InnerSchema)$ ? \\
\datalogspace \datalogspace OuterCost + (OuterCard * InnerCost) : infinity, \\
\datalogspace $Cost < Bound$, \\
\datalogspace Card := $OuterSchema.joinsWith(InnerSchema)$ ? \\
\datalogspace \datalogspace (OuterCard * InnerCard) / 3 : (OuterCard * InnerCard), \\
\datalogspace PlanId := ``nested-loop'' + Group.id(). \\
\\
p3 {\bf plan}(PlanId, Group, "index-loop", OuterGroup, InnerGroup, Card, Cost) :- \\
\datalogspace {\bf branch}(Group, BranchId, Cursor, Bound), \\
\datalogspace {\bf winner}(OuterGroup, OuterPlanId, OuterCard, OuterCost), \\
\datalogspace {\bf winner}(InnerGroup, InnerPlanId, InnerCard, InnerCost), \\
\datalogspace {\bf group}(OuterGroup, OuterSchema), \\
\datalogspace {\bf group}(InnerGroup, InnerSchema), \\
\datalogspace $OuterGroup.insersect(InnerGroup) ==  null$, \\
\datalogspace $OuterSchema.joinsWith(InnerSchema) ==  true$, \\
\datalogspace $InnerGroup.size() == 1$, \\
\datalogspace {\bf index}(IndexId, Tablename, IndexColumn), \\
\datalogspace $InnerGroup.tablePredicate() == Tablename$, \\
\datalogspace $OuterSchema.join(InnerSchema).contains(IndexColumn) ==  true$, \\
\datalogspace Cost := OuterCost + OuterCard, \\
\datalogspace $Cost < Bound$, \\
\datalogspace Card := (OuterCard * InnerCard) / 3, \\ 
\datalogspace PlanId := "index-loop" + Group.id(). \\
  
\end{boxedminipage}
\caption{\label{ch:opt:fig:cascades_plan} Cascades plan generation rules.}
\end{figure*}

Figure~\ref{ch:opt:fig:cascades_plan} gives three rules for generating plans
in the Cascades optimizer.  The rules are very similar to the plan generation
rules in the System R optimizer (Section~\ref{ch:opt:sec:systemr}) but are based on
{\emph winner} plans from relevant subgroups.  The schema of the \ol{plan}
table has also changed to reference groups instead of actual plans, as
indicated by the $OuterGroup$ and $InnerGroup$ variables in rules~\ol{p2} and
\ol{p3}.

The plan generation rules are evaluated in a bottom-up fashion by deducing new
plans for a given group.  The \ol{branch} tuple for a given group triggers
each rule.  If the group contains a single table predicate ($Group.size == 1$
in rule~\ol{p1}) then a {\emph table scan} access method is deduced with a cost based
on the number of tuples in the table.  This access method will be selected as
the winner for the single predicate group.  Since P2 only has a table scan
access method we do not consider other access methods (e.g., index).
Additional access methods would include appropriate rules in the form of
Rule~\ol{p1}.

Rules~\ol{p2} and \ol{p3} consider joins of two subgroups (an $OuterPlan$ and
$InnerPlan$) for nested-loop and index-loop join methods.  The rules reference
the optimal plan, contained in the \ol{winner} table, for each subgroup in
order to derive an overall cost for the plan with the given join method.  Each
rule also ensures that the inner plan contains a single table predicate
(left-deep plans only) and that the subgroups do not overlap in the predicates
the consider ($OuterGroup.insersect(InnerGroup) == null$).  We avoid cross
product plans be giving such plans a high cost ($infinity$), which forces such
plans to be considered last.  Since rule~\ol{p3} considers an index-loop join
method, it must check for the existence of an index on the inner predicate that
matches the join attribute.

\subsection{Winner Selection}
\label{ch:opt:sec:cascades_winner}

\begin{figure*}
\ssp
\centering
\begin{boxedminipage}{\linewidth}
wc1 {\bf winner}(Group, PlanId, Schema, Cost) :- \\
\datalogspace {\bf bestCost}(Group, Cost), \\
\datalogspace {\bf branch}(Group, \_, Cursor, \_), \\
\datalogspace $Cursor ==  null$,
\datalogspace {\bf group}(Group, Schema), \\
\datalogspace {\bf plan}(PlanId, Group, \_, \_, \_, \_, \_, Cost). \\
\\
wc2 {\bf bestCost}(Group, {\bf min}$<Cost>$) :- \\
\datalogspace {\bf bestBranchCost}(Group, BranchId, Cost). \\
\\
wc3 {\bf bestBranchCost}(Group, BranchId, {\bf min}$<Cost>$) :- \\
\datalogspace {\bf plan}(PlanId, Group, BranchId, Method, \_, \_, \_, Cost). \\
  
\end{boxedminipage}
\caption{\label{ch:opt:fig:cascades_winner} Cascades winner selection rules.}
\end{figure*}

The rules in Figure~\ref{ch:opt:fig:cascades_winner} select a {\emph winner}
plan from the plans deduced for a given group.  We begin with rule~\ol{wc3},
which determines the optimal plan in a given group.  The cost of this optimal
plan is used to update the upper bound for the next branch taken by the search
strategy.  Rule~\ol{wc2} further aggregates the result of rule~\ol{wc3} to
determine the best overall plan for a given group, which is used to select a
winner for the group in rule~\ol{wc1}.  We must ensure however that a winner is
only selected when the group has been fully explored, which occurs after the
cursor ($Cursor$) in the \ol{branch} table for the group takes on a $null$
value.

%Suppose the initial query is $A \Join B \Join C$.  The optimizer first
%initalizes the \ol{winner} relation with the root group [ABC]. 
%A single
%rule seeds the recursive rule \ol{c1} in Figure~\ref{ch:evita:fig:bb} by
%initializing the \ol{branch} relation with a tuple that defines the root group
%(i.e., $ABC$) and starts the optimization at position $0$ with predicates ($A$,
%$B$, $C$) and a bound of \ol{infinity}.  The recursion proceeds in a top-down
%fashion.  In the first step a new \ol{branch} tuple is generated that removes
%the predicate in position $0$ generating the group $BC$.  Another rule will
%generate a branch group $A$ at the same time.  The recursion returns when a
%winner for group $ABC$ has been discovered, which occurs when groups $A$ and
%$BC$ have been fully explored and the \ol{next} branch position (e.g., $1$) is
%set for group $ABC$.  A group has been fully explored when its branch position
%reaches the end.  As new winners are discovered the \ol{Bound} variable is
%updated with the winning cost before proceeding to the next predicate.


\subsection{Termination}
\label{ch:opt:sec:cascadesend}


\section{Discussion}
\label{ch:opt:sec:discussion}

When we started this work, the vision of declaratively specified query
optimization was appealing thanks to its elegance and its promise of usability
and maintainability.  Although we remain convinced on this front, our optimism
has been tempered by the pragmatics of developing software within a
continuously changing system prototype.  Here we reflect on some of the (hard)
lessons we learned while conducting this research.

P2's notion of consecutive Datalog-style fixpoints, especially in networked
environments, still has many rough edges, both on the design and on the
engineering front.  Because deep down P2's runtime is an event-driven execution
engine, its basic unit of atomicity is akin to a single iteration through a
recursive query evaluation strategy like semi-naive evaluation, generating a
set of derived actions (tuples to be inserted, deleted, transmitted remotely,
or evaluated locally for further deduction) from a single incoming event, and
committing changes to the database atomically upon completion of such a
step~\cite{LuThesis}.  P2's Datalog-style fixpoints are implemented as
sequences of such single-event iterations.  As a result, the system's design
shares both event-driven and logic-style flavors, with some remaining
unresolved conflicts (e.g., stratified Datalog).
%, and no explicit language constructs to bridge between the two.

%One example is the notion of \ol{delete} rules, the semantics of which are
%unclear.  How is one to handle delete rules triggered by the \emph{deletion} of
%a base tuple?  The system certainly does not support -- semantically or
%operationally -- the ``undeleting'' of tuples that were originally deleted due
%to a base fact that is no longer in the database.  Similarly, the semantics for
%multiple updates to the same tuple within the same fixpoint are undefined and a
%local tie breaking rule is chosen to decide on a consistent ordering among
%same-fixpoint updates to the same relation.  Compiler stages that do static
%analysis might catch such dangerous rules and alert the user.

Second, as in most prototypes, the programmer interface is not polished.
Debugging is difficult, especially since the logic language makes it tough to
understand which value corresponds to which formal attribute in a long tuple of
a dozen or more attributes.  Though concise, declaratively specified
optimizations pack a punch in terms of density of concepts, which only becomes
deadlier due to the (otherwise desirable) arbitrary order of rule execution.
Certainly a better thought-out system to debug declarative programs --
optimizations, no less -- would have made the job easier.  To be fair, however,
our experience with building monolithic optimizers in production database
management systems in the past was not a great deal rosier.  It is hard to
debug code when the output's correctness (e.g., minimality of cost) is too
expensive to verify.

Third, the evolution of the \OVERLOG language has a long way to go.  The P2
version of the language offers no modularity, making it tough to isolate and
reuse logically distinct components.  It does have a rudimentary concrete type
system, but has poor support for structured types like matrices and lists.
\OVERLOG still ``cuts corners'' on the proper set-orientation of Datalog; since
program stratification is not present in the system, dealing with streaming
aggregates required us to resort to imperative tricks like timers and polling
to determine that aggregates were ready to be finalized.

Beyond particular characteristics of P2, one hard lesson we learned was that
extensibility and ease of use at the top often comes at the expense of
complexity below the extensibility layer.  The tabularization of compiler state
to enable declarative optimizations also meant that even imperative compiler
stages such as our bootstrap stages implemented in C++ had to use tables,
foregoing their familiar interaction with C++ data structures.  Building glue
libraries that ease this interaction may relieve this pain.

Nevertheless, despite these complaints, we were able to get all of our desired
optimizations expressed in \OVERLOG in a highly compact way, as promised by the
various earlier papers on P2.  By contrast, the initial version of P2 had no
query optimizations of interest beyond localization.  As \OVERLOG and P2
mature, the use of a metacompilation approach should get even easier.  And
based on our initial experience extending \OVERLOG with security properties in
a manner similar to~\cite{abadi-netdb07}, we believe that our Evita Raced
infrastructure could accelerate the ability to pursue modifications to \OVERLOG
itself.

\section{Conclusion} 
\label{ch:opt:sec:summary} 

The Evita Raced metacompilation framework allows \OVERLOG compilation tasks to
be written in \OVERLOG and executed in the P2 runtime engine.  It provides
significant extensibility via a relatively clean declarative language.  Many of
the tasks of query optimization -- dynamic programming, dependency-graph
construction and analysis, statistics gathering -- appear to be well served by
a recursive query language.  The notion of metacompilation also leads to a very
tight implementation with significant reuse of code needed for runtime
processing.

Even with the caveats expressed in Section~\ref{ch:opt:sec:discussion}, we are
convinced that a declarative metacompiler is much easier to program and extend
than the monolithic query optimizers we have worked on previously.  We are now
at a point where we can add significant features (e.g., histograms, broadcast
rewrites, stratification tests) in an hour or two, where they would otherwise
have taken days or weeks of work in a traditional implementation.

One surprising lesson of our work was the breadth of utility afforded by the
metacompilation framework.  Although motivated by performance optimizations, we
have used Evita Raced for a number of unforeseen tasks.  These include:
automatically expanding user programs with instrumentation and monitoring
logic; generating pretty-printers for intermediate program forms; language
wrappers for secure networking functionality in the manner of
SecLog~\cite{abadi-netdb07}; stratification detectors and other static code
analysis.  None of these are performance optimizations per se, but all fit well
within an extensible, declarative program manipulation framework.  More
generally, we believe that metacompilation is a good design philosophy not only
for our work, but for the upcoming generation of declarative engines being
proposed in many fields.


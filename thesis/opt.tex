\chapter[Declarative Optimization]{Declarative Optimization}
\label{ch:opt}

Previous chapters described the Evita Raced declarative architecture and its
reuse of the query executor in a stylized fashion to serve as the engine
beneath the query compilation process.  This resulted in an {\em economy of
mechanism}~\cite{Saltzer75theprotection} not afforded by earlier extensible
optimizers (i.e., EXODUS~\cite{exodus}, Starburst~\cite{phh92},
Volcano~\cite{volcano}, OPT++~\cite{opt++}).  In Chapter~\ref{ch:magic}, we
presented our first optimization stage; the magic-sets rewrite, which we
declaratively expressed as a transitive closure over the rule/goal graph of an
\OVERLOG program.

In this chapter we turn our attention to cost-based optimizations, which are
commonly based on dynamic programming algorithms.  We begin in
Chapter~\ref{ch:opt:sec:related} with a short review of literature on
extensible query optimizers, with further details described in the two
optimizations we discuss.  Chapter~\ref{ch:opt:sec:systemr} describes a dynamic
programming optimizer stage akin to that of System R.  In
Chapter~\ref{ch:opt:sec:cascades}, we present a declarative version of the
Cascades branch-and-bound optimizer, which is structured around a dynamic
programming algorithm called ``memoization.'' Based on our experience, we
believe that declarative metacompilation is a clean, architecturally
parsimonious way to build the next generation of extensible query optimizers
for a wide variety of emerging application domains, where the relevant
optimizations are likely to evolve over time.  
%We conclude in
%Chapter~\ref{ch:opt:sec:summary} with some final thoughts and a summary of our
%overall experience with the Evita Raced work.

\section{Related Work}
\label{ch:opt:sec:related}

The pioneering work on extensible query optimizer architectures was done in the
EXODUS~\cite{exodus} and Starburst~\cite{lohman,phh92} systems, which provided
custom rule languages for specifying plan transformations.  The EXODUS
optimizer generator used a forward-chaining production rule language to iteratively
transform existing query plans into new ones.  Follow-on work
(Volcano~\cite{volcano} and Cascades~\cite{cascades}) exposed more interfaces
to make the search in this space of transformations more efficient.  Starburst
had two rule-based optimization stages.  The SQL Query Rewrite stage provided a
production rule execution engine, for ``rules'' that were written imperatively
in C; it included a precedence ordering facility over those rules.  The
cost-based optimizer in Starburst was more declarative, taking a grammar-based
approach to specifying legal plans and subplans.

While all of this work was rule-based and extensible, most of it only exposed
individual plan transformations to extensibility; the actual search algorithms
or transformation orderings of EXODUS, Volcano, Cascades, and the Starburst
cost-based optimizer were confined to procedural code.  By contrast, Evita
Raced does not embed a search algorithm, instead leaving that open to
specification as needed.  As we show in Chapter~\ref{ch:opt:sec:systemr}, both
the System R bottom-up strategy and the Cascades top-down strategy naturally
fit to a Datalog-based rule language.

Another interesting extensible query optimizer is Opt++~\cite{kabradewitt},
which exploits the object-oriented features of C++ to make an optimizer
framework that was easy to customize in a number of ways.  A specific goal of
Opt++ was to make the search strategy extensible, enabling not only top-down
vs.  bottom-up state-space enumeration, but also randomized search algorithms.
Evita Raced embraces these additional dimensions of extensibility introduced by
Opt++, but provides them in a higher-level declarative programming framework.


\section{System R Optimization}
\label{ch:opt:sec:systemr}

The System R optimizer paper by Selinger, et al.  is the canonical textbook
framework for database query optimization~\cite{selinger}.  The paper laid out
for the first time the notion that query optimization can be decomposed into
two basic parts: query plan cost estimation and plan enumeration.  While this
algorithm is traditionally implemented inside the heart of a database system
via a traditional procedural programming language, both of these tasks are
naturally specified in a declarative query language.  To perform cost
estimation, System~R requires data statistics like relation cardinalities and
index selectivities, which can be packaged into a relational format, and
thereby accessible in the \OVERLOG language.

\begin{figure*}
\ssp
\footnotesize
\centering
\begin{boxedminipage}{\linewidth}
  {\bf def} \ol{optimize}($PREDS$)
    \begin{algorithmic}[1]
	\STATE Let $AM = \emptyset$ be a set of single table access method plans
  	\FORALL{relations $r \in PREDS$}
		\STATE $AM$ = $AM \bigcup$ access methods on $r$
  	\ENDFOR
	\STATE
	\STATE $GRP_{AM}$ = GroupBy(f\_equivalent, $AM$)
	\STATE $GRP_{AM}$ = $GRP_{AM}\ -\ $ \{uninteresting ordered, suboptimal groups $\in GRP_{AM}$\}
	\STATE $bestplan[1]$ = ArgMin(f\_cost, $GRP_{AM}$) /* best plans of size 1, from each group */
	\STATE $BP$ = \ol{search}($bestplan$, $PREDS$, f\_sizeof($PREDS$)) 
	\STATE $bp$ = ArgMin(f\_cost, $BP$) /* best overall plan */
	\STATE
	\IF{query contains a \ol{group by} or \ol{order by} clause}
		\STATE $bop$ = best ordered plan relative to the clause attributes
		\RETURN Min(f\_sort?($bp$), f\_sort?($bop$)) /* Note: ignores hash grouping plans */
	\ELSE
	 	\RETURN $bp$
	\ENDIF
    \end{algorithmic}
  {\bf end}
  \\
  \\
  /* Returns a set containing the best size $k$ plans. */ \\
  {\bf def} \ol{search}($bestplan$, $PREDS$, $k$)
    \begin{algorithmic}[1]
  	\IF{$bestplan[k] = \emptyset$}
	\STATE /* Get the set of size~$k-1$ best plans. */
	\STATE $BP_{k-1}$ = \ol{search}($bestplan$, $PREDS$, $k-1$)
	\STATE Let $P_{k} = \emptyset$ be a set of size $k$ plans
	\FORALL{plans $bp \in BP_{k-1}$} 
		\FORALL{predicates $p \in PREDS \notin bp$ }
		\STATE $M_k$ = all methods (e.g., join) that take 
			       plan $bp$ (outer) and include $p$ (inner)
		\STATE $P_{k} = P_{k} \bigcup M_k$ 
		\ENDFOR
	\ENDFOR
	\STATE
	\STATE /* Group by {\em equivalent} plan, and retain optimal and interesting ordered plans. */
	\STATE $GRP_{k}$ = GroupBy(f\_equivalent, $P_{k}$)
	\STATE $GRP_{k}$ = $GRP_{k}\ -\ $ \{uninteresting ordered, suboptimal groups $\in GRP_{k}$\}
	\STATE
	\STATE /* The set of size $k$ best plans from each group in $GRP_k$ */
	\STATE $bestplan[k]$ = ArgMin(f\_cost, $GRP_{k}$) 
	\ENDIF
	\RETURN $bestplan[k]$ /* The set of size $k$ best plans */
      \end{algorithmic}
    {\bf end}
\end{boxedminipage}
\caption{\label{ch:opt:fig:systemr}
Sketch of the System R optimizer algorithm.  The \ol{optimize} procedure is called
with all predicates mentioned in the query ($PREDS$), while the \ol{search} procedure 
enumerates the plan space (bottom-up). Each enumeration step generates plans 
size $k~\in~[1, \ldots, |PREDS|]$, and stores the set of optimal plans in the
$bestplan$ array.
}
\end{figure*}

We focus on the basic dynamic programming algorithm for the state-space
enumeration at the heart of the System R optimizer.  A sketch of the System R
dynamic program is given in Figure~\ref{ch:opt:fig:systemr}, which searches for
an optimal plan from a set of query predicates ($PREDS$).  We focus here on the
search strategy, which enumerates query plans for increasingly-large subgoals
of the query.  It fills in a dynamic programming table (i.e., $bestplan$ array)
with the best plans that cover a given number of (relational algebra)
predicates.  Each entry in this table contains the set of lowest-estimated-cost
query plans among all plans producing an {\em equivalent} output relation
(i.e., plans composed of the same predicates), and among the plans that produce
an ``interesting order.'' If the plan produces tuples in an order that is
relevant to a later join condition, or an ``group/order by'' clause, then it is
considered to be an {\em interesting order}~\cite{selinger}.

The \ol{optimize} procedure in Figure~\ref{ch:opt:fig:systemr} takes the set of
predicates mentioned in the query, and returns an optimal plan to the query.
The search begins with plans of size $1$, which consists of the access methods
to any relations mentioned in the query.  Note that in P2 the initial plan (of
size $1$) is the event predicate, which is assigned to the rule by the delta
rewrite (Chapter~\ref{ch:evita:sec:delta}).  The event predicate is used to
initialize our optimization described in Chapter~\ref{ch:opt:sec:plangen},
instead of the traditional approach; shown here as the optimal table access
methods.  The \ol{search} procedure captures the essence of generating {\em
plans} of size $k$, and pruning away those {\em plans} that are not optimal,
nor interesting.  The \ol{optimize} procedure makes the ``top-level'' call to
\ol{search}, requesting the best plans that cover all predicates in the query.
The \ol{search} returns a reference to this set of ``top-level'' optimal plans,
including those with interesting orders.  If the query contains a \ol{group by}
or \ol{order by} clause, then we may require a further sorting
operation~\footnote{This pseudocode ignores hashing plans for \ol{group by}.}
--- the cost of which depends on the order of the chosen optimal plan.  In the
absence of any ordering constraints, we simply return the overall
lowest-estimated-cost plan.

In the System R optimizer, the {\em principle of optimality} is assumed to
hold: the lowest-cost solution to some plan is constructed from the optimal
solutions to subplans.  Thus dynamic programming can proceed in a ``bottom-up''
fashion.  For a given set of predicates ($PREDS$), the optimizer generates
plans of size $k$ terms by appending a single (unused) term from $PREDS$ to an
optimal plan of size $k-1$ terms, as shown in the loop of \ol{search} procedure
of Figure~\ref{ch:opt:fig:systemr}.  There are a few additional details that we
have chosen to gloss over in the pseudocode.  For instance, avoid combining a
k-way plan with a 1-way plan if there is no join condition between them, unless
all other predicates with join conditions have been used (i.e., postpone
Cartesian products).  We handle this case in our \OVERLOG rules by ensuring the
cost of a ``cross-product'' plan is greater than any other plan that contains
joining attributes.

We now turn to the description of our \OVERLOG rules for plan generation and
conclude with our rules for best plan selection.  Our declarative optimizer
adds two new tables (\ol{plan} and \ol{bestPlan}) to the Metacompiler Catalog.
The \ol{plan} table identifies a join method for evaluating a subgoal as the
``inner'' relation.  Each \ol{plan} tuple contains an identifier, which the
\ol{bestPlan} table uses to reference optimal plans.  For a given rule body
term, the $Planner$ stage generates a physical dataflow plan based on the
position and join method assigned in the relevant term relation (i.e.,
\ol{sys::predicate}, \ol{sys::assign} and \ol{sys::select}).
Chapter~\ref{ch:opt:sec:plangen} presents our System R rules for generating
plans (\ol{plan} tuples) from the predicates in the rule body.  Our rules for
selecting a best plan are described in Chapter~\ref{ch:opt:sec:bestplan}, which
also includes a description of how we estimate selectivities.  We then conclude
with our termination rules in Chapter~\ref{ch:opt:sec:termination}.

\subsection{Plan Generation}
\label{ch:opt:sec:plangen}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr1 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    systemr::programEvent(@A, Pid, ...),
    sys::rule(@A, Pid, Rid, ...),
    sys::predicate(@A, Pid, Rid, PredID, ..., Schema, Pos, ...),
    Pos == 1,
    PlanID := f_cons(``delta'', PredID),
    Group := f_cons(PredID, null),
    Sort := null,
    Card := 1, Cost := 1.
\end{lstlisting}
\caption{\label{ch:opt:fig:planseed}Plan seed rule.}
\end{figure*}

Figure~\ref{ch:opt:fig:systemr} describes the System R algorithm in two phases;
access method plan generation and plan enumeration for increasingly large
subgoals.  Recall from Chapter~\ref{ch:evita:sec:delta} that P2 converts a rule
into an event-condition-action (ECA) form, where the event predicate represents
a stream of tuples representing side-affect actions (i.e., insert and delete)
to the reference table.  As a consequence of this dataflow design, our first
phase simply generates a plan that listens for such event tuples.  The reader
can assume the delta rewrite stage executes before the System R optimizer
stage, and that the delta predicate is in the first rule position.

Figure~\ref{ch:opt:fig:planseed} contains the single rule that creates an
initial plan, from each rule in the program, using the delta predicate.  A
\ol{plan} tuple represents a query plan for a given rule, and the plan's
\ol{size} reflects the number of term identifiers covered in the $Group$
attribute (i.e., the number of leaves in the plan tree).  The optimizer listens
on the \ol{systemr::programEvent} event stream in rule \ol{sr1}, which
initiates the optimization process.  The \ol{systemr::programEvent} tuple is
joined with the \ol{sys::rule} table along the $Pid$ (program identifier)
attribute to obtain the set of rules defined in the input program.  This result
set of rule tuples are joined with the \ol{sys::predicate} table along the
$Rid$ (rule identifier) attribute; producing a tuple for each predicate term
defined by a given rule.  The predicate term assigned to position~$1$ ($Pos ==
1$) is by convention the event predicate term.  The result of this rule creates 
a \ol{plan} of ``size~$1$'' for each rule in the input program.  The
$Group$ attribute is initialized to a list containing the $PredID$ of the event
predicate and the $PlanID$ is used to hold the actual plan definition.  As plan
enumeration proceeds, we append new subgoal term identifiers to the $Group$
attribute and physical operator descriptions (e.g., sort-merge join) to the
$PlanID$ attribute.

The \OVERLOG optimizer defines a set of plan generation rules that together
perform the induction step of the dynamic program.  These rules extend a best
plan of $k$ terms with a $(k+1)^{st}$, thus far unused term from the rule body.
If the new term considered is a table predicate, then the new plan ($PlanID$)
is annotated with an appropriate join method, which takes the optimal subplan
and ``joins it'' with the predicate table.  The join methods supported by P2
include scanned and index-nested-loop join, as well as sort-merge join.  A plan
tuple also carries with it an associated cost, which only considers CPU costs
since all P2 relations reside in memory~\footnote{Including other cost metrics
(e.g., I/O) would entail modifying the cost estimations defined in
rules~\ol{sr2}, \ol{sr3}, and \ol{sr4}.}.  We now turn to the description of
the rules that generate plans for nested-loop-join, index nested-loop-join, and
sort-merge join methods.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr2 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :- 
    bestPlan(@A, Pid, Rid, OPlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::predicate(@A, Pid, Rid, PredID, ..., Tid, PSchema, Pos, ...),
    Pos > 1,
    sys::table(@A, Tid, ..., TCard, Sort),
    f_contains(PredID, OGroup) == false,
    PlanID := f_cons(``nested-loop'', OPlanId, PredID),
    Group  := f_cons(PredID, OGroup),
    Schema := f_joinSchema(OSchema, PSchema),
    Sort   := OSort,
    Card   := f_nlj_card(OCard, OSchema, TCard, PSchema),
    Cost   := f_nlj_cost(OCost, OSchema, TCard, PSchema).
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen1}nested-loop join method.}
\end{figure*}

All materialized table predicates appearing in the rule body are considered when
creating a nested-loop join plan, which is derived by rule~\ol{sr2} in
Figure~\ref{ch:opt:fig:plangen1}.  Rule~\ol{sr2} is evaluated on an update to the
\ol{bestPlan} relation (described in Chapter~\ref{ch:opt:fig:bestplan}), which
contains the plan identifier ($OPlanID$) used to select the reference (optimal)
subplan in the \ol{plan} relation.  The result of joining \ol{bestPlan} with 
the \ol{plan} table gives us the ``outer'' plan of the nested-loop join method.

We extend the ``outer'' \ol{plan} with an ``inner'' table predicate by joining
with the \ol{sys::predicate} relation along the same rule identifier ($Rid$).
The selection predicate $Pos > 1$ ensures that we do not consider the rule head
predicate (the zeroth term by convention) or the delta predicate (the first
term position).  The outer plan tuple contains a list ($OGroup$) of the term
identifiers that already appear in it.  This list is used to prune results that
reference inner table predicates already appearing in the outer plan.  This
test happens in the $f\_contains$ function, which checks for inner table
predicate membership in the outer plan term list.

The next step is to assign a cost to our nest-loop join plan.  This cost
depends on cardinality estimates for the outer plan---already defined in the
\ol{plan} tuple--- and the inner relation.  Cardinality estimates for the inner
relation are given by the \ol{sys::table} predicate, which is joined with the
\ol{sys::predicate} in rule~\ol{sr2} along the $Tid$ (table identifier)
variable.  The functions $f\_nlj\_cost$ and $f\_nlj\_card$ consider existing
costs and cardinality estimates, as well as the (join) input schemas.  If the
input schemas force a cross-product plan, then $f\_nlj\_cost$ assigns an
infinite cost, which postpones this plan relative to other plans that contain
joining attributes.  We also note that the result order that this plan produces
is identical to the order of the outer plan, which is referenced by the $OSort$
variable.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr3 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    bestPlan(@A, Pid, Rid, OPlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::predicate(@A, Pid, Rid, PredID, ..., Tid, PSchema, Pos, ...),
    Pos > 1,
    sys::table(@A, Tid, ..., TCard, Sort),
    sys::index(@A, Iid, Tid, Key, Type, Selectivity),
    f_contains(PredID, OGroup) == false,
    f_indexMatch(OSchema, PSchema, Key),
    PlanID := f_cons(``index-loop'', OPlanID, PredID, Iid),
    Group  := f_cons(PredID, OGroup),
    Sort   := OSort,
    Card   := OCard * (Selectivity * TCard),
    Cost   := OCost + Card.
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen2}index-nested-loop join method.}
\end{figure*}

An index-nested-loop join plan is generated by rule \ol{sr3} in
Figure~\ref{ch:opt:fig:plangen2}.  Like rule~\ol{sr2}, it joins the
\ol{bestPlan}, \ol{plan}, \ol{sys::predicate}, and \ol{sys::table} predicates
to get all table predicates and cardinality estimates for predicates that do
not appear in the $OGroup$ term list.  That result is subsequently joined with
the (additional) \ol{sys::index} predicate, which adds index information to the
this result.  The function {\em f\_indexMatch} tests if the index can be used
to perform the join using attributes from the outer plan schema ($OSchema$) and
attributes from the inner predicate table ($PSchema$).  Any resulting tuples
are assigned example cardinality and cost estimates, which now use the
additional {\em index} selectivity information given by the $Selectivity$
variable defined by the \ol{sys::index} predicate.  We also support range
predicates in our index-nested-loop join plans but do not discuss them in
detail.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr4 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    bestPlan(@A, Pid, Rid, OPlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::predicate(@A, Pid, Rid, PredID, ..., Tid, PSchema, Pos, ...),
    Pos > 1,
    sys::table(@A, Tid, ..., TCard, TSort),
    f_contains(PredID, OGroup) == false,
    JM     := f_sortPlan(OSort, OSchema, PSchema, TSort),
    PlanID := f_cons(``sort-merge'', OPlanID, PredID, JM),
    Group  := f_cons(PredID, OGroup),
    Sort   := f_sortJoinAttributes(OSort, OSchema, 
                                   PSchema, TSort),
    Schema := f_sortMerge(Sort, OSchema, PSchema),
    Card   := OCard * (TCard / 10),
    Cost   := f_sortCost(JM, OCard, TCard).
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen3}sort-merge join method.}
\end{figure*}

Figure~\ref{ch:opt:fig:plangen3} shows the rule for generating a sort-merge
join plan, which considers a best plan and a new table predicate joined along
some ordered attributes.  The tuples from the outer plan and the inner table
predicate can be ordered by some attributes, or not.  We note that the $TSort$
attribute in the \ol{sys::table} table identifies the ordered attributes of the
inner relation, while $OSort$ refers to the order of the outer tuples.  

The join method variable $JM$ is given a value that indicates the need to
presort the inner relation, or not.  In our implementation of the sort-merge
join operator, we decided not to sort the outer relation by first draining all
of its tuples, sorting them, and then merging with the sorted inner
relation.~\footnote{This would have added significant complexity to the P2
dataflow architecture, which is optimized for tuple at a time processing.}
Instead, each outer tuple is used to perform a binary search on the sorted
inner relation, which returns any tuples that join along the relevant
attributes.  If we know that the tuples from the outer result will be given in
order, then we can optimize this binary search to be like a
merge-join.~\footnote{We maintain a cursor state on the inner relation that
tells us where the last join match occurred.} These costs are considered by the
{\em f\_sortCost} function, which takes the assigned join method and the input
cardinalities and returns a plan cost.  The output of a sort-merge join plan
includes the join attribute in the $Sort$ variable.

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr5 plan(@A, Pid, Rid, PlanID, Group, Sort, Schema, Card, Cost) :-
    bestPlan(@A, Pid, Rid, OPlanID),
    plan(@A, Pid, Rid, OPlanId, OGroup, OSort, OSchema, OCard, OCost),
    sys::select(@A, Sid, Rid, BoolExpr, ...),
    f_contains(Sid, OGroup) == false,
    f_filter(OSchema, BoolExpr) == true,
    PlanID := f_cons(``filter'', OPlanID, Sid),
    Group  := f_cons(Sid, OGroup),
    Sort   := OSort,
    Schema := OSchema,
    Cost   := OCost,
    Card   := OCard / 3.
\end{lstlisting}
\caption{\label{ch:opt:fig:plangen4}selection predicate filter plan.}
\end{figure*}

Figure~\ref{ch:opt:fig:plangen4} contains a rule that creates a plan out of any
selection predicates in the rule body.  A selection predicate plan is created
when all variables mentioned in its boolean expression ($BoolExpr$) are bound
by the current outer plan schema ($OSchema$).  Applying a selection filter does
not change the sorting attribute of the outer plan, nor does it effect its
schema.  We assume the cost of a ``filter'' plan is negligible, but could
add a function that considers certain operational costs.  Furthermore,
we use a generic cardinality estimation here but could associate meta-data
(e.g., attribute distributions and min/max values) with the \ol{plan} relation
that would tune this estimator.

\subsection{Best plan selection}
\label{ch:opt:sec:bestplan}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr6 bestGroupCost(@A, Pid, Rid, Group, a_min<Cost>) :-
    plan(@A, Pid, Rid, PlanID, Group, ..., Cost).

sr7 bestOrderCost(@A, Pid, Rid, Group, Sort, a_min<Cost>) :-
    interestingOrder(@A, Pid, Rid, PlanID),
    plan(@A, Pid, Rid, PlanID, Group, Sort, ..., Cost).

sr8 interestingOrder(@A, Pid, Rid, PlanID) :-
    plan(@A, Pid, Rid, PlanID, ..., PlanSchema, ..., Cost),
    sys::rule(@A, Pid, Rid, HeadPredID, ...),

    /* The head predicate */
    sys::predicate(@A, Pid, Rid, HeadPredID, ..., HeadPredSchema, ...),

    /* A rule body predicate */
    sys::predicate(@A, Pid, Rid, BodyPredID, ..., BodyPredSchema, ...),
    HeadPredID != BodyPredID,

    /* participates in a later join OR 
       is a prefix of a grouping attribute */
    (f_contains(BodyPredID, PlanID) ==  false && 
     f_contains(f_joincond(PlanSchema, BodyPredSchema), Sort)) ||
    f_isGroupByPrefix(Sort, HeadPredSchema) ==  true.

sr9 bestPlan(@A, Pid, Rid, PlanID) :-
    bestGroupCost(@A, Pid, Rid, Group, Cost),
    plan(@A, Pid, Rid, PlanID, Group, Sort, ..., Cost),

sr10 bestPlan(@A, Pid, Rid, PlanID) :-
     bestOrderCost(@A, Pid, Rid, Group, Sort, Cost),
     plan(@A, Pid, Rid, PlanID, Group, Sort, ..., Cost),
\end{lstlisting}
\caption{\label{ch:opt:fig:bestplan}Best plan selection.}
\end{figure*}

Figure~\ref{ch:opt:fig:bestplan} shows the rules that select the best plan from
a set of equivalent plans, in terms of the output they produce and the order in
which it comes.  The \ol{bestGroupCost} predicate of rule~\ol{sr6} identifies
the plan with the minimum cost from the set of equivalent plans, regardless of
order.  This is followed by rule~\ol{sr7}, which queries the \ol{plan} and
\ol{interestingOrder} relations for the minimum cost plans for each equivalent
interesting order.  Recall that the $Group$ variable references all the
predicate identifiers that participate in this plan.  We use a {\em set-based}
container object to hold these identifiers so that when a comparison is made
between to such objects, it is based on the containment of the same
identifiers.  Therefore, the purpose of the $Group$ variable is to ensure that
we select the minimum cost plan among the {\em set of} equivalent plans.  The
purpose of rule~\ol{sr6} is to ensure we consider the costs associated with
interesting ordered plans.

Rule~\ol{sr8} determines if a plan that is sorted on a given attribute is
interesting.  This occurs in P2 when the plan is sorted along attributes that
are relevant to a later join or are a prefix of the grouping attributes.  The
body of this rule joins a \ol{plan} tuple with the \ol{predicate} table, twice,
to get the head predicate and a body predicate that does not already exist in
the plan.  The final selection predicate in this rule checks the necessary
conditions, and if met, the rule will generate an \ol{interestingOrder} tuple
referencing the given $PlanID$.  The remaining two rules (\ol{sr9} and
\ol{sr10}) populate the \ol{bestPlan} table with the actual optimal plan
information.

\subsubsection{Improving Selectivity Estimation}

For equality selection predications, our System R rules above support
selectivity estimates using a uniform distribution estimator given by the
index.  For more precise estimates and to handle range predicates, we have
defined declarative rules that produce equiwidth histograms ({\em
ew-histograms}); additional histogramming rules could be added analogously.
The creation of an ew-histogram is triggered by the installation of a fact in a
metadata table of the ew-histograms defined in the system.  The metadata table
contains the parameters of the histogram (i.e., the table name, the attribute
position, and the number of buckets).  For example, the fact \[
\ol{sys::ewhistogram::metadata}(@LOCALHOST, "pred", 3, 10).  \] creates a ten
bucket equi-width historgram on table \ol{pred} for the attribute in the third
position.

Each fact in the ew-histogram table triggers Evita Raced rules that themselves
generate new rules to create ew-histograms (determining bucket boundaries based
on the bucket count and the min and max values of the attribute), and to
maintain bucket counts (performing a count aggregation over the table
attributes, grouped by the bucket boundaries).  The compiler stage that
generates ew-histograms in this fashion consists of $23$ rules ($92$ lines).
The histogram data is stored in relational format with each row corresponding
to a single bucket.  Exploiting these histograms required an aggregation query
to sum up appropriate bucket boundaries based on selection predicates
in the user query.  The cost and selectivity estimators, in the \ol{plan}
generation rules, were then modified to incorporate the result of these bucket
aggregates, and used to obtain density estimations for a given selection
predicate

\subsection{Termination}
\label{ch:opt:sec:termination}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
sr11 rules(@A, Pid, a_count<Rid>) :-
     systemr::programEvent(@A, Pid, ...),
     sys::rule(@A, Pid, Rid, ...).

sr12 completeRule(@A, Pid, Rid) :-
     bestPlan(@A, Pid, Rid, PlanID),
     sys::rule(@A, Pid, Rid, ..., Goals),
     f_sizeof(PlanID) == Goals - 1.

sr13 completeRuleCount(@A, Pid, a_count<Rid>) :-
     completeRule(@A, Pid, Rid).

sr14 sys::program(@A, Pid, ..., ``systemr'', ...) :-
     completeRuleCount(@A, Pid, Count),
     rules(@A, Pid, Count),
     sys::program(@A, Pid, ..., Stage, ...).
\end{lstlisting}
\caption{\label{ch:opt:fig:systemrend}System R termination rules.}
\end{figure*}

Figure~\ref{ch:opt:fig:systemrend} presents our rules for terminating the
System R optimizer stage.  Rule~\ol{sr11} counts the number of rules in the target
program.  This count will be used to check for our end condition, which occurs
when all rules have been given a \ol{bestPlan} tuple with a plan size equal to
the number of subgoals.  Rule~\ol{sr12} identifies the completion of a rule based
on this end condition, while rule~\ol{sr13} counts the number of completed rules
for a given program.  Finally, when the counts in \ol{completeRuleCount} and
\ol{rules} are equal, rule~\ol{sr14} generates the termination signal for a given
program by inserting a new tuple into the \ol{program} program with the ``systemr''
stage name.

\section{Cascades Optimization}
\label{ch:opt:sec:cascades}

The bottom-up, dynamic programming search strategy described in
Chapter~\ref{ch:opt:sec:systemr} is a natural fit to a Datalog-based rule
language.  One might think a top-down Cascades-style optimization
strategy~\cite{cascades} would be difficult to implement since \OVERLOG, like
Datalog, is evaluated in a bottom-up fashion.  This is partially true but still
relatively straightforward.  Since the System R search strategy conforms to the
\OVERLOG evaluation strategy, we did not need to write explicit rules for
traversing through the plan space.  That is, the System R search strategy was
implicitly implemented by the \OVERLOG bottom-up evaluation.  A top-down search
strategy, on the other hand, requires extra logic to guide the search through
the plan space in a top-down order.  The logic of a top-down search strategy
follows a dynamic programming technique called memoization, which turns out to
be just as natural and intuitive in \OVERLOG, and therefore can be implemented
in Evita Raced.

The remainder of this chapter presents our implementation of the Cascades
branch-and-bound optimization in \OVERLOG.  Chapter~\ref{ch:opt:sec:overview}
provides a short description of the Cascades algorithm, before describing our
declarative rules that implement the algorithm.  Our rules are divided into
three logical modules---search strategy
(Chapter~\ref{ch:opt:sec:cascades_search}), plan generation
(Chapter~\ref{ch:opt:sec:cascades_plan}) and winner selection
(Chapter~\ref{ch:opt:sec:cascades_winner})---that model a paper
description~\cite{Shapiro-opt}.  Our rules for plan generation and winner
selection may remind the reader of the plan generation and best plan rules in
the previous System R discussion.  However, the search strategy rules are
unique to this optimization stage, and will therefore be the focus our
attention.

\subsection{Overview}
\label{ch:opt:sec:overview}

Our description of the Cascades optimizer follows the notation of Shapiro, et
al.~\cite{Shapiro-opt}.  Cascades' plans are classified into {\em groups},
which is an equivalence class of expressions (i.e., predicates) that produce
the same result.  During the optimization, each group (e.g., [ABC] consisting
of table predicates A, B, and C) represents a container to physical plans
(e.g., \{[AB]~\ol{sort-merge-join}~[C]\}, \{[B]~\ol{nested-loop-join}~[AC]\},
\ldots) over subexpressions in that group.  In order to keep the search space
small, a group only references top-level physical plans through {\em
multiexpressions}, which are plan expressions that restrict the input of
operators to subgroups.  For example, group [ABC] references the
multiexpression \{[AB]~\ol{sort-merge-join}~[C]\}, whose \ol{sort-merge-join}
operator takes groups [AB] and [C] as input, instead of the (possibly many)
individual plans within these subgroups.
Associated with each group is a {\em winner's circle}, which identifies the
optimal plan within a given group, and will be the plan chosen to represent the
group, referenced by top-level multiexpressions.  

At a high-level, the branch-and-bound algorithm that drives the Cascades
optimizer performs the following actions.  The search strategy generates groups
in a top-down order, and within each group it performs a bottom-up search for
the cheapest multiexpression, which is called the {\em winner}.  The top-down
order follows a depth-first search over the space of multiexpressions, where a
particular {\em branch} (multiexpression) is fully explored before considering
another.  An upper bound, initialized to $\infty$, is assigned to each group.
The upper bound is updated as new (cheaper) multiexpressions for the given
group are discovered.  The group bound is carried down each branch of the
depth-first search.  A multiexpression is pruned if its cost exceeds the group
bound.  The optimization terminates when the root group (containing all
expressions in the query) has been fully explored, and a winner chosen.  In the
discussion that follows, when we indicate a {\em plan} we mean a
multiexpression within a group.

\subsection{Search strategy}
\label{ch:opt:sec:cascades_search}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
/* Initialize the top-level group */
bb1 groupSeed(@A, Rid, a_list<PredID>, a_list<Schema>) :-
    cascades::programEvent(@A, Pid, ...),
    sys::predicate(@A, Pid, Rid, PredID, ..., Schema, Pos, ...),
    Pos > 1. /* Exclude the head and event predicates */

bb2 group(@A, Rid, GroupID, PredList, SchemaList) :-
    groupSeed(@A, Rid, PredList, SchemaList),
    f_sizeof(PredList) > 1,
    GroupID := f_mkGroupID(PredList).

/* Initialize a new branch and bound on the given group. */
bb3 branch(@A, Rid, GroupID, Pos, Bound) :-
    group(@A, Rid, GroupID, PredList, SchemaList),
    Pos   := 0,
    Bound := infinity.

%* /* Extract the subgroup of predicates that don't include position $Pos$ */ *)
bb4 group(@A, Rid, SubGroupID, SubPredList, SubSchemaList) :-
    branch(@A, Rid, GroupID, Pos, Bound),
    group(@A, Rid, GroupID, PredList, SchemaList),
    Pos < f_sizeof(PredList),
    SubPredList   := f_remainder(PredList, Pos),
    SubSchemaList := f_remainder(SchemaList, Pos),
    SubGroupID    := f_mkGroupID(SubPredList).

%* /* Extract the predicate at position $Pos$ */ *)
bb5 group(@A, Rid, SubGroup, SubSchema) :-
    branch(@A, Rid, GroupID, Pos, Bound),
    group(@A, Rid, GroupID, PredList, SchemaList),
    Pos < f_sizeof(PredList),
    SubPredList   := f_get(PredList, Pos),
    SubSchemaList := f_get(SchemaList, Pos),
    SubGroupID    := f_mkGroupID(SubPredList).

/* Move the branch position forward when the branch group is complete. */
bb6 branch(@A, Rid, GroupID, PredList, SchemaList, Pos+1, Bound) :-
    branchComplete(@A, Rid, GroupID, Pos, Cost),
    branch(@A, Rid, GroupID, Pos, OldBound),
    group(@A, Rid, GroupID, PredList, SchemaList),
    Pos <= f_sizeof(PredList), // termination when: Pos == |PredList|
    Bound := Cost < OldBound ? Cost : OldBound.

%* /* A branch for a specific group is complete when we receive an update 
      to the \ol{winner} relation. */ *)
bp7 branchComplete(@A, Rid, GroupID, Pos, Cost) :-
    winner(@A, Rid, GroupID, Pos, Cost).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_top_down} Cascades top-down search strategy rules.}
\end{figure*}

The optimization begins when the root group (e.g., [ABC]) is inserted into the
\ol{group} table, and a \ol{branch} tuple is created to initiate a depth-first
traversal over the plan space.  This is initiated by rules~\ol{bb1}
and~\ol{bb2} in Figure~\ref{ch:opt:fig:cascades_top_down} after the
\ol{cascades::programEvent} tuple is received.  Rule~\ol{bb1} aggregates {\em
lists} (not sets) of predicate identifiers and schemas, for each rule in the
program.  Rule~\ol{bb2} converts \ol{groupSeed} tuples to \ol{group}
tuples by creating a $GroupID$ variable, which uses a set-based object to hold
the identifiers from the $PredList$ variable.  Rule~\ol{bb3} is triggered on
updates to the \ol{group} relation, and creates a \ol{branch} tuple
containing the group identifier, an initial branch position, and an initial
bound ($\infty$) for this group.  Rules~\ol{bb4} and \ol{bb5} create new
subgroups, by first (\ol{bb4}) excluding the predicate at the branch position
$Pos$, and the second (\ol{bb5}) including only it.

The \ol{branch} tuples are used in the generation of \ol{plan} tuples; using
the rules described in Chapter~\ref{ch:opt:sec:cascades_plan}.  Here, we must
ensure that we do not update the branch position until all plans for the
current branch position have been evaluated.  We can detect this constraint by
simply waiting for an update to the \ol{winner} predicate, which includes the
group identifier.  A group has been fully exported when a \ol{winner} tuple
exists for the given group and branch position.  This property holds, since we
evaluate branches bottom-up and the result of that evaluation is exposed after
a dataflow fixpoint.  Rule~\ol{bp7} then creates a \ol{branchComplete} tuple
when a \ol{winner} tuple is derived, which prompts rule~\ol{bb6} to move the
\ol{branch} tuple position forward by one, with a bound that considers the cost
of the given \ol{winner}.

\subsection{Plan Generation}
\label{ch:opt:sec:cascades_plan}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
bp8 plan(@A, Rid, GroupID, PlanID, Schema, Sort, Card, Cost) :-
    branch(@A, Rid, GroupID, Pos, Bound),
    group(@A, Rid, GroupID, _, SchemaList),
    f_sizeof(PredList) == 1,
    PlanID := f_cons(``delta'', f_get(GroupID)),
    Schema := f_mkSchema(SchemaList),
    Sort   := null,
    Card   := 1,
    Cost   := 1.

bp9 plan(@A, Rid, GroupID, PlanID, Schema, OSort, Card, Cost) :-
    /* Information associated with some winner plan. */
    winner(@A, Rid, OGroupID, OPlanID, _, _),
    plan(@A, Rid, OGroupID, OPlanID, OSchema, OSort, OCard, OCost),

    /* Evaluate predicates that belong to a branch of size one */
    branch(@A, Rid, IGroupID, _, _),
    f_sizeof(IGroupID) ==  1, // contains a single predicate
    sys::predicate(@A, Pid, Rid, PredID, ..., Tid, ISchema, Pos, ...),
    f_get(IGroupID) == PredID, 
    f_exists(PredID, OGroupID) == false, // not part of outer plan
    sys::table(@A, Tid, ..., TCard, TSort),

    /* Find the parent branch */
    branch(@A, Rid, GroupID, Pos, Bound),
    f_combine(OGroupID, IGroupID) == GroupID,

    PlanId := f_cons(``nested-loop'', OPlanID, PredID),
    Schema := f_mkSchema(OSchema, ISchema),
    Card   := f_card(OSchema, ISchema, OCard, TCard),
    Cost   := f_cost(OSchema, ISchema, OCost, OCard, TCard),
    Cost <= Bound.
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_plan1} Cascades plan generation rules for event
predicates and nested-loop join method.}
\end{figure*}

We now present our rules for generating \ol{plan} tuples related to the group
referenced by the \ol{branch} tuple.  Figure~\ref{ch:opt:fig:cascades_plan1}
presents our first set of rules that derive \ol{plan} tuples for a given group.
Rule~\ol{bp8} handles the case when a single predicate identifier is referenced
by the $GroupID$ attribute.  The plan for this case is a streaming delta
predicate, which is placed in the first position of the rule body.  

Rule~\ol{bp9} generates a nested-loop join \ol{plan} using a ``winner'' plan as
the outer and a single table predicate as the inner.  The \ol{winner} relation
(described in Chapter~\ref{ch:opt:sec:cascades_winner}) identifies the best
plans for a given group.  The rule joins the \ol{winner} predicate with the
\ol{plan} predicate to obtain an actual best plan.  For the inner predicate, we
look for a \ol{branch} containing a single predicate and associate it with the
\ol{sys::predicate} and \ol{sys::table} predicates to obtain the desired
inner information (i.e., $PredID$, $ISchema$, and $TCard$ variables).  We then look
for the (parent) branch containing all the predicates mentioned in $OGroupID$
and $IGroupID$.  We need this check to ensure that we only generate plans with
existing branches.  Also note that the $Bound$ variable is used here for
pruning expensive plans.  We finalize the rule by creating remaining variables
needed by the \ol{plan} projection.  Like our System R rules, we use the plan
identifier ($PlanID$) to hold the actual plan definition.

%\begin{figure*}
%\ssp
%\centering
%\begin{lstlisting}
%bp9 plan(@A, Rid, Group, PlanID, OuterSort, OuterGroup, InnerGroup, 
%         Card, Cost) :-
%    branch(@A, Rid, Group, Schema, Pos, Bound),
%    winner(@A, Rid, OuterGroup, OuterPlanId),
%    plan(@A, Rid, OuterGroup, OuterPlanID, OuterSort, ..., 
%         OuterCard, OuterCost),
%    group(@A, Rid, OuterGroup, OuterSchema),
%
%    group(@A, Rid, InnerGroup, InnerSchema),
%    sys::table(@A, Tid, TableName, ..., InnerCard, InnerSort),
%    sys::index(@A, Iid, Tid, Key, Type, Selectivity),
%    f_sizeof(InnerGroup) == 1 && f_get(InnerGroup, 0) == TableName,
%
%    f_combine(OuterGroup, InnerGroup) == Group,
%    f_joinCol(OuterSchema, InnerSchema) == f_get(InnerSchema, Key),
%    Cost := OuterCost + OuterCard,
%    Cost < Bound,
%    Card := OuterCard * (InnerCard * Selectivity),
%    PlanId := f_cons("index-loop", OuterPlanID, Tid, Iid).
%
%bp10 plan(@A, Rid, Group, PlanID, Sort, OuterGroup, InnerGroup, 
%          Card, Cost) :-
%     branch(@A, Rid, Group, Schema, Pos, OldBound),
%     winner(@A, Rid, OuterGroup, OuterPlanId),
%     plan(@A, Rid, OuterGroup, OuterPlanID, OuterSort, ..., 
%          OuterCard, OuterCost),
%     group(@A, Rid, OuterGroup, OuterSchema),
%     group(@A, Rid, InnerGroup, InnerSchema),
%     sys::table(@A, Tid, TableName, ..., InnerCard, InnerSort),
%     f_sizeof(InnerGroup) == 1 && f_get(InnerGroup, 0) == TableName,
%     f_combine(OuterGroup, InnerGroup) == Group,
%     Sort := f_joinAttribute(OuterSort, OuterSchema, 
%                            InnerSort, InnerSchema),
%     Cost := f_sortJoinCost(OuterSort, OuterCard, 
%                            InnerSort, InnerCard),
%     Cost < Bound,
%     Card := (OuterCard * InnerCard) / 3,
%     PlanId := f_cons(``sort-merge'', OuterPlanID, Tid, Sort).
%\end{lstlisting}
%\caption{\label{ch:opt:fig:cascades_plan2} Cascades plan generation rules for index-loop
%and sort-merge join methods.}
%\end{figure*}

The rules that cover index-loop and sort-merge join methods trivially follow
from rule~\ol{bb8} and the System R respective rules (\ol{sr3} and \ol{sr4}),
so we elide their details.  Like System R rules, we need to consider various
properties of these join methods.  First, when considering an index-loop join
of an outer ``winning'' plan and an inner table predicate, we include the index
definition relevant to the joining attributes.  Second, for the sort-merge join
case we ensure the join attributes define the order of the inner
relation---sorting if necessary---so that for each tuple in the outer plan, we
can perform a (possibly optimized) binary search on inner relation.  The cost
of this plan depends on the ordering properties of the outer and inner plans,
and the output is ordered by the join attributes.  We also omit the rule that
handles selection predicates, which follows from rule~\ol{sr5} in
Figure~\ref{ch:opt:fig:plangen4}.

\subsection{Winner Selection}
\label{ch:opt:sec:cascades_winner}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
/* Determine the best overall cost for a given plan. */
bb10 bestGroupCost(@A, Rid, GroupID, Pos, a_min<Cost>) :-
     branch(@A, Rid, GroupID, Pos, _),
     plan(@A, Rid, GroupID, PlanID, Schema, Sort, Card, Cost).

/* Determine the best cost plan for each ordered result. */
bb11 bestOrderCost(@A, Rid, GroupID, Pos, Sort, a_min<Cost>) :-
     branch(@A, Rid, GroupID, Pos, _),
     plan(@A, Rid, GroupID, PlanID, Schema, Sort, Card, Cost),
     interestingOrder(@A, Pid, Rid, PlanID).

/* Identify interesting ordered plans. */ 
bb12 interestingOrder(@A, Pid, Rid, PlanID) :-
     plan(@A, Rid, GroupID, PlanID, Schema, Sort, Card, Cost),
     sys::rule(@A, Pid, Rid, HeadPredID, ...),
     sys::predicate(@A, Pid, Rid, HeadPredID, ..., HeadPredSchema, ...),
     sys::predicate(@A, Pid, Rid, BodyPredID, ..., BodyPredSchema, ...),
     HeadPredID != BodyPredID, 
     (f_contains(BodyPredID, GroupID) ==  false &&
      f_contains(f_joincond(Schema, BodyPredSchema), Sort)) ||
     f_isGroupByPrefix(Sort, HeadPredSchema) ==  true.

/* Choose a winner based on the best overall cost. */
bb13 winner(@A, Rid, GroupID, PlanId, Pos, Cost) :-
     bestGroupCost(@A, Rid, GroupID, Pos, Cost),
     plan(@A, Rid, GroupID, PlanID, ..., Cost).

/* Choose a winner from each interesting ordered plans. */
bb14 winner(@A, Rid, GroupID, PlanId, Pos, Cost) :-
     bestOrderCost(@A, Rid, GroupID, Pos, Sort, Cost),
     plan(@A, Rid, GroupID, PlanID, _, Sort, _, Cost).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascades_winner} Cascades winner selection rules.}
\end{figure*}

The rules in Figure~\ref{ch:opt:fig:cascades_winner} select {\em winner} plans
from the plans generated for a given group.  We begin with rule~\ol{bb10},
which determines the cost of an optimal plan, regardless of its order.  The
\ol{bestGroupCost} predicate, in rule~\ol{bb11}, identifies an optimal plan
from each group of interestingly ordered plans.  Rule~\ol{bb12} is nearly
identical to rule~\ol{sr8}, both of which determine the orders that are
interesting based on later grouping and joining attributes.  Finally,
rules~\ol{bb13} and~\ol{bb14} select winners based on the costs referenced by
the \ol{bestGroupCost} and \ol{bestOrderCost} predicates.


\subsection{Termination}
\label{ch:opt:sec:cascadesend}

\begin{figure*}
\ssp
\centering
\begin{lstlisting}
bb15 rules(@A, Pid, a_count<Rid>) :-
     cascades::programEvent(@A, Pid, ...),
     sys::rule(@A, Pid, Rid, ...).

bb16 completeRule(@A, Pid, Rid) :-
     branch(@A, Rid, GroupID, Pos, _),
     f_sizeof(GroupID) == Pos.

bb17 completeRuleCount(@A, Pid, a_count<Rid>) :-
     completeRule(@A, Pid, Rid).

bb18 sys::program(@A, Pid, ..., ``cascades'', . ..) :-
     completeRuleCount(@A, Pid, Count),
     rules(@A, Pid, Count),
     sys::program(@A, Pid, ..., Stage, ...).
\end{lstlisting}
\caption{\label{ch:opt:fig:cascadesend}Cascades termination rules.}
\end{figure*}

Figure~\ref{ch:opt:fig:cascadesend} contains the four rules used to detect the
termination condition of this optimization stage.  These rules resemble the
System R termination rules in Figure~\ref{ch:opt:fig:systemrend}.  The first
rule (\ol{bb15}) counts the total number of rules in the target program.
Rules~\ol{bb16} and \ol{bb17} count how many rules have completed, which occurs
when the \ol{branch} cursor has moved beyond the last predicate.  Some number
of fixpoints later, when the \ol{completeRuleCount} reaches the total number of
rules in the program, rule~\ol{bb18} terminates the optimization stage, and
projects a new \ol{sys::program} tuple with the stage attribute set to
``cascades.''


%\section{Discussion}
%\label{ch:opt:sec:discussion}
%
%When we started this work, the vision of declaratively specified query
%optimization was appealing thanks to its elegance and its promise of usability
%and maintainability.  Although we remain convinced on this front, our optimism
%was tempered by the pragmatics of developing software within a continuously
%changing system prototype.  Here we reflect on some of the (hard) lessons we
%learned while conducting this research.
%
%P2's notion of consecutive Datalog-style fixpoints, especially in networked
%environments, still had many rough edges, both on the design and on the
%engineering front.  Because deep down P2's runtime is an event-driven execution
%engine, its basic unit of atomicity was akin to a single iteration through a
%recursive query evaluation strategy like semina\"{\i}ve evaluation, generating a
%set of derived actions (tuples to be inserted, deleted, transmitted remotely,
%or evaluated locally for further deduction) from a single incoming event, and
%committing changes to the database atomically upon completion of such a
%step~\cite{LuThesis}.  P2's Datalog-style fixpoints were implemented as
%sequences of such single-event iterations.  As a result, the system's design
%shares both event-driven and logic-style flavors, with some remaining
%unresolved conflicts (e.g., stratified Datalog).
%%, and no explicit language constructs to bridge between the two.
%
%%One example is the notion of \ol{delete} rules, the semantics of which are
%%unclear.  How is one to handle delete rules triggered by the \emph{deletion} of
%%a base tuple?  The system certainly does not support -- semantically or
%%operationally -- the ``undeleting'' of tuples that were originally deleted due
%%to a base fact that is no longer in the database.  Similarly, the semantics for
%%multiple updates to the same tuple within the same fixpoint are undefined and a
%%local tie breaking rule is chosen to decide on a consistent ordering among
%%same-fixpoint updates to the same relation.  Compiler stages that do static
%%analysis might catch such dangerous rules and alert the user.
%
%Second, as in most prototypes, the programmer interface was not polished.
%Debugging was difficult, especially since the logic language made it tough to
%understand which value corresponded to which formal attribute in a long tuple of
%a dozen or more attributes.  Though concise, declaratively specified
%optimizations pack a punch in terms of density of concepts, which only becomes
%deadlier due to the (otherwise desirable) arbitrary order of rule execution.
%Certainly a better thought-out system to debug declarative programs --
%optimizations, no less -- would have made the job easier.  To be fair, however,
%our experience with building monolithic optimizers in production database
%management systems in the past was not a great deal rosier.  It is hard to
%debug code when the output's correctness (e.g., minimality of cost) is too
%expensive to verify.
%
%Third, the evolution of the \OVERLOG language had a long way to go.  The P2
%version of the language offered no modularity, making it tough to isolate and
%reuse logically distinct components.  It did have a rudimentary concrete type
%system, but had poor support for structured types like matrices and lists.
%\OVERLOG in P2 ``cut corners'' on the proper set-orientation of Datalog; since
%program stratification was not present in the system, dealing with streaming
%aggregates required us to resort to imperative tricks like matching ``counts'',
%computed in separate ``dataflow fixpoints'', to determine that state was ready
%to be finalized.
%
%Beyond particular characteristics of P2, one hard lesson we learned was that
%extensibility and ease of use at the top often comes at the expense of
%complexity below the extensibility layer.  The tabularization of compiler state
%to enable declarative optimizations also meant that even imperative compiler
%stages such as our bootstrap stages implemented in C++ had to use tables,
%foregoing their familiar interaction with C++ data structures.  Building glue
%libraries to ease this interaction might have relieved this pain.
%
%Nevertheless, despite these complaints, we were able to get all of our desired
%optimizations expressed in \OVERLOG in a highly compact way, as promised by the
%various earlier papers on P2.  By contrast, the initial version of P2 had no
%query optimizations of interest beyond localization, which was really a
%requirement imposed by the P2 dataflow architecture on rules containing
%distributed predicates.
%
%\section{Conclusion} 
%\label{ch:opt:sec:summary} 
%
%The Evita Raced metacompilation framework allows \OVERLOG compilation tasks to
%be written in \OVERLOG and executed in the P2 runtime engine.  It provides
%significant extensibility via a relatively clean declarative language.  Many of
%the tasks of query optimization -- dynamic programming, dependency-graph
%construction and analysis, statistics gathering -- appear to be well served by
%a recursive query language.  The notion of metacompilation also leads to a very
%tight implementation with significant reuse of code needed for runtime
%processing.
%
%Even with the caveats expressed in Chapter~\ref{ch:opt:sec:discussion}, we are
%convinced that a declarative metacompiler is much easier to program and extend
%than the monolithic query optimizers we have worked on previously.  We are now
%at a point where we can add significant features (e.g., histograms, broadcast
%rewrites, stratification tests) in an hour or two, where they would otherwise
%have taken days or weeks of work in a traditional implementation.
%
%One surprising lesson of our work was the breadth of utility afforded by the
%metacompilation framework.  Although motivated by performance optimizations, we
%have used Evita Raced for a number of unforeseen tasks.  These include:
%automatically expanding user programs with instrumentation and monitoring
%logic; generating pretty-printers for intermediate program forms; language
%wrappers for secure networking functionality in the manner of
%SecLog~\cite{abadi-netdb07}; stratification detectors and other static code
%analysis.  None of these are performance optimizations per se, but all fit well
%within an extensible, declarative program manipulation framework.  More
%generally, we believe that metacompilation is a good design philosophy not only
%for our work, but for the upcoming generation of declarative engines being
%proposed in many fields.
%

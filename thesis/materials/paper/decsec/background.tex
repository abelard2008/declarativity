\section{Background}

\note{Use consistent notation using the LaTeX macros for the overlog
  environment (with begin and end) and inline overlog with \ol{blah()}.}
Since our system is based on P2, getting familiarity with some of the
basic constructs of P2 will help a lot in understanding and appreciating
our design decisions. P2 is a programming framework which uses a
high-level declarative language to express overlay networks in a highly
compact and reusable form. P2 uses tuples to represent state and
messages. Each tuple is represented as {\em name(@X, ...other
  fields...)}. The first field of a tuple is a special field called
location specifier. Location specifiers (@X) "declare" the intended node
"location" of each tuple. Thus, a programmer does not have to worry
about how the tuple reaches the given location specifier. Tuples can be
materialized (i.e.,  stored) or events. Event tuples are like messages,
and are lost after their reception. Materialized tuples on the other hand are stored and can be read at a later stage.

The high-level declarative language P2 uses is called Overlog. An
Overlog program consists of a set of rules. Each rule has the following structure:
\begin{code}
<head> :- <precondition1>, \\
\> <precondition2>, ? , <preconditionN>.
\end{code}
\begin{overlog}
head :- precondition1, ?, precondition2.
\end{overlog}
A rule of this form implies that when all the preconditions become true,
the action specified in the head should happen. The action could be the
insertion or deletion of a stored tuple or the arrival of an event tuple
at some node on the network. Consider a network reachability example
that might be useful towards a BGP implementation, to see Overlog in action. 

In the following example, the relation {\em link(@A, B)} represents that
node A has a link with node B. The relation {\em reachable(@A, B, C)}
represents that node C is reachable from node A through node B. The {\em
  saysReachable(@A, B, C)} tuple means that B offers a path via itself
to C for A's use. Link and reachable are materialized relations and saysReachable is an event tuple.
\begin{code}
r1 reachable(@A, A, B, B) :- link(@A, B).\\
r2 saysReachable(@A, A, B, C) :- \\
\> reachable(@B, B, NextHop, C), link(@B, A)\\
r3 reachable(@A, A, B, C) :- link(@A, B), \\
\> saysReachable(@A, A, B, C).
\end{code}
\begin{overlog}
r1 reachable(@A, A, B, B) :- link(@A, B).
r2 saysReachable(@A, A, B, C) :- 
  reachable(@B, B, NextHop, C), link(@B, A).
r3 reachable(@A, A, B, C) :- link(@A, B),
  saysReachable(@A, A, B, C).
\end{overlog}

The relation link can be populated differently based on the neighbor set of a node. The reachable relation is calculated based on the the link relation. Rule r1 says that if A has a link to a node B, then A assumes that it has a path to B. Rule r2 says that is a node B has a path to a node C, and node A is linked to node B, then tell node A, that it can use node B to route to C. Note that here we don't take care of the cycles for simplicity. They can be easily eliminated by keeping path vector. Finally rule r3 says that if node A is linked to node B and node B has a path to node C, then node A has a path to node C through node B. 

The next important concept in P2 world is of events rules and view rules. A rule that has an event tuple on the RHS is called an event rule. All other rules are view rules. Since rules are not allowed to contain more than one event tuple on the RHS, it implies that view rules have no event tuple on RHS. A materialized tuple also has events associated with it. These events are triggered whenever a materialized tuple is created, deleted, changed or re-refreshed. These events come under the category of external events. An external event is also triggered on receipt of a message (event tuple or stored tuple) from the network. An internal event is triggered when a rule produces an event locally (i.e the rule has an event tuple on LHS with local location specifier). 

Each rule has one or more triggering events associated with it. This triggering event dictates when the event rule is triggered. An event rule is associated with the creation of a local event(internal event) or receipt of the event tuple from network(external event). On the contrary, a view rule has multiple events associated with it. Essentially all the external events associated with the materialized tuples on the RHS are considered to be the triggering events for the view rule. Note that external events for the RHS materialized tuples are {\em not} considered to be the triggering event in event rules. So, the external event indicating the receipt of an event tuple from the network is the only external event associated with an event rule. Creation of a local event is the only local event that can occur in this system and this can only trigger event rules associated with the created event.

Next, we define the semantics of fix-point. A fix-point is like a synchronization block that defines which rules are executed concurrently. Rules not executing in a given fix-point are guaranteed to be isolated from the rules executing in that fix-point. The start of the fix-point is marked by an external event. This could be the receipt of a message or insertion, deletion, updating or refreshing of a stored tuple. All the rules associated with the external event marking the starting fix point are then executed concurrently. A specification can't rely on the ordering of execution between rules associated with a given external event. Execution of rules associated with this external event can lead to creation of several new external and local events. Any local event created by a rule in a fix-point is also processed in the same fix-point. Thus all the local events are processed until no more local events are left. External events are buffered until the end of fix-point when they are committed. Committing an external event involves performing the action associated with the external event and (possibly) inserting them into the external event queue. Action could be insertion, deletion, update or refresh of stored tuple or sending of stored or event tuple. Once all these tasks are over, next event from the external event queue is picked and a new fix-point is started.


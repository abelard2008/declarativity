\subsubsection{Authentication Algebra}

Authentication algebra defines the relationship between the says primitives. Given the desired says primitive and an available one, it gives a partial order between the two enabling the decision whether the available says primitive is {\em strong} enough to match the required says primitive or not. It also provides the semantics for combining two says primitive to produce strongest possible says primitive.

Authentication algebra is useful for following reasons:
\be
\item Authentication algebra gives us a partial order between the authentication primitive. This partial ordering enables us to decide that given an available authentication certificate and a required one, is the available certificate strong enough to be used in place of the required one. This can be the case, for example when a protocol desires simple authentication without non-repudiation, but a non-repudiable certificate is available. In this case, the non-repudiable certificate is clearly strong enough to be used in place of simple authentication certificate. Authentication algebra dis-ambiguates the ordering between the primitives in general scenarios where it might not be obvious whether an available certificate is strong enough for the desired certificate.
\item Given, two says primitive, authentication algebra enables us to combine the says primitive to produce the strongest possible says primitive. (PS This may not be obvious in many cases)
\ee

{\bf Partial Order:} We first define an partial order amongst different says primitive. We say

\begin{center}
says(P', R', k' , V') $\leq$ says(P, R, k, V), iff\\
V' $\subseteq$ V\\
R' $\subseteq$ R\\
k' $\leq$ k\\
%P' $\subseteq$ P\\
|P| - |$P \cap P'$| $\leq$ k - k'
\end{center}

Thus, a {\em says(P, R, k, V)} event also fires all the {\em says(P', R', k', V')} such that {\em says(P', R', k' , V') $\leq$ says(P, R, k, V)}. This partial ordering is based on the intuition that a certificate stronger than the required certificate should also trigger the corresponding rule. Its easy to convince that the first three conditions are necessary. This is because a bigger R set implies that more receivers can now interpret the certificate. Likewise, a bigger V set implies more verifiers and a bigger K (for same P) implies more principals from the P set are now making the statement. However, a bigger P set (for same K) doesn't necessary imply a stronger primitive. In fact, the primitives can't be unordered-ordered when $P$ increases. 

To motivate this scenario, consider a very simple example where initial $P'=\{n_{1}\}$ and $K'=1$. Now, lets consider $P={n_{1}, n_{2}}$ and $K=K'=1$. In this case, we can't claim that $says(P', R, K, V) \leq says(P, R, K, V)$. This is because $says(P, R, K, V)$ can be generated when $n_{2}$ alone is making the statement which doesn't imply that $n_{1}$ is also making the statement. In general whenever P changes, the above conditions don't suffice because the precise set of nodes that were part of any $^{P'}C_{K'}$ set needn't be a part of all possible $^{P}C_{K}$ sets. To handle this condition, we add the last terms that ensures that all the terms that are part of {\em any} possible smaller set $^{P'}C_{K'}$ are also included in {\em all} possible sets $^{P}C_{K}$.

{\bf Combining Primitives:} To ease the discussion of the combination algebra, we give some notation first. We define three axes in a primitive:
\be
\item Speaker Axis(P, K): This axis represents the speakers set in a primitive.
\item Receiver Axis(R): This axis represents the receivers set.
\item Verifier Axis(V): This axis represents the verifiers set.
\ee



Combining primitives can be an exponentially expensive operations as combining two primitives can produce up to three different primitives. This doesn't imply that the combination will have exponential cost in all scenarios. In fact, in most common cases, such as combining primitives which differ only along one axis is only linearly expensive.

We now define the $\cap$ and $\cup$ operations for each of the axis types. For receiver and verifier axis, $\cap$ and $\cup$ correspond to their counterparts in sets. However, its a little more complicated for the speaker axis. For speaker axis, the $\cup$ and $\cap$ operations are defined as follows:\\
\begin{math}
(P_{1}, K_{1}) \cup (P_{2}, K_{2}) = \\ (P_{1} \cup P_{2}, Max(K_{1}+K_{2}-|P_{1} \cap P_{2}|, K_{1}, K_{2}))\\
(P_{1}, K_{1}) \cap (P_{2}, K_{2}) = \\ (P_{1} \cap P_{2}, Max(K_{1}+K_{2}-|P_{1} \cup P_{2}|, K_{1} - |P_{1}/P_{2}|, K_{2} - |P_{2}/P_{1}|, 0))\\
\end{math} 

Now using these $\cup$ and $\cap$ operators, we can define the $+$ operator for our says primitive. We will need to apply $\cup$ along one axis and $\cap$ along the other axis.\\
\begin{math}
((P_{1}, K_{1}), R_{1}, V_{1}) + ((P_{2}, K_{2}), R_{2}, V_{2}) = \\ \{((P_{1}, K_{1}) \cup (P_{2}, K_{2}), R_{1} \cap R_{2}, V_{1} \cap V_{2}), \\
((P_{1}, K_{1}) \cap (P_{2}, K_{2}), R_{1} \cup R_{2}, V_{1} \cap V_{2}), \\((P_{1}, K_{1}) \cap (P_{2}, K_{2}), R_{1} \cap R_{2}, V_{1} \cup V_{2})\} \\
\end{math} 


\prince{Describe the rest of algebra here motivating its use: also describe the motivation for the above terms}

%\item Using the above two properties, we construct a dynamic programming algorithm enables us to determine if a required says primitive can be constructed using a number of given says primitives using some combination of the given primitives.


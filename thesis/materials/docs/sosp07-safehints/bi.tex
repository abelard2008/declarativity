\section{BI's multiple avatars}

We now illustrate multiple BI protocols that we have come up with. Goal
is to identify the strenghts and weaknesses of each of these protocols and
verify if the experimental results make sense.

\subsection{TACT style}
Each replica independently collects a batch of $\beta$-weighted requests and
responds tentatively to these requests. Once it reaches the $\beta$ bound, it
initiates a COMMIT. During COMMIT, a replica becomes client to the PBFT 
protocol and sends the request to all replicas. This commit request contains
all requests that combine to form its batch of $\beta$-weighted requests.
Once a BI-batch is committed, all replicas receive an upcall about what batch
is committed. Once (2f+1) BI batches have been linearized by the PBFT layer,
commit is considered to be complete. A replica creates a deterministic
ordering of requests from these (2f+1) batches and executes them and commits
the state. After that, it is ready to process further requests.

Advantages compared to PBFT:
\begin{itemize}
\item{} No replica-to-replica communication required other than PBFT commit.
\end{itemize}

Disadvantages compared to PBFT:
\begin{itemize}
\item{} Blocks during PBFT commit. Significant degradation at low values of 
$\beta$.
\item{} Need to send whole requests in the commit request since other replicas
may not have seen the request contained in the $\beta$-weighted batch.
\item{} Each replica independently commits, sending O(N$^2$) messages during
commit phase.
\end{itemize}



\subsection{TACT style + batching of commits}

To reduce the number of messages sent during the COMMIT phase, each replica first
sends its BI-batch to the primary. Primary collects 2f+1 such BI batches and creates
a single PBFT request and initiates PBFT protocol. Advantage is that number of messages
reduce to O(N) compared to O(N$^2$) messages required in the previous protocol. However,
an additional message delay is introduced for the commit phase.


\subsection{Preserialization + TACT style}

Similar to how we preserialize requests in PSHQ. BI replicas respond tentatively to 
requests serialized by the Preserializer. Preserializer is also able to batch these
requests to reduce its overhead. Only the preserializer replica initiates a commit
and validation is performed by the replicas during the execute upcall where they check
if at least 2f other replicas have agreed to commit what the preserializer is attempting
to commit.

Advantages:
\begin{itemize}
\item{} Each replica receives same set of requests. No need for each replica to commit
independently. Basically, reduced the time taken during the COMMIT phase.
\end{itemize}

Disadvantages:
\begin{itemize}
\item{} Additional delay introduced for processing each request tentatively. 
\item{} Additional load on the preserializer, potential bottleneck and source for additional delay.
\end{itemize}

\subsection{PBFT style}
Similar to the previous preserialization technique. However, this works inside the PBFT protocol, rather
than as a separate layer outside PBFT which calls PBFT layer. More precisely, primary of the PBFT
protocol sends Pre-Prepare requests for batches of requests. Replicas do not process them directly for
the PBFT protocol other than tentatively responding, but buffer them until they have seen 
upto $\beta$-weighted requests in these 
Pre-Prepares. Once received $\beta$-weighted Pre-Prepares, each replica sends a Prepare for each of the
buffered Pre-Prepares and PBFT protocol follows. 

Advantages:
\begin{itemize}
\item{} Avoids the extra message delays during the COMMIT phase since Pre-Prepares are already sent.
\end{itemize}

Disadvantages:
\begin{itemize}
\item{} More number of PBFT's required depending on the size of PBFT batches that the primary sends.
\item{} Blocks until all PBFT's are complete. So, increasing the number of PBFT's may hit us badly.
\end{itemize}

\subsection{Expectations}

At small values of $\beta$, blocking in the BI layer makes our protocol perform worse compared to
the PBFT protocol. 

At high values of $\beta$: why do we take more time in collecting $\beta$-weighted updates?


\section{Current status}
As of April 20, 2007 we are putting BI aside. Here is the status:

\begin{itemize}
\item{} We have found that the networking substrate of HQ is not efficient. The co-routines 
library spends more amount of time than what we expect. Improving this will help everyone,
including HQ, PBFT. So, not sure if this is what we should be doing.
\item{} Obtain the latest results for BI-PBFT and PBFT and put in the paper.
\item{} Increase the latency and put those results in the paper.
\item{} Do we really expect the throughput to be spectacularly better compared to PBFT? Even
though every message is processed by the RSM, where is the gain? Also, increasing batch sizes have
diminishing returns in terms of throughput. So, what is the expected throughput gain with BI?
\item{} Find another operating condition where BI will perform better. Disconnected operation, 
dynamically adapt between strong and weak consistency.
\item{} Is it true that current version of BI is essentially PBFT with read-only optimization?

\end{itemize}
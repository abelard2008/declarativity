\documentclass{article}

\usepackage{color,graphicx}

\usepackage{fullpage}

\newcommand{\kw}[1]{{\small \tt #1}}
\newcommand{\code}[1]{{\tt \small #1}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\imp}{\mbox{\tt \ :-\ }}
\newcommand{\datalogspace}{\textcolor[gray]{1}{.}\hspace{0.8in}}

\begin{document}
\title{OverLog semantics}
%\author{David Gay, Boon Thau Loo, \ldots}
\maketitle

\section{Motivation}

The current OverLog semantics are unclear. This is an attempt to provide a
simple, consistent description which is close to the current system. This
should allow us to a) understand OverLog better, b) have a better base for
discussing what the semantics should/can be. The semantics will be as seen
from a single node, rather than for the system as a whole.

For the sake of a clear and simple description, I will change the syntax,
and, possibly, the semantics. For now, I'm going to ignore several issues
like values, equations involving values, etc (I don't think there's any
significant changes from DataLog there anyway).

Finally, I'll intersperse \emph{Notes} in italics, for open issues,
changes, etc.

\section{OverLog: Syntax}

An OverLog program is composed of:
\begin{itemize}
\item A set of named \emph{relations} over tuples of \emph{values}. A
relation name starts with a lower-case letter. 

\emph{Note: I'll ignore values for now (assume they are drawn from some
arbitrary set $V$)}.

\item There are three kinds of relations: \emph{tables}, \emph{views} and
\emph{actors}. Tables are a persistent store for tuples and are
declared with \code{materialize}. Views are computed
from one or more tables. Actors represent computation triggered by
\emph{events}. 

\item Variables, which start with an uppercase letter.

\item Terms of the form $relation(t_1, \ldots, t_n)$, where the $t_i$'s are
variables or values. A table, view or actor term is a term whose relation
is a table, view or actor.

\item A set of \emph{rules} of the form $\mbox{head} \imp \mbox{body}$,
where the body is a comma-separated list of terms. The head is either a
term, or an \emph{action}.

\item An action is one of:
  \begin{itemize}
  \item \code{add$<t>$}, where $t$ is a table term. This corresponds to 
    adding terms to a table.

  \item \code{delete$<t>$}, where $t$ is a table term. This corresponds
    to deleting terms from a table.

  \item \code{send$<t, D>$}, where $t$ is an actor term and $D$ is a
    variable denoting a remote node. This corresponds to sending a
    message to $D$. $D$ can be the current node.
  \end{itemize}

  A rule whose head is an action or an actor term is an action rule, a
rule whose head is a view term is a view rule.

\item An event is one of:
  \begin{itemize}
    \item \code{periodic$<t, n>$}, where $t$ is an actor term, and $n$
    is a numerical value. This corresponds to periodic local alarms.
    \item \code{recv$<t>$}, where $t$ is an actor term. This corresponds
    to arriving of an actor t to a node, as a result of a send action.
    \item \code{update$<t>$}, where $t$ is a table term. This
    corresponds to adding new terms or updating existing terms in a
    table. \emph{Note: For now, deleting terms from a table does not trigger an event.}
  \end{itemize}

\end{itemize}
%\emph{Note: the differences from the current OverLog syntax are the lack of
%X annotations, the fact that actions are made explicit, and the different
%syntax for periodic actions. }

\section{Static Semantics}

\emph{Note: for the non-PL people, this means ``what is a valid program?'',
and is hopefully checked at compile-time. Typical examples are requiring
that variables be declared and type-checking. I cheated a bit in the 
syntax by including some static rules.}

OverLog relations can be categorized into tables, views and actors. A
relation is a table if it is declared with \code{materialize}. A relation
is a view if it is the head of some rule whose bodies contain only view
or table terms. In all other cases, a relation is an actor. \emph{Note:
this definition is recursive - the correct solution is the least fixed
point.}


Overlog rules have the following restrictions:

\begin{itemize}

\item A rule (both view and action) cannot have a table term as its head. \emph{Note:
there's a trivial rewrite which allows table terms as heads.} 

\item A view rule has a view term as the head, and either view or table
  terms in the body.

\item An action rule has exactly one event or exactly one actor term. The other
  terms are either view or table terms.

\item The head of an action rule must be an action or an actor.

\item For each recv$<t>$ event in an action rule, there must be a
  corresponding send$<t>$ action head in another action rule.

\item For each update$<t>$ event in an action rule, there must be a
  corresponding add$<t>$ action head in another action rule.

\end{itemize}


%\emph{Note: this
%requirement is only meaningful for rules with an action head (i.e.,
%\code{send$<>$}, \code{add$<>$}, \code{del$<>$}). For rules with actor
%terms it is true by the definition of actor relations.}

\emph{Comments: Active rules are to distinguish the bits of computation that
are ``active'', i.e., triggered by events versus those which could be
computed at any time based on the current table state (views). These
rules are not strictly necessary, but (1) it does seem easier to understand
OverLog programs if relations are cleanly separated between tables,
views and actors,  and (2) a rule like \[\code{send}<\code{fun}(X), X> \imp \code{localhost}(X)\] is not very meaningful, even if the semantics below will assign it an
actual meaning (in this case, on every event, you receive a \code{fun}
message with your own identity in it). To summarize, actions must
ultimately be triggered by events.}

\section{Semantics}
\label{sec:semantics}

The state of an OverLog program at a time $t$ is simply the state of all
its tables. This state changes as the result of events, and from tuples
added and timing out from tables. 

Events are what causes an OverLog program to execute. There are three kinds of
events: (periodic) alarms, updates to local tables, and messages. An event has an associated actor term
whose tuple is built from values only.

I'll use $\parallel$ for sequence concatenation, and names starting with an
uppercase letter for types in the semantics.

We can model the execution of an OverLog program on a single node as the 
evolution of the four-tuple $(\T, \tau, \E, \M)$, where
\begin{itemize}
\item $\T = (T_1, \ldots, T_n)$ is the state of all tables.
\item $\tau$ is the current time.
\item $\E = ((\tau_1, t_1), (\tau_2, t_2), \ldots)$ is the infinite
sequence of future events, sorted by increasing time ($t_i$ is the tuple of
the event that occurs at time $\tau_i$).
\item $\M = ((\tau_1, t_1, D_1), \ldots, (\tau_m, t_m, D_m))$ is the sequence of
messages that have been sent so far.
\end{itemize}

To handle table timeouts, tables are modeled as a function from tuples and
time to booleans: 
\begin{eqnarray*}
  \mbox{Table} = \mbox{Tuple} \times \mbox{Time} \rightarrow \mbox{Bool} \\
  \mbox{add}_t : \mbox{Table} \times \mbox{Tuple} \rightarrow \mbox{Table} \\
  \mbox{del} : \mbox{Table} \times \mbox{Tuple} \rightarrow \mbox{Table}
\end{eqnarray*}
\code{add}$_t$ is defined for each table $t$ in the obvious fashion to add a
tuple; \code{del} deletes tuples from any table.

\subsection{Execution}

The initial state is $(\T_0, \tau_0, \E_0, \emptyset)$, where
\begin{itemize}
\item $\T_0$ has all tables empty. \emph{Note: it's trivial to assume
persistence and the existence of some predefined tables, of course.}

\item $\E_0$ is built from the \code{every} declarations in the source
code, and an oracle indicating what messages this node will receive.
\end{itemize}

If no event is currently due, time passes:
\[
  (\T, \tau, ((\tau', t'), \ldots), \M) \hookrightarrow (\T, \tau', ((\tau', t'), \ldots), \M)  \mbox{ if } \tau < \tau'
\]

If an event is due, we execute it by performing queries on the OverLog
program viewed as a DataLog program. We have
\[
  (\T, \tau, ((\tau, t)) \parallel \E, \M) \hookrightarrow (\T', \tau, \E, \M')
\]
where we compute $\T', \M'$ with the help of a DataLog program built from
the OverLog program as follows:
\begin{enumerate}
\item We assert $t$.
\item We include every rule of the OverLog program whose head is
not an action.
\item For every rule whose head is an action $A$, we add a rule
to the DataLog program whose head is a new relation which includes
all the arguments of $A$. 
\end{enumerate}

We then query this DataLog program by asking the value of all actions. We
use these results to:
\begin{itemize}
\item Update the tables in $\T$ based on the results of querying the
\code{add} and \code{delete} actions, using the $\mbox{add}_t$ and
\mbox{del} functions. The result is $\T'$.
\item Update $\M$ to contain all the messages obtained by querying all
the \code{send} actions. The result is $\M'$.
\end{itemize}

\subsection{Comments}

First, note that the event is executed in zero time, and that all updates
to tables happen at the end. This seems the cleanest semantics, but of
course we could model performing the action queries one at a time, with
intervening table updates.  

Second, each event is executed independently and atomically. There is
no simultaneous execution of events, which could lead to mysterious
interaction of table updates\ldots

To return to the first point, there is a rewrite of the OverLog program
which makes \code{add}'s happen during the execution of the event: if 
we had an add to table \code{foo} \[
\code{add}<\code{foo}(A)> \imp B
\]
we can rewrite the program by adding a new relation \code{foo'}, replacing all uses of \code{foo} by
\code{foo'} (except the \code{add$<>$}), and adding the following rules:
\begin{eqnarray*}
\code{foo'}(\ldots) \imp \code{foo}(\ldots) \\
\code{foo'}(A) \imp B
\end{eqnarray*}

Note that \code{foo'} is a view, as the second rule defining it depends
only on a table (even though the first has an actor term in its body).

Finally, the use of negation is fine in OverLog if the DataLog program
generated by the semantics uses negation in an acceptable way\ldots By
reducing OverLog semantics to that of DataLog, we can reuse most of the
results for DataLog, this applies for more than negation of course (e.g.,
some paper I was reading recently mentioned that there's a ``staged'' way
of executing DataLog which supports some uses of negation).


\subsection{Routing Protocol Examples}
\label{sec:routing}

We first consider the following program from the sigcomm paper that computes all-pairs shortest
paths written in Datalog with location annotations. In traditional datalog terminology, link is a {\em base fact}, path and
bestPath are {\em derived facts}, and bestPath is also a {\em result
  fact} since it is required as the output of the query. All facts are
stored at their source nodes S and are declared as materialized.

\noindent{\bf R1: } path(S,D,P,C) :- link(S,D,C), P = $f\_concatPath$(link(S,D,C), nil). \\
{\bf R2: } path(S,D,P,C) :- link(S,Z,C$_{1}$),
path(Z,D,P$_{2}$,C$_{2}$), C = C$_{1}$ + C$_{2}$,\\
\datalogspace P = $f\_concatPath$(link(S,Z,C$_{1}$),P$_{2}$).\\
{\bf R3: } bestPath(S,D,P,C) :- min(C,(S,D),path(S,D,P,C)). \\
{\bf Query: } bestPath(S,D,P,C).\\

A possible rewrite into the proposed new Overlog is as follows:

\noindent{\bf Action rules:}\\
\noindent{\bf A1:} send$<$linkMsg(S,D,C),D$>$ :- \code{update$<$link(S,D,C)$>$}.\\
{{\bf A2:} \code{add$<$inLink(S,D,C)$>$} :- \code{recv$<$linkMsg(S,D,C)$>$}.\\
{\bf A3:} \code{add$<$path(S,D,P,C)$>$} :- \code{recv$<$pathMsg(S,D,P,C)$>$}.\\
{\bf A4:} \code{send$<$pathMsg(S,D,P,C),S$>$} :- \code{update$<$inLink(S,Z,C$_{1}$)$>$}, path(Z,D,P$_{2}$,C$_{2}$), \\
\datalogspace C = C$_{1}$ + C$_{2}$, P =
$f\_concatPath$(link(S,Z,C$_{1}$),P$_{2}$).\\
{\bf A5:} \code{send$<$pathMsg(S,D,P,C),S$>$} :- inLink(S,Z,C$_{1}$), \code{update$<$path(Z,D,P$_{2}$,C$_{2}$)$>$}, \\
\datalogspace C = C$_{1}$ + C$_{2}$, P =
$f\_concatPath$(link(S,Z,C$_{1}$),P$_{2}$).\\

\noindent{\bf View rules:}\\
{\bf V1:} bestPath(S,D,P,C) :- min(C,(S,D),path(S,D,P,C)). \\
\bf V2:} path(S,D,P,C) :- link(S,D,C), P = $f\_concatPath$(link(S,D,C), nil). \\
{\bf Query: } bestPath(S,D,P,C).\\

When link(S,D,C) at node S is updated at time t, the following happens
at node S:

\begin{enumerate}
\item \code{update$<$link(S,D,C)$>$} event is generated locally and executed.
\item Rule A1 is triggered, and generates send$<$linkMsg(S,D,C),D$>$
  action. Action \code{send$<$linkMsg(S,D,C),D$>$} is applied. This
  results in a recv$<$linkMsg(S,D,C),D$>$ in the receiving node D.
\item localPath(S,D,P,C) is updated in V2, and this generates an
  update$<$localPath$>$ event.
\item Execute next event and repeat.
\end{enumerate}


\subsubsection{Language Restrictions for Routing}

For routing, we restrict ourselves to Datalog that perform path
computations. Here are some restrictions:

Program has a {\em link table}, which represents the underlying
topology. 

\begin{itemize}
\item Paths represent the current state of path computations. They are
  computed locally and exhanged between nodes for further computation. Each path has source, destination, path vector and cost
  argument. 

\item Messages can only be sent between nodes allowable by
  underlying topology. For programs that send paths not allowed by
  underlying topology, in certain circumstances, a rewrite can be used to send back on {\em
  reverse} path of the pathVector.

\item Only paths are exchanged recursively.

\item Query must be based on an aggregate computation of the cost
  argument for path.

\end{itemize}

The above language restrictions make it easier to reason about safety of
a routing program.  Given a set of rules and initial input tables, a program is safe
(i.e. terminates) if is a finite number of derived facts are
generated. 

The additional language requirement that enables static safety checks is
as follows: the cost argument C of all recursive paths monotonically
increase/decrease at each iteration, and the number of iterations is
finite because (1) (1) a upper/lower bound condition on the cost argument, or (2) an aggregate bound imposed by aggregate
selections rewrites.

For example, consider the all-pairs-all-paths query in
Section~\ref{sec:routing}, the actor {\em pathMsg} is a recurring term
in A3 and A5. However, each recursive iteration computes a new {\em
  PathMsg} of increasing cost, and the bound check (with aggregate
selections) is that pathMsg
should never exceed the current known bestPath for each source and
destination pair.

TODO: Extend KRS proof for aggregate selections to perform that.

\subsubsection{Sigcomm Datalog to New Overlog Rewrite}

The original Datalog routing specifications are arguably more
``declarative'' for expressing routing protocols, compared to active
rule specifications which are more ``operational''. On top of that,
figuring out how we can map the original Datalog specifications to Overlog allows
us to reuse the techniques of existing Datalog optimizations, safety
checks and negation semantics.

There are two mappings we have to do. First, from centralized Datalog to the
distributed version of Datalog where derived facts can be shipped from
one node to another. Second, from distributed Datalog to Overlog. 

Given location of base facts and derived facts, the translation of centralized Datalog to
distributed version is straightforward. One possible optimization is to
automatically determine the ``optimal'' placement of the derived facts
that lead to minimum communication. 

The translation rules for the second mapping has two steps. First, we
localize all rule bodies, to break up distributed joins into multiple
overlog rules. 

\begin{enumerate}
\item {\bf Localize rule bodies}. We assume a default left to right join
  ordering. Starting from the first term, we identify the unifying argument in the next term, and ship either
  term so the unification can be done at one location for each join
  key. The results of the join is then shipped to the location of the
  next term, etc. For each term that is sent, generate the send rule 
  (e.g. A1), and the rule that stores the sent value (e.g. A3).

\item {\bf Create view rules}. For rules whose body and head are
  co-located, classify them as view rules.  

\item {\bf Generate active messenging rules.} Generate a
  send$<$t\_msg,D$>$ action to send t to D, and introduce another rule
  add$<$t$>$ :- recv$<$t\_msg$>$ if t is materialized. 

\item{\bf Generate periodic rules}. If periodic exists in rule body, use
  that as the triggering event of rule.

\item{\bf Generate update event rules}. For all remaining active rules with no
  periodic triggers, replace all
  active rule term bodies that contain t with update$<$t$>$. We further break up each rule
  such that each rule has only one update event term.


\end{enumerate}


\subsection{Query Rewrites}

Aggregate selections rewrite:\\
{\bf A6:} \code{send$<$pathMsg(S,D,P,C),S$>$} :- inLink(S,Z,C$_{1}$), \code{update$<$bestPath(Z,D,P$_{2}$,C$_{2}$)$>$}, \\
\datalogspace C = C$_{1}$ + C$_{2}$, P = $f\_concatPath$(link(S,Z,C$_{1}$),P$_{2}$).

\noindent Magic Sets with Left-linear rewrite:

The following query is rewritten. magicSources and magicDsts is tagged
along with query. link and bestPath are stored at source node S, path and
pathDst are stored at destination node D.\\

\noindent{\bf BPP1: } path(S,D,P,C) :- magicSources(S), link(S,D,C), \\
\datalogspace  P = $f\_concatPath$(link(S,D,C), nil). \\
{\bf BPP2: } path(S,D,P,C) :- path(S,Z,P$_{1}$,C$_{1}$), link(Z,D,C$_{2}$),\\  
\datalogspace C = C$_{1}$ + C$_{2}$, \\
\datalogspace P = $f\_concatPath$(P$_{1}$, link(Z,D,C$_{2}$)). \\
{\bf BPP3: } pathDst(S,D,P,C) :- magicDsts(D), path(S,D,P,C). \\
{\bf BPP4: } bestPath(S,D,P,C) :- min(C,(S,D), pathDst(S,D,P,C)). \\
{\bf Query: } bestPath(S,D,P,C)\\

\noindent{\bf Action rules:}\\
{\bf A1:} \code{send$<$pathMsg(S,D,P,C),D$>$} :- magicSources(S),
\code{update$<$link(S,D,C)$>$}, \\
\datalogspace P = $f\_concatPath$(link(S,D,C), nil). \\
{\bf A2:} \code{add$<$path(S,D,P,C)$>$} :- \code{recv$<$pathMsg(S,D,P,C)>$>$}.\\
{\bf A3:} \code{send$<$pathMsg(S,D,P,C),D$>$} :-
\code{update$<$path(S,Z,P$_{1}$,C$_{1}$)$>$}, link(Z,D,C$_{2}$), \\
\datalogspace C = C$_{1}$ + C$_{2}$, P = $f\_concatPath$(P$_{1}$,
link(Z,D,C$_{1}$).\\
{\bf A4:} \code{send$<$pathMsg(S,D,P,C),D$>$} :- path(S,Z,P${1}$,C$_{1}$), \code{update$<$link(Z,D,C$_{2}$)$>$}, \\
\datalogspace C = C$_{1}$ + C$_{2}$, P = $f\_concatPath$(P$_{1}$, link(Z,D,C$_{1}$).\\
{\bf A5:} \code{send$<$bestPathMsg(S,D,P,C),S$>$} :-
update$<$bestPathCost(S,D,C)$>$, path(S,D,P,C). \\ 
{\bf A6:} \code{add$<$bestPath(S,D,P,C)$>$} :- \code{recv$<$bestPathMsg(S,D,P,C)$>$}. \\ 

\noindent{\bf View rules:}\\
{\bf V1: } pathDst(S,D,P,C) :- magicDsts(D), path(S,D,P,C). \\
{\bf V2: } bestPath(S,D,P,C) :- min(C,(S,D), pathDst(S,D,P,C)). \\
{\bf Query:} bestPath(S,D,P,C).\\


\subsubsection{Long-running queries}

In practice, if we want to run the routing queries over a prolonged
period, we need to have periodic timers that will propagate any best
paths that has changed since the last update. For example, 

\noindent{\bf R1: } path@S(S,D,P,C) :- link@S(S,D,C), P = $f\_concatPath$(link(S,D,C), nil). \\
{\bf R2: } pendingBestPath@Z(S,D,P,C) :- link@S(S,Z,C$_{1}$), bestPath@Z(Z,D,P$_{2}$,C$_{2}$), C = C$_{1}$ + C$_{2}$,\\
\datalogspace P = $f\_concatPath$(link(S,Z,C$_{1}$),P$_{2}$).\\
{\bf R3: } path@S(S,D,P,C) :- periodic(10), pendingBestPath@S(S,D,P,C).\\
{\bf R4: } bestPath@S(S,D,P,C) :- min(C,(S,D),path@S(S,D,P,C)). \\
{\bf Query: } bestPath(S,D,P,C).\\

A possible rewrite into the proposed new Overlog is as follows:

\noindent{\bf Action rules:}\\
\noindent{\bf A1:} send$<$linkMsg(S,D,C),D$>$ :- \code{update$<$link(S,D,C)$>$}.\\
{{\bf A2:} \code{add$<$inLink(S,D,C)$>$} :- \code{recv$<$linkMsg(S,D,C)$>$}.\\
{\bf A3:} \code{add$<$path(S,D,P,C)$>$} :- \code{recv$<$pathMsg(S,D,P,C)$>$}.\\
{\bf A3:} \code{send$<$pathMsg(S,D,P,C),S$>$} :- periodic(10), pendingBestPath(S,D,P,C).\\

\noindent{\bf View rules:}\\
{\bf V1:} pendingBestPath(S,D,P,C) :- inLink(S,Z,C$_{1}$), bestPath(Z,D,P$_{2}$,C$_{2}$), \\
\datalogspace C = C$_{1}$ + C$_{2}$, P =
$f\_concatPath$(link(S,Z,C$_{1}$),P$_{2}$).\\
{\bf V2:} bestPath(S,D,P,C) :- min(C,(S,D),path(S,D,P,C)). \\
\bf V3:} path(S,D,P,C) :- link(S,D,C), P = $f\_concatPath$(link(S,D,C), nil). \\
{\bf Query: } bestPath(S,D,P,C).\\

{\em pendingBestPath} is set to expire after interval is over.


\subsection{Chord Examples}

The old Lookup rules:

\noindent{\bf L1:} lookupResults@R(R,K,S,SI,E) :- node@NI(NI,N), lookup@NI(NI,K,R,E), \\
\datalogspace bestSucc@NI(NI,S,SI), K in (N,S].\\
{\bf L2:} bestLookupDist(NI,K,R,E,min$<$D$>$) :- node@NI(NI,N), lookup@NI(NI,K,R,E), \\
\datalogspace finger@NI(NI,I,B,BI), D:=K - B - 1, B in (N,K).\\
{\bf L3:} lookup@BI(min$<$BI$>$,K,R,E) :- node@NI(NI,N), bestLookupDist@NI(NI,K,R,E,D), \\
\datalogspace finger@NI(NI,I,B,BI), D = K - B - 1,  B in (N,K).\\

\noindent The new Chord rules:

\noindent{\bf L1:} \code{send$<$lookupResults(R,K,S,SI,E), R$>$} :- node(NI,N), \code{recv$<$lookup(NI,K,R,E)$>$}, \\
\datalogspace bestSucc(NI,S,SI), K in (N,S].\\
{\bf L2:} \code{send$<$bestLookupDist(NI,K,R,E,min$<$D$>$), NI$>$} :- node(NI,N), \code{recv$<$lookup(NI,K,R,E)$>$}, \\
\datalogspace finger(NI,I,B,BI), D:=K - B - 1, B in (N,K).\\
{\bf L3:} \code{send$<$lookup(min$<$BI$>$,K,R,E),BI$>$} :- node(NI,N), \code{recv$<$bestLookupDist(NI,K,R,E,D)$>$}, \\
\datalogspace finger(NI,I,B,BI), D = K - B - 1,  B in (N,K).

The actor terms are {\em lookup}, {\em bestLookupDist} and {\em
  lookupResults}. The view terms are {\em bestSucc}. The table terms are
  {\em node} and {\em finger}. Apart from the rules that compute the best successor, all the Chord
rules are active (i.e. triggered by some events).



\subsection{Negation}

The following Datalog query appeared in the SIGCOMM paper, has negation
and appears to be unstratifiable because the predicate dependency graph
has cycles containing negation. Specifically ({\em path}
depends (+/-) on {\em bestPath} (rules R2 and R3), and {\em bestPath}
depends (+gb) on {\em path}) (R4).

\noindent{\bf R1:} path(S,D,P,C) :- magicSources(S),
link(S,D,C), P = $f\_concatPath$(link(\underline{S},D,C), nil). \\
{\bf R2:} path(S,D,P,C) :- magicDst(D$_{3}$), path(S,Z,P$_{1}$,C$_{1}$), link(Z,D,C$_{2}$),\\
\datalogspace $\neg$bestPath(Z,D$_{3}$,P$_{3}$,C$_{3}$), C =
$f\_compute$(C$_{1}$,C$_{2}$), \\
\datalogspace P = $f\_concatPath$(P$_{1}$, link(\underline{Z},D,C$_{2}$)).\\ 
{\bf R3:} path(S,D,P,C) :- magicDst(D),
path(S,Z,P$_{1}$,C$_{1}$),bestPath(Z,D,P$_{2}$,C$_{2}$), \\
\datalogspace C = C$_{1}$ + C$_{2}$, P = $f\_concatPath$(P$_{1}$,P$_{2}$). \\
{\bf R4: } bestPathCost(S,D, min$<$C$>$) :- magicDsts(D),path(S,D,P,C). \\
{\bf R5: } bestPath(S,D,P,C) :-
bestPathCost(S,D,C), path(S,D,P,C). \\
{\bf Query: } bestPath(S,D,P,C)\\


A proof as follows:

For any source {\em a} and destination {\em b} pair, from rule R2 and R3, path(a,b,p,c)
depends (+/-) on bestPath(z,b,p$_{1}$,c$_{1}$) if {\em z} is a node along the
path p. The following monotonicity constraints also hold: c $\ge$ c$_{1}$ due to the
monotonic property of addition, and p $\ge$ p$_{1}$ due to {\em
  f\_concatPath}. 

The query is not stratifiable if bestPath(z,b,p$_{1}$,c$_{1}$) depends on
path(a,b,p,c). Let's assume that this dependency holds. In this case,
based on the derivation tree for bestPath(z,b,p$_{1}$,c$_{1}$),
bestPath(z,b,p$_{1}$,c$_{1}$) is derived from path(z,b,p$_{1}$,c$_{1}$)
(rule R5 and R5),
and path(z,b,p$_{1}$,c$_{1}$) is derived from path(a,b,p,c) (rule R3). However, 
this generates the conditions that {\em a} is in p$_{1}$, c$_{1} \ge $ c
and p$_{1} \ge$ p, all of which contradicts the earlier conditions or
lead to path cycles. Hence,
bestPath(z,b,p$_{1}$,c$_{1}$) cannot depend on path(a,b,p,c). 

A more general proof demonstrates that the query is {\em locally
stratifiable\footnote{While the program may not be
stratified, in that there is a cycle through negation in the
predicate-level program graph, no proof tree or derivation contains a
cycle through negation (i.e., acyclic at the instance level).}} in instances whenever paths are monotonically increasing
(or decreasing) as new links are added, and acyclic (due to positive
only links and a min aggregate). Hence, each path
can depend negatively on its subpaths but not negatively
in terms of itself. Similarly, each best path is acyclic and depends only on its subpaths.

%To illustrate with a specific example, consider a ring network
%a $<$-$>$ b $<$-$>$ c $<$-$>$ d $<$-$>$ a, where all links are of cost 1. From
%rule R2 and R3, path(a,b,[a,b,c,d],3) depends (+/-) on
%bestPath(b,d,[b,c,d],2). However, bestPath(b,d,[b,c,d],2) does not depend on path(a,d,[a,b,c,d],3)
%since there exist a subpath path(b,d,[b,c,d],2) that has a lower cost. 




%Two things we have to prove: (1) Will the above query converge? (2) If
%the query converges, is there a correct answer be produced (best path for
%required src/dst pair?)

%{\bf Proof sketch \#1:}
%We first remove the negated term $\neg$bestPath in R2. This ``breaks'' the
%cycle caused by negation. If we show that this query terminates after
%removal of this term, then adding the $\neg$bestPath term back also
%converges since R2 would be further restricted. To prove (2), we have to show
%that removing the $\neg$bestPath term produces the same answer as adding
%the term, only the latter avoids some redundant work. Consider a path
%P that computes the shortest paths from node {\em a} to {\em b} via node
%{\em c}. P can be generated either by aggregating all the individual
%links along the path from node {\em a} to {\em b} (using rule R2 with
%the negated term removed), or by combining two
%subpaths (from {\em a} to {\em c}, and from {\em c} to {\em b}) at node
%{\em c}. Removing the negated term in R2, we are computing the subpath {\em
%  c} to {\em b} redundantly twice. 



\end{document}

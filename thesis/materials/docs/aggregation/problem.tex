\documentclass{article}

\title{Secure Distributed Counting}
\author{Aydan R. Yumerefendi}

\begin{document}

\maketitle

\section{Problem Definition and Requirements} 
A large population of distributed computers maintains collections of interesting
information. We will refer to them as data sources. Periodically, an
interested party would like to know the total number of records
from all data sources that satisfy a given condition. 

There are two main requirements for a successful solution of the
problem. First, any solution should be able to address large
populations of data source nodes in an efficient and scalable way that
does not create hot spots or single sources of attack and
vulnerability. Second, the final result should be
provably correct---only a bounded fraction of counts reported by data
source nodes can be omitted. Performing some additional work should be
able to limit the size of the fraction to any desired constant.

\section{Possible Solutions}

\subsection{Centralized Approach}
In this approach the interested party disseminates the request to all
data sources. The data sources inspect their records, calculate the
desired amount, and send it back in a network message. To obtain the
final result of its query, the interested party processes every single
message incrementing a counter with the amounts reported in each
message. The final count is indeed the sum of all reported values and
as such satisfies our second requirement. The centralized approach
used in this solution, though, does not satisfy the first
requirement---as the number of data sources increases, the
performance of this method will degrade significantly.

\subsection{Distributed Solution}
To solve the counting problem in the case when the number of data
source nodes is significant, it is necessary to bound the messages
received by a single node as well as the amount of computation that it
performs. Using this approach, we introduce the notion of an
\emph{aggregator} --- a computer that receives information from a
bounded number of data sources or other aggregators and calculates the
sum of all data locally. An aggregator node forwards the result of
its computation to other aggregator nodes in a single network
message. Using this approach, there is a single top level aggregator
whose output is the final count of all data.

This solution satisfies our first requirement---it can scale to large
data source populations. Unlike the previous solution, the interested
party performs no direct summation of all received data. As a result,
trusting the final count calculated using this technique is
problematic: during the course of execution, any aggregator node can
misreport the correct value and consequently the total count can be
significantly flawed.

\subsection{Problems with the Distributed Solution}
\begin{itemize}
\item [P1] need some means to identify each data source/aggregator
\item [P2] need to associate data/aggregations with their originator
\item [P3] how to construct the aggregation tree
\item [P4] need to ensure that all data reported to the aggregator is included
in its computation
\item [P5] need to ensure that there is no data that was not reported to the
aggregator but is included in the computation
\item [P6] need to make sure that the result of the aggregator is the correct
sum of all reported data.
\end{itemize}

\section{Assumptions}
First of all we assume that there exists a publicly available
community Distributed Hash Table. This community DHT is managed by a
single authority, that ensures its correct and trustworthy
execution. The DHT provides API to store and retrieve data given a key,
as well as to route a specific kind of message to a DHT node that
corresponds to a given key. The basic assumption is that these
primitives are correct and can be trusted.

All data source and aggregator nodes make use of the DHT as a
service. 

There exists some PKI so that it is possible to obtain the certificate
corresponding to a given entity.

\section{Addressing the Problems}

\subsection{The Easy Ones}
Our assumption that all query processing is implemented on top of a
DHT provides a natural solution to P1. To identify a given data source
or aggregator, we use its identifier in the overlay built to serve the
DHT. We will refer to this identifier as \emph{node id}.

To associate data with its originator we need to sign digitally each
network message. We can do this using asymmetric signatures, in which
case we require the existence of PKI. The other option is to use MAC
based signature schemes and introduce asymmetry by the use of loose time
synchronization and forward key chains as in the TESLA protocol. As of
now we will assume that we can undeniably associate a message with its
originator and the exact nature of this mechanism is not important.

\subsection{The Hard Ones}

\subsubsection{Generating the Tree}
\begin{itemize}
\item Needs to be randomized -- given the current structure, an
  attacker should not be able to determine the next tree
  structure. Also an attacker should not be able to modify the tree
  structure to serve its own needs.
\item A query request should propagate to all data source nodes.

\item Given a tree node in the current structure of the tree it should
  be possible to find deterministically each of its descendants and
  predecessors in the tree.

\item Have to decide whether data source nodes are located only at the
  leaves of the tree, or they can be also internal nodes. The general
  preference is to have the data source nodes also in the internal
  nodes and consider their reading as an additional child.
\end{itemize}

We have discussed two somewhat different approaches to build an m-way
tree of depth at most d. 

In the first approach, the node issuing the
query partitions the key space into m equal portions, chooses a random
key in each of the portions and sends a message to the nodes
corresponding to the given key. Once a node receives a query message,
it further splits its range, chooses a random key in each range, and
sends a message to it. When the required depth has been reached or the
same node is selected both as a parent and a child in the tree (?),
the current node stops propagating the query and becomes a leaf in the
tree. Using this technique it is possible to choose random descendants
of a given tree node. We have also discussed using some rotation at
each level so that we make it harder for an adversary to determine
the tree structure.

The other approach is based on choosing a random seed and labeling
each tree node with an m-base number that corresponds to its location
in the tree. To calculate the physical node that maps to a given tree
node, we compute the
$hash(seed||depth||position)$ and we route a message to the node
closest in id space to this value. Using this technique it is possible to 
find out the data source node that corresponds to a given tree
position, given the random seed. Even with this approach it is still
possible to have the same physical node mapped on different tree
levels although it corresponds to different keys.


Either of these approaches needs some additional mechanism to ensure
that all existing tree nodes have been included in the tree. As of now
the termination condition is the same node being selected twice in a
row. It is not clear whether this will work.

\subsubsection{Ensuring All Data are Present}
This mechanism addresses P4 and P5. The idea is to ensure that at most
some small fraction of data is maliciously omitted or is \emph{incorrect}. We
define incorrect data as data whose signature is invalid or data that
is included at the wrong place in the aggregation hierarchy
(e.g. included multiple times). 

The general approach to ensure the above requirements, is to require
aggregator nodes to commit to the data that they receive and
aggregate. A popular commitment scheme makes use of hash trees. For
our purposes a hash tree is a binary search tree with data stored at
its leaves and sorted with respect to a given key. Each tree node
stores also an \emph{authenticator}. The authenticator of a leaf node
is $hash(key||data)$, while the authenticator of an internal node is
$hash(auth_{left}||key||auth_{right})$. Using this scheme, the
authenticator of the root of the hash tree is a commitment record for
any of the data items present at the leaves of the tree. Using the
hash tree one can construct a \emph{membership proof} showing the
presence or absence of a data item with a given value and key in the
leaves of the tree. A membership proof consists of the authenticators
of the siblings of all nodes on the path from the root to the leaf
where the given key is expected to reside. To verify a membership
proof, one starts from the leaves of the tree computing the missing
authenticators in a recursive way. A successful proof computes the
same root authenticator as the one computed when creating the tree.


Using a hash tree commitment scheme, we can ensure that an aggregator
node cannot change at a later time its statement about the data it has
received from its children. For this scheme to work it is important
that once the aggregator computes the root authenticator of the tree,
it publishes the authenticator to an external medium, so that it
cannot equivocate about the value of the root authenticator.

Each aggregator node commits to the data that it has received and used
using the hash tree commitment scheme described above. Since we have a
hierarchy of aggregators, each lower-lever aggregator sends its root
authenticator as data to its parent. As a result higher-level
aggregators include the root authenticators of their children that are
also aggregators. Using this scheme we embed in each internal node of
the aggregation tree a secondary structure---a hash tree that includes
the output of all the node's children in the aggregation tree. Following this
process recursively, the root of the hash tree embedded at the root of
the aggregation tree contains an authenticator that commits the
aggregation of all data. We will refer to this authenticator as the
\emph{final} authenticator.

We assume that the final authenticator is published to some external
publication medium or sent directly to the entity issuing the
query. Using this commitment scheme we can ensure that:

\begin{itemize}
\item [G1] the aggregation commits to at least $(1-\epsilon)$ fraction of
  all existing data with probability $(1-\delta)$.
\item [G2] for at least $(1-\epsilon)$ aggregators, at most $\epsilon$
  fraction of their children are incorrect with probability
  $(1-\delta)$. \\
The above statement is a bit confusing. What we acutally need is:\\
With probability at least $(1-\delta)$ at most $\epsilon$ fraction of
  the commited data is invalid.

 
\end{itemize}

Where $\epsilon$ and $\delta$ are constants in $(0,1)$. 

We can ensure G1 using two different approaches.

{\bf Query Initiator Driven}\\
As soon as the query initiator receives the final
authenticator, it initiates a verification procedure. The verification
procedure consists of the following steps.

\begin{enumerate}
\item Choose a random data source node\\
This can be done by choosing a random node in the key space and using
the overlay to route a message to the closest data source node (note
that it can also be an aggregator). The node has information about its
position in the tree that we can use to reconstruct the aggregation
path from it to the root of the aggregation tree. Let $v$ be the
chosen data source node. 

\item $v$ sends the data that it contributed to the query
  initiator. If $v$ is also an aggregator node it sends also a
  membership proof that these data were included in its hash tree. $v$
  also contacts its parent and requests a membership proof for its own
  authenticator to be sent to the query initiator.

\item When an aggregator node receives a membership proof request for
  a data item with a given key, it returns the proof and forwards the
  request to its parent.

\item When all membership proofs reach the query initiator it first
  verifies that the nodes sending the proofs have the correct location
  in the aggregation hierarchy. Having done this, it verifies each
  individual membership proof. The failure of any of the verifications
  prompts the node to raise an alarm. The commitment scheme makes it
  possible to identify the fraudulent node and we assume that some
  mechanism exists to trigger a corrective action. 

\item To achieve the bounds mentioned above, we need to perform the
  above operations $\frac{1}{\epsilon}\ln{\frac{1}{\delta}}$ times. 
\end{enumerate}

{\bf NOTE:} Initially i thought that each data source node needs to
publish its data in the DHT, so that the mechanism can avoid
situations in which data source nodes attempt to frame their
aggregators. However, this is not necessary because:

\begin{itemize}
\item each aggregator retains a record of the data that it has
  received
\item each data item carries the signature of its creator

\item as of now we assume that nodes do not fail during the execution
  of a query. This means that the set of nodes reachable at the time the
  query was disseminated and the set of nodes reachable at the time of
  verification are the same.
\end{itemize} 

The first two observations assure that a data source cannot claim it
sent a different value---given such a claim, its aggregator can always
show the digitally signed data that it has received earlier. The last
assumption rules out the possibility of a node claiming that
it sent some data when it actually did not send it.


{\bf Data Source Node Driven}\\
The difference of this approach is that verification is triggered not
by the entity that initiated the query but by the data sources. Each
data source randomly decides whether to verify that its data were
correctly aggregated. We can adjust the probabilities so that
$\frac{1}{\epsilon}\ln{\frac{1}{\delta}}$ nodes decide to perform
validation, and as a result can achieve the same correctness bounds.

While performing this kind of verification, it is important to decide
the aggregator node with respect to which we are verifying. There are
some interesting consequences depending on the choice:

\begin{itemize}
\item Verify with the root of the aggregation tree - using this
  approach, a data source node requests membership proof from its
  parent aggregator, which in turn requests a membership proof from
  its parent, and so on until the root of the aggregation tree. Proof
  verification is similar the Query Initiator Approach.
\item We can save some work by verifying only with the parent
  aggregator. While efficient, this approach has some problems. First,
  we need to ensure that the parent aggregator cannot equivocate about
  its root authenticator--in general it is possible to report one
  authenticator to the hierarchy that is above the aggregator, and
  another one to the hierarchy that is below. To avoid this problem we
  can require that each aggregator node publish its root authenticator
  in the DHT under a key that can easily be derived from the id of the
  query and the node id of the authenticator, e.g. $hash(query
  id||node id)$. Second, it is possible to come up with situations in
  which both a child and its parent in the aggregation hierarchy are
  compromised. Limiting verification to only child-parent, makes it
  possible for a compromised parent to report an arbitrary authenticator for the
  subtree rooted at its compromised child. This observation shows that
  defense against parent-child compromise requires deeper verification

\item A middle ground between both approaches involves \emph{hybrid}
  verification. When a node decides to verify, it decides randomly how
  high in the hierarchy it should go. Each node on the path from the
  node to the root of the aggregation tree has equal probability of
  being selected for verification. The benefit of this mechanism is
  still unclear. Need to do some math to get a rough estimate.

\item A general problem with the data source driven approach is to
  ensure that the verifications will indeed take place. Verifications
  performed by compromised nodes are useless, and as a result we might
  require a higher number of nodes to perform verification to ensure
  the same error bounds.
\end{itemize}


Using either query initiator or data source driven approach, we can
ensure G1. To ensure G2, we need to inspect the hash tree in an
aggregator node: choose a random leaf in the hash tree, and make sure
that it is correct. A node is correct if: (1) the signature on its
data is valid, (2) the node that supplied the data is indeed a child
of the aggregator in the aggregation tree. 

Verification of an aggregator node can take place from any node
in the hierarchy or ultimately the query initiator. However, if
we restrict the verification to only parent-child (child-parent), we are again
vulnerable to parent-child being simultaneously
compromised. Therefore, to protect against this problem, it is
necessary to choose random aggregator nodes. 

Once we have chosen an aggregator node, we select
$\frac{1}{\epsilon}\ln{\frac{1}{\delta}}$ random leaves in its
aggregation tree. For each leaf, we receive a membership proof. To
verify that a leaf is correct, we inspect the signature of its data,
the location of the corresponding data source in the aggregation tree,
and the membership proof. If any of these fails, we raise an alarm.

Using the above scheme, it is possible for a node to equivocate about
its root authenticator. We can avoid this by requiring a membership
proof for the root authenticator from any aggregator node on the path
to the root of the aggregation tree. The other alternative is to have
each aggregator publish its root authenticator in the DHT.


Nodes in the aggregation tree (data sources and aggregators) and/or
the query initiator can perform the above procedure. With the
former approach, we have the same problem of ensuring that
verification indeed takes place. With the latter, the query initiator
will have to do all the work.


{\bf Summary}
We use a hierarchical commitment: aggregator nodes receive data, form
a hash tree and obtain root authenticator. Each aggregator node pushes
its authenticator to its parent aggregator either via direct network
message or via publishing it in the DHT. Eventually, the root of the
aggregation tree reports its root authenticator.

To ensure the correctness of the commitment scheme, we perform
verification. Two main aspects need to be verified: (1) no more than
$\epsilon$ fraction of all data is omitted and (2) at at least
$(1-\epsilon)$ aggregator nodes there are at most $\epsilon$
invalid committed data items. Either data source/aggregator nodes or
the query initiator node can perform the verification.

To ensure the first condition we choose a random data source node and
inspect the membership proofs for its data item all the way up to the
root. To ensure the second requirement, we choose a random aggregator
node and pick a number of random leaves in its commitment tree.

It is possible to speed up the first type verification by limiting how
high in the tree we go. Nevertheless, we should not limit verification
to only child-parent pairs.

Data source driven verification might require more work to ensure the
same correctness guarantees.


\subsubsection{Ensuring Summation is Correct}
To ensure that the summation is correct, we augment the hash tree
described earlier. Internal nodes of the hash tree contain two
additional fields: $sum_{left}$ - the sum of all data in the left
sub-tree and $sum_{right}$ - the sum of all data in the right
sub-tree. We extend label computation to include these two nodes.

Membership proof for an element x, returns also the sibling of this
element on the leaf level of the hash tree. To verify the proof, we
make sure that the 
parent of x has the correct values of $sum_{left}$ and $sum_{right}$
and that the summation as we move higher in the hierarchy is correct:
if we follow a left path from a child $c$ to a parent $p$,
$sum_{left}^p$ should equal $sum_{left}^c + sum_{right}^c$. Similarly
for the right path.

Using this scheme, we can ensure that the contribution of a single
leaf node propagates up to the root of the hash tree. Choosing
$\frac{1}{\epsilon}\ln{\frac{1}{\delta}}$ data source nodes, we can
ensure that the contribution of at least $(1-\epsilon)$ nodes has been
included in the final count with probability at least $(1-\delta)$.

During aggregation it is possible to include data from a single node
more than once and inflate the final count. We can protect against
this mechanism if we require that a membership proof for an element $x$
also retrieves its sibling $y$. Since an aggregator can
increment the count only if it includes an element in the hash tree,
by inspecting the sibling we can minimize the probability of
multiple inclusion or inclusion of data with wrong signature. Using
this scheme we ensure that no more than $\epsilon$ fraction of the
committed nodes are invalid.


Overall, we can ensure that:
\begin{enumerate}
\item  With probability at least $(1-\delta)$, no more than $\epsilon$ fraction of all
original data is omitted.
\item With probability at least $(1-\delta)$, no more than $\epsilon$
  fraction of the total committed data is invalid
\end{enumerate}

It is possible to improve on the second result to $\epsilon$ fraction
of the initial data.  Since we are running
on a community DHT, we can assume that at any moment of time we have a
relatively correct estimate of the number of the existing data source
nodes. Given this, we can further augment the hash tree with two more
fields to keep track of the number of nodes in each each subtree. This
mechanism, together with the earlier verification steps can prevent
aggregator nodes from inflating the committed data set and as a result
the final count.


Even with the above guarantees, the final result can be significantly
different from the correct count. The problem with counts is that it
is very easy to affect the end result by simply compromising a single
summand. If there is no bound on the contribution of a single data
source node, then even a solution that can ensure close to perfect
aggregation, can give an arbitrarily incorrect result. A bound is also
a precaution in situations in which data source nodes are compromised
and misreport their initial data.





\end{document}
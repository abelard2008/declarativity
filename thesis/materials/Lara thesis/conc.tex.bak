\part[Conclusion and Future Extensions]{Conclusion and Future
Extensions}\label{last}
%\chapter[Concluding Remarks]{Concluding Remarks}

This dissertation dealt with two interesting problems in modern
coding theory that arise when conventional assumptions on
communication no longer hold. First, we addressed the issue of
inadequate synchronization from a coding theoretic-perspective. We
derived several novel structural properties of Reed-Muller codes
which were subsequently used for an in-depth study of these codes in
channels which in addition to substitution errors permit a bit
repetition or a bit deletion. We presented explicit number-theoretic
constructions for communication in the presence of repetition
errors. Our constructions are asymptotically optimal for the case of
one repetition, and are within a constant factor of the upper bound
on the cardinality for the case of multiple repetitions. They
improve on the previously best known results.

We also discussed  a general prefixing method for improving the
repetition error correcting capability of a given (additive) error
correcting code.  The proposed method leverages number-theoretic
constructions and constructs a carefully chosen prefix whose length
is only logarithmic in the codeword length, while providing a
guarantee on the immunity to repetition errors. A possible future
extension would be to implement the proposed methods as a component
of  a real communication system. Another interesting extension would
be to combine the proposed prefixing method with a suitable decoding
algorithm, of the kind presented here.

In the second part, we discussed the LDPC code performance in the
low BER regime under iterative decoding. We introduced the concept
of (fully) absorbing sets. Fully absorbing sets are combinatorial
objects in the Tanner graph of the code, that are stable under the
bit flipping algorithm. As a concrete case study, we systematically
described minimal (fully) absorbing sets of high rate array-based
LDPC codes. These were shown to entirely dominate the low BER
performance over the AWGN channel under practical iterative decoding
algorithms. This observation is in contrast to the minimum distance
codewords which play the central role in describing the performance
of a code under the optimal yet computationally expensive maximum
likelihood decoding algorithm. Insights from the study of absorbing
sets have already been used for improved decoder implementations
\cite{ICCquant}, and for the error-floor prediction based on fast
stochastic simulation, \cite{itw:07}.

As a future direction, it would be interesting to establish an
explicit link between absorbing sets, which play an important role
in describing the performance of message passing algorithms over
AWGN channels, and pseudo-codewords, which are useful in
understanding linear programming-based decoding. It would also be
useful to generalize the analysis presented here to other LDPC code
families, and to derive asymptotic properties of code ensembles from
the point of view of absorbing sets.

 \comment{
\section{Concluding Remarks}\label{section6}

In this paper we studied the performance of a Reed-Muller
RM($1$,$m$) code, as an instance of a substitution-error
correcting code, over channels in which, in addition to
substitution errors, a sampling error can cause synchronization
errors. Specifically, we studied the cases where the
synchronization error results in the deletion of a single bit and
where it results in the repetition of a single bit. The model we
worked with is aimed at handling the kinds of errors that can
occur in a variety of applications, such as magnetic recording and
wireless transmission, in the absence of adequate timing recovery.
Our approach to handling synchronization errors is to start with a
good substitution-error correcting code, to analyze which codeword
pairs cause the identification problem, and then find a linear
subcode of as high a rate as possible that would both provide
protection against substitution errors and be robust to the
synchronization errors. The rate loss incurred from using the
subcode and the increase in the complexity of the decoding
algorithm should of course be reasonably small for such an
approach to work.

Another contribution of this paper is to develop several
structural properties of the RM($1$,$m$) codes, which where
motivated by this point of view. These structural properties may
be of interest in their own right.

In general, we provided an analysis that is combinatorially much
tighter than might be needed for our immediate concerns. These
combinatorial results may also be of independent interest.
Specifically, we  enumerated all pairs of codewords of the
RM($1$,$m$) codes that suffer from an identification problem over
a channel allowing for the deletion of a single bit. We introduced
a pruned linear subcode of the RM($1$,$m$) code, with the loss of
one information bit, which does not suffer from the identification
problem under the deletion of a single bit. Given a pair of
codewords in the pruned code the appropriate notion of distance
between them over a channel permitting synchronization errors is
the minimum Hamming distance between any pair of strings which are
derived respectively from each codeword after the application of
such synchronization error. We gave a combinatorially tight
analysis of the the minimum distance of the pruned code for this
notion of distance for both the case of the deletion of a single
bit and the case of the repetition of a single bit. Specifically,
we explicitly identified all pairs of codewords of the pruned code
for which the post-synchronization error Hamming distance equals
the corresponding post-synchronization minimum distance of the
pruned code.

Finally, we provided a bounded distance decoding algorithm,
suitable for the use of the pruned code over a channel where in
addition to possibly one deletion error (respectively one
repetition error), substitution errors can occur as well. The
complexity of this algorithm is of the same order as that of the
usual fast Hadamard transform based decoding for the RM($1$,$m$)
code. What is more, the proposed algorithm can in fact be
essentially run on the same hardware platform as in the case
without synchronization errors.

There are of course many codes that are superior to RM($1$,$m$)
codes in several respects (for instance, having higher rates).
Future work would involve studying the behavior under our
synchronization error model of other families of codes with good
substitution-error correcting properties. The analysis should also
be broadened to include more general models in which several
repetitions and deletions are simultaneously allowed. As in this
paper, the aim of such an analysis would be to find pruned
versions of such codes, with low rate loss and only moderate
increase in decoding complexity, which would not only have good
substitution error-correcting capabilities but would also provide
protection against the sampling errors of interest. Additional
work-in-progress of ours along these lines has been reported in
%\cite{TechnicalReportBasedOnISITSubmission}.
\cite{daArrayTech:06}. }

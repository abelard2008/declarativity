\section{Experience and Lessons}
\label{sec:lessons}

Our overall experience with \BOOMA\ has been quite positive. Building the system
required only nine months of part-time work by four developers, including the
time required to go well beyond the feature set of HDFS\@. Clearly, our
experience is not universal: system infrastructure is only one class of
distributed software, and analytics for ``Big Data'' is even more
specialized. However, we feel that our experience sheds light on common patterns
that occur in many distributed systems, including the coordination of multiple
nodes toward common goals, replicated state for high-availability, state
partitioning for scalability, and monitoring and invariant checking to improve
manageability.

Anecdotally, we feel that much of our productivity came from using a data-centric
design philosophy, which exposed the simplicity of tasks we undertook.  When you
examine the tables we defined to implement HDFS and MapReduce, it seems natural
that the system implementation on top should be fairly simple, regardless of the
language used. Overlog imposed this data-centric discipline throughout the
development process: no private state was registered ``on the side'' to achieve
specific tasks.  Beyond this discipline, we also benefited from a few key
features of a declarative language, including built-in queries with support for
recursion, flexible view materialization and maintenance, and high-level
metaprogramming opportunities afforded by Overlog and implemented in \JOL.

\subsection{Everything Is Data}
In \BOOMA, \emph{everything} is data, represented as objects in collections.
This includes traditional persistent information like file system metadata,
runtime state like \TT status, summary statistics like those used by the \JT's
scheduling policy, in-flight messages, system events, execution state of the
system, and even parsed code.

%On reflection, there seem to be two key aspects to this data-centric approach: the {\em reification} (conceptual promotion) of system details into data, and the {\em uniformity of representation}.  Together, these resulted in ubiquitous, clean interfaces that were easy to identify and exploit.  
The benefits of this approach are perhaps best illustrated by the simplicity with which we scaled out the \NN\ via partitioning (Section~\ref{sec:scale}): by having the relevant state stored as data, we were able to use standard data partitioning to achieve what would ordinarily be a significant rearchitecting of the system. Similarly, the ease with which we implemented system monitoring --- via both system introspection tables and rule rewriting --- arose because we could easily write rules that manipulated concepts as diverse as transient system state and program semantics, all stored in a unified database representation (Section~\ref{sec:manage}).

The uniformity of data-centric interfaces also allows
\emph{interposition}~\cite{jones-sosp93} of components in a natural manner: the
dataflow ``pipe'' between two system modules can be easily rerouted to go
through a third module. This enabled the simplicity of incorporating our Overlog
LATE scheduler into \BOOM-MR (Section~\ref{sec:mr-overlog}).  Because dataflows
can be routed across the network (via the location specifier in a rule's head),
interposition can also involve distributed logic --- this is how we easily added
Paxos support to the \BOOM-FS \NN\ (Section~\ref{sec:rely}).  Our experience
suggests that a form of encapsulation could be achieved by constraining the
points in the dataflow at which interposition is allowed to occur.

%Another advantage of the uniformity of representation is the resulting economy of mechanism.  Because the system consists of joining and aggregating tables, there is a small suite of tricks for addressing performance problems.  One trick is caching of computation via view materialization, as we discussed in our handling of fully-qualified file paths in Section~\ref{sec:proto}.  Another is building indexes on tables.  This came up in an early version of \BOOM-MR, when we were seeing very poor performance.  After some analysis, we realized that the Overlog-based \JT\ was examining scheduling options that it had rejected in previous timesteps.  The performance fix involved almost no code changes, just a modification to the data representation: we added a {\em dirty} column to the relevant tables to flag rows that were updated at the beginning of the timestep, and defined an index on that column.  The only code change was to modify a Java table function to set that bit upon insertion of a tuple, and an Overlog rule to turn off the bit at the end of a timestep. From then on, rules that considered those tables joined them in via the index, and only looked at newly-arrived data.

% \jmh{``Everything is data'': uniform treatment of core logic, invariant specification, exception handling, debugging monitoring, etc. Also enables powerful metaprogramming.  This is a very big bin, we may want to separate it out based on our war stories.}

In all, relatively little of this discussion seems specific to logic programming
per se.  Many modern languages and frameworks now support convenient high-level
programming over collection types (e.g., list comprehensions in Python, query
expressions in the LINQ framework~\cite{linq}, and algebraic dataflows like
MapReduce).  Programmers using those frameworks can enjoy many of the benefits
we identified in our work by adhering carefully to data-centric ``design
patterns'' when building distributed systems.  However, this requires
discipline in a programming language like Python, where data-centric design is
possible but not necessarily idiomatic.

% \jmh{``Message-centric Batch programming as a metaphor for communicating processes'': generalize the Declarative Networking argument that protocols are not so different from batch programs, and hence dataflow is a convenient methodology.  Lessons of transactional messaging: state mods happen via batch handling of messages and atomic computation of their higher-level (app) consequences, which is nicer to reason about than generic concurrent processes.  Something deeper here methinks -- in a state-machine model, you'd have to encapsulate consequences into individual states to get this atomicity, which would lead to a combinatorial blowup of state space?}

% \jmh{``Rapid prototyping and data independence'': Tyson's example of adding a column and an index to speed up the runtime.  Correctness first on the logic, performance second.  Combo of rapid prototyping, continuous integration, ``from working to working'', etc. grounded in the DB practice of separating logical from physical, and tuning both.}

%\jmh{Vs. Erlang or state machines: Without ``Everything is data'', tasks like monitoring, debugging, etc seem more onerous (?). W.r.t. ``batch programming'', simple exercise would be to think about streamJoin in Erlang, and scenarios where we joined streams to data.}


% \jmh{Help guys! What things did we talk about in the paper that ``join'' across apparently disparate data types?  Sometimes we do this as a ``trick'': e.g. passing API calls from Java into Overlog treats the callstream as a table.  Similarly integrating Assertion failures with \code{die}.  What about more fundamental stuff?  Maybe the best examples to date are from monitoring: messages and system state get logged as data, examined by invariants, which turn them back into Java exceptions, for example.  In future, this should make feedback loops pretty: events become data, get folded into decision-logic, generating new events that trigger other events that become data... and all along the chain we can tap, monitor, reuse.}


% Overlog vs. Erlang (from relwork.tex).  (1) identify cases where batchthink helps; aggregation may be a lever, join another.  Can you easily do a 2-way delta rewrite (symmetric hashjoin) on Erlang msgs?  Example here?  (2) logging (3) metaprogramming, (4) unification of different kinds of state.
%	\item Porting state machines to Overlog (from rely.tex).  What else to say about translating across conceptual programming models?  We leveraged two classic P2 design patterns: asynch comm with msg handlers, and transitive closure (in BFS).  Maybe there are more to learn about?
	% \item Distributed table consistency semantics, e.g. Boon's NDLog assumptions (from bg.tex).  Interesting that this didn't affect us one way or another.  Probably because of the level of our distributed logic.  On TOP of Paxos and/or 2PC you might actually want distributed tables.  In fact, if we implemented an actual MapReduce program in Overlog (which is a one-liner), it would be in terms of distributed tables -- that's the WHOLE POINT.  So it's not that we discard the P2 distributed table model, but it should live atop some mechanisms that make it likely to succeed.
%	\item Persistence was good enuf for now (from rely.tex).  This seems likely to change as we support mutiple programs accessing shared data.  But what would those circumstances look like (outside of the obvious sharing of persistent databases/files?)
%	\item Generic \JOL improvements (from proto.tex).  Compiled runtime in C.  Aspire to compete with native data movement code.
%	\item Not handling FS data movement in Overlog (from proto.tex).  See above.
%\end{itemize}
%\jmh{Should draw the distinction between what data-centric bought us, and what Logic bought us.  I.e. are there tricks we played that would have been hard to do over an algebraic dataflow description?  If not, then we can reiterate this point.}


%\jmh{I will write up the themes here top-down first, but we should really present this bottom up via the war-stories in the paper: i.e. how did we see that these themes helped us?}


%\paa{hard to do this without waxing tautological.  data is data.  protocols are state, transitions and messages.  distributed systems theory already collapses messages and state (channel state).  so protocols are state and transitions.  state is trivially data, and transitions are rules -- which are data, and metaprogrammable.  in a dataflow environment, exceptions are generated by data and are themselves data; propagation of exceptions is inference, which is rules, which are data, etc. ugh.}






\subsection{Developing in Overlog}
\label{sec:overlog-lessons}
Some of the benefits we describe above can be attributed to data-centric design,
while others relate to the high-level declarative nature of Overlog.  However,
Overlog is by no means a perfect language for distributed programming, and it
caused us various frustrations.  Many of the bugs we encountered were due to
ambiguities in the language semantics, particularly with regard to state update
and aggregate functions. This is partly due to Overlog's heritage: traditional
Datalog does not support updates, and Overlog's support for updates has never
had a formally-specified semantics. We have recently been working to address
this with new theoretical foundations~\cite{dedalus-tr}.

In retrospect, we made very conservative use of Overlog's support for
distributed queries: we used the \texttt{@} syntax as a convenient shorthand for
unidirectional messaging, but we did not utilize arbitrary distributed queries
(i.e., rules with two or more distinct location specifiers in their body
terms). In particular, we were unsure of the semantics of such queries in the
event of node failures and network partitions.

Instead, we implemented protocols for distributed messaging explicitly,
depending on the requirements at hand (e.g., Paxos consensus, communication
between {\NN} and {\DN}s). As we observed in Section~\ref{sec:hdfs-discuss},
this made the enforcement of distributed invariants somewhat ``lower-level''
than our specifications of local-node invariants. By examining the coding
patterns found in our hand-written messaging protocols, we hope to develop new
higher-level abstractions for specifying and enforcing distributed invariants.

During our Paxos implementation, we needed to translate state machine
descriptions into logic (Section~\ref{sec:rely}).  In fairness, the porting task
was not actually very hard: in most cases it amounted to writing
message-handling rules in Overlog that had a familiar structure.  But upon
deeper reflection, our port was shallow and syntactic; the resulting Overlog
does not ``feel'' like logic, in the invariant style of Lamport's original Paxos
specification. Now that we have achieved a functional Paxos implementation, we
hope to revisit this topic with an eye toward rethinking the \emph{intent} of the
state-machine optimizations.  This would not only fit the spirit of Overlog
better, but perhaps contribute to a deeper understanding of the ideas involved.

Finally, Overlog's syntax allows programs to be written concisely, but it can be
difficult and time-consuming to read. Some of the blame can be attributed to
Datalog's specification of joins via repetition of variable names. We are
experimenting with an alternative syntax based on SQL's named-field approach.


% We had one consistently recurring kind of bug in our code, which happened across multiple developers.  The issue was incorrect specification of the primary key columns when declaring our tables.  This apparently minor detail cost us more debugging time than any other language construct.  Key bugs manifested themselves in two broad ways: {\em data disappearance}, and {\em state bloat}.  Consider a simple messaging table {\tt \small buffer(\underline{SenderIP}, \underline{SequenceNumber}, Payload)}; the proper key includes the first {\em two} columns.  When we specified only the first column as the key, then each message tuple from a Sender would overwrite any prior message tuple.  Hence messages would ``mysteriously'' disappear from the system under load, when new messages would arrive before old messages were handled.  As a different example, consider a simple status table {\tt \small workers(\underline{nodeId}, time, status)}; the proper primary key is the first column alone.  When we incorrectly specified the first {\em two} columns as the key, status updates to a worker would be appended to the table {\em without} overwriting prior status, due to consistent differentiation in the time field.  In some cases we still observed correct system behavior -- e.g., when our rules considered only the most recent tuple per worker.  However, our system performance would quickly and mysteriously degrade, as rules would traverse ever-larger tables.  We do not have a simple panacaea for avoiding these bugs.  In our own code we learned to be careful with our primary key specifications, and we are now familiar with these failure symptoms.

% \jmh{can we put this in Section~\ref{sec:manage}?}
% \paa{one war story: the paxos bug neil caught running at scale because of tripping an assertion.  the assertion is "at any time, no two passed decrees have the same instance number and a different assertion", easily stated as a selection over a huge space of possibilities.  I didn't have a particular corner case in mind}


% \subsection{Consistency}
% Interesting issues arose in our interaction with Overlog's treatment of consistency.  In Section~\ref{sec:bg} we repeated an Overlog characterization from earlier papers: that the Overlog data model consists of globally-consistent relations that are stored by partitioning tuples across nodes by location specifier.  We had expected this abstraction to make our distributed programming task much easier, but this did not end up being the case.  First, we found that we did not need any significant distributed Overlog to reimplement Hadoop and HDFS, which are master-worker systems, not true distributed systems.  
% %For that effort, the most complex distributed rules we wrote were ones where all the body relations were partitioned the same way, but generated messages by having the head relation partitioned on another variable.  This corresponds to running local Datalog queries, and partitioning their results.  
% But even when we implemented Paxos and \NN\ partitioning, we did not write any rules with a mixture of location specifiers in the body; we found ourselves coding in a style where we were consciously pushing distribution into the heads (outputs) of rules.
% 
% Upon reflection, we had some discomfort with the lack of consistency guarantees offered by rules with mixed-location bodies, so we avoided them.
% % -- corresponding to distributed joins of partitioned Overlog tables.  
% Although Loo, et al.\ guarantee eventual consistency of these kinds of rules in some cases, they do not handle rules with aggregation, nor network partitions~\cite{loo-sigmod06}.  In writing Paxos, we made heavy use of aggregation (e.g., to count votes), and were writing a protocol specifically designed to reason about network partitions.  Rather than thinking through when and how Loo, et al.'s guarantees might hold, we coded in a style where we relied only on local deduction via rules with a single location specifier in the body.  
% 
% However, we are now ready to think about returning to the abstraction of globally-consistent tables in some cases.  After all, Map-Reduce is a successful programming paradigm built on the model of globally consistent collections, as is SQL.  The issue is a question of layering: once a certain level of consistency is provided by lower-level logic (e.g., HDFS), programmers should move to a higher level of abstraction that assumes that consistency.  To this end, we are exploring an extension to Overlog that exports consistency promises across layers, and discourages the use of code that assumes distributed consistency unless such promises have been offered by underlying code.
% 

% With respect to consistency of storage, we were comfortable with our
% model of associating a local storage transaction with each
% fixpoint. However, we expect that this may change as we evolve the use
% of \JOL.

\subsection{Performance}
\JOL\ performance was good enough for \BOOMA\ to match Hadoop performance, but
we are conscious that it has room to improve.  We observed that system load
averages were much lower with Hadoop than with \BOOMA.  We are now exploring a
reimplementation of the dataflow kernel of \JOL\ in C, with the goal of having
it run as fast as the OS network handling that feeds it.  This is not important
for \BOOMA, but will be important as we consider more interactive cloud
infrastructure.

In the interim, we actually think the modest performance of the
current \JOL\ interpreter guided us to reasonably good design choices.
By using Java for the data path in \BOOM-FS, for example, we ended up
spending very little of our development time on efficient data
transfer.  In retrospect, we were grateful to have used that time for
more challenging efforts like implementing Paxos.

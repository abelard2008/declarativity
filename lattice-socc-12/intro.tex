\section{Introduction}
\label{sec:intro}
%Distributed programming has become an essential and commonplace task,
%but most developers still find it challenging to write correct distributed
%programs. 
As cloud computing becomes increasingly common, the inherent difficulties of distributed systems---asynchrony,
concurrency, and partial failure---affect a growing segment of the developer community.
Traditionally, transactions and other forms of strong consistency encapsulated these problems at the data management layer.  But in recent years there has been interest in achieving application-level consistency criteria without incurring the latency and availability costs of strongly consistent storage~\cite{Birman2009,Helland2009}.
% % remind reviewers that it's a database problem. can remove if accepted! 
% % Much of the discussion about distributed programming today revolves around data
% % management, and the tradeoffs between transactions and weak
% % consistency. Programmers using distributed transactions are relieved of
% % consistency concerns but often face significant performance and operational
% % challenges~\cite{Birman2009,Helland2009}. By contrast, programmers who use loosely
% % consistent systems can expect more predictable and low-latency performance, but
% % must reason explicitly about program correctness over inconsistent distributed
% % state.
% 
% Much of the discussion about distributed programming today revolves around data
% management, and the tradeoffs between transactions and weak
% consistency. Programmers using distributed transactions are relieved of
% consistency concerns, but the coordination mechanisms that guarantee
% strong consistency are widely believed to raise unacceptable problems in
% performance and operational overhead~\cite{Birman2009,Helland2009}. As a result,
% there has been increased interest in techniques for achieving correct program
% behavior without requiring coordination.  
Two different frameworks for these
techniques have received significant attention in recent research:
\emph{Convergent Modules} and \emph{Monotonic Logic}.

% The coordination protocols that provide strong consistency are widely believed
% to raise unacceptable challenges in performance and operational overhead for
% modern systems~\cite{Birman2009,Helland2009}. As a result, there has been
% increased interest in techniques for achieving correct program behavior without
% requiring coordination.  Two different frameworks for these techniques have
% received significant attention in recent research: \emph{Convergent Modules} and
% \emph{Monotonic Logic}.
%Both of these frameworks guarantee confluence: eventually deterministic outcomes in the face of message reordering and delay.

\vspace{0.5em}\noindent
\textbf{Convergent Modules}: In this approach, a programmer writes encapsulated
modules whose public methods provide certain guarantees regarding message
reordering and retry. For example, Statebox is an open-source library that
merges conflicting updates to data items in a key-value store; the user of the
library need only register commutative, associative, idempotent merge
functions~\cite{statebox}. This approach has roots in research in
databases and systems~\cite{Farrag1989,Garcia-Molina1983,O'Neil1986,Helland2009,Terry1995} as well as
groupware~\cite{Ellis1989,Sun1998}.  Shapiro et al.\ recently proposed a formalism
for these approaches called \emph{Conflict-Free Replicated Data Types} (CRDTs),
which casts these ideas into the algebraic framework of {\em
  semi-lattices}~\cite{Shapiro2011a,Shapiro2011b}.

CRDTs present two main problems: (a) the programmer bears responsibilty for ensuring that lattice properties hold for their methods (commutativity, associativity, idempotence), and (b) CRDTs only provide guarantees for individual data objects, not for application logic in general. As an example of this second point, consider the following:

\vspace{-0.25em}
\begin{example}
A replicated, fault-tolerant courseware application assigns students into study teams.  It uses two \emph{set} CRDTs: one for \emph{Students} and another for \emph{Teams}.  The application reads a version of \emph{Students} and inserts the derived element $<$\emph{Alice,Bob}$>$ into \emph{Teams}. Concurrently, \emph{Bob} is removed from
\emph{Students} by another application replica. The use of CRDTs ensures that all replicas will
eventually agree that \emph{Bob} is absent from \emph{Students}, but this is not enough: application-level state
is inconsistent unless the derived values in \emph{Teams} are updated consistently to reflect \emph{Bob}'s
removal.  This is outside the scope of CRDT guarantees.
\end{example}

\vspace{-.25em}
Taken together, the problems with Convergent Modules present a {\bf scoping
  dilemma}: a small module (e.g., a set) makes lattice properties easy to
inspect and test, but provides only simple semantic guarantees. Large CRDTs
(e.g., an eventually consistent shopping cart) provide higher-level application
guarantees but require the programmer to ensure lattice properties hold for a
large module, resulting in software that is difficult to test, maintain, and
trust.
% 
% Although the CRDT maintains its own invariants, the programmer
% still bears the burden of ensuring the consistency semantics of the
% program as a whole.

% Many researchers have proposed the use of deductive database languages to enable
% high-level declarative implementations of distributed systems
% (e.g.,~\cite{Abiteboul2011,Alvaro2010,Field2009}).

\vspace{0.5em} \noindent
\textbf{Monotonic Logic}: In recent work, we observed that the database theory
literature on monotonic logic provides a powerful lens for reasoning about
distributed consistency. Intuitively, a monotonic program makes forward progress
on each input: it never ``retracts'' an earlier conclusion in the face of new
information. We proposed the CALM theorem, which established that all monotonic
programs are \emph{confluent} (invariant to message reordering and retry) and
hence eventually
consistent~\cite{Ameloot2011,Hellerstein2010,dedalus-confluence}. Monotonicity
of a Datalog program is straightforward to determine conservatively from
syntax, so the CALM theorem provides the basis for a simple analysis technique
for verifying the consistency of distributed programs. We concretized CALM into
an analysis procedure for \emph{Bloom}, a Datalog-based language for distributed
programming~\cite{Alvaro2011,bloom}

The original formulation of CALM and Bloom only verified the consistency of
programs that compute sets of facts that grow over time (``set monotonicity'');
that is, ``forward progress'' was defined according to set containment. As a practical
matter, this is overly conservative: it precludes the use of common monotonically-increasing
constructs such as timestamps and sequence numbers. 

\vspace{-0.25em}
\begin{example}  In a
quorum voting service, a coordinator counts the number of votes received
from participant nodes; quorum is reached once the number of votes exceeds a
threshold. This is clearly monotonic: the vote counter increases
monotonically, as does the threshold test ($\mathtt{count(votes)} > k$) which ``grows'' from False to True. But both of these constructs (upward-moving
mutable variables and aggregates) are labeled non-monotonic by the
original CALM analysis.
\end{example}

\vspace{-.25em}
Monotonic Logic solves the scope dilemma of CRDTs but presents a \textbf{type dilemma}: sets are the only data type amenable to CALM analysis, but the programmer may have a more natural representation of a monotonically growing phenomenon. For example, a monotonic counter is more naturally represented as a growing integer than a growing set. This dilemma leads either to false negatives in CALM analysis and over-use of coordination, or to idiosyncratic set-based implementations that can be hard to read and maintain.

% \jmh{A problem with the above trading examples are that we don't return to them ever again. At minimum, we should flag that we return to the constructs they use: replicated mutable set, counters and threshold tests.}
\subsection{\lang: Logic and Lattices}
% The strengths and weaknesses of these two approaches appear
% complementary. CRDTs provide synchronization-free consistent objects, but
% cannot guarantee whole-program consistency. Bloom's CALM analysis guarantees
% whole-program consistency but is unable to verify a number of natural
% coordination-free mechanisms.
We address the two dilemmas above with \emph{\lang,} an extension to Bloom that
incorporates a semilattice construct similar to CRDTs.  We present this construct in detail below, but the intuition is that \lang programs can be defined over arbitrary types---not just sets---as long as they have commutative, associative, idempotent \emph{merge functions} (``least upper bound'') for pairs of items.  Such a merge function defines a partial order  for its type. This
generalizes Bloom (and traditional Datalog), which assumes a fixed merge
function (set union) and partial order (set containment).

% Relate user-defined merge functions to merge functions in other contexts?
% (e.g., key-value store, COPS, Piccolo)

\lang provides three main improvements in the state of the art of both Bloom and CRDTs:  
\begin{enumerate}
\item \lang solves the type dilemma of logic programming: CALM analysis in \lang is able to 
 assess monotonicity for arbitrary lattices, making it significantly more liberal in its ability to test for confluence.  \lang can validate the coordination-free use of
  common constructs like timestamps and sequence numbers.

\item {\lang} solves the scope dilemma of CRDTs by providing monotonicity-preserving mappings between lattices via
  \emph{morphisms} and \emph{monotone functions}, as described below.  By using such mappings, the
  per-component monotonicity guarantees offered by CRDTs can be extended across
  multiple items of lattice type.  This capability is key to the CALM
  analysis described above.  It is also useful for
  establishing the monotonicity of sub-programs even when the whole program is
  not designed to be monotonic.

\item For efficient incremental execution, we extend the standard Datalog semi-naive
  evaluation scheme~\cite{Balbin1987} to support arbitrary lattices. We also describe how an existing Datalog-style engine can be
  extended to support lattices with relatively minor changes.
\end{enumerate}

% \subsection{Beyond confluence}
% Both Convergent Objects and Monotonic Logic provide eventual consistency in the face of message delay and reordering.  In fact they provide an even stronger guarantee than consistency: {\em confluent} (i.e., deterministic) outcomes.  However, many distributed applications are not intended to be confluent.  Instead, they use coordination to achieve {\em controlled non-determinism}: the ability for timing conditions to affect the choice of one among many acceptable outcomes. This includes applications that require serializability or causal consistency, both of which employ coordination to stay within a ``family'' of acceptable timing schedules.  
% 
% The coordination protocols used for controlled non-determinism are expressible in Bloom, but typical implementations are not syntactically monotonic~\cite{Alvaro2011}.  In many cases, however, these protocols work in a monotonic fashion, providing distributed barriers in computation by using constructs like arrays of mutable counters.  These protocols can be quite directly mapped to \lang using lattices.  This further improves the fit between Bloom's logic programming roots and standard practice in distributed programming.  On a more concrete basis, \lang can provide strong monotonicity guarantees for these coordination constructs.  This can ensure, for example, that a barrier-inducing protocol does indeed ``coordinate'' correctly: it monotonically transitions from ``Wait'' to ``Go''.

\subsection{Outline}
The remainder of the paper proceeds as follows.  Section~\ref{sec:background}
provides background on Bloom and CALM.  In Section~\ref{sec:lang} we introduce
\lang, including cross-lattice morphisms and monotonic functions. We detail
\lang's built-in lattice types and show how developers can define new lattices.
We also describe how the CALM analysis extends to \lang.  In
Section~\ref{sec:impl}, we describe how we modified the Bloom runtime to support
\lang, including our extension to semi-naive evaluation that supports both
lattices and relations.

In Sections~\ref{sec:kvs} and~\ref{sec:carts}, we present two case studies.
First, we use \lang to implement a distributed key-value store that supports
eventual consistency, object versioning using vector clocks, and quorum
replication. Second, we revisit the simple e-commerce scenario presented in
Alvaro et al.\ in which clients interact with a replicated shopping cart
service~\cite{Alvaro2011}. We show how \lang can be used to make the
``checkout'' operation monotonic and confluent, despite the fact that it
requires aggregating over a distributed data set.

  % We generalize the CALM analysis to programs that contain both lattices and
  % set-oriented collections, and show how lattices can be used to prove the
  % confluence of several common distributed design patterns that were regarded as
  % non-monotonic in Bloom. % XXX: revisit this

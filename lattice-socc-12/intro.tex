\section{Introduction}
\label{sec:intro}
Although distributed programming has become an essential and commonplace task,
it remains challenging for most developers to write correct distributed
programs. The inherent difficulties of distributed computing---asynchrony,
concurrency, and partial failure---are exacerbated by the scale at which many
modern systems operate.

% remind reviewers that it's a database problem. can remove if accepted! 
% Much of the discussion about distributed programming today revolves around data
% management, and the tradeoffs between transactions and weak
% consistency. Programmers using distributed transactions are relieved of
% consistency concerns but often face significant performance and operational
% challenges~\cite{Birman2009,Helland2009}. By contrast, programmers who use loosely
% consistent systems can expect more predictable and low-latency performance, but
% must reason explicitly about program correctness over inconsistent distributed
% state.

Much of the discussion about distributed programming today revolves around data
management, and the tradeoffs between transactions and weak
consistency. Programmers using distributed transactions are relieved of
consistency concerns, but the coordination protocols that are needed to achieve
strong consistency are widely believed to raise unacceptable challenges in
performance and operational overhead~\cite{Birman2009,Helland2009}. As a result,
there has been increased interest in techniques for achieving correct program
behavior without requiring coordination.  Two different frameworks for these
techniques have received significant attention in recent research:
\emph{Convergent Modules} and \emph{Monotonic Logic}.

% The coordination protocols that provide strong consistency are widely believed
% to raise unacceptable challenges in performance and operational overhead for
% modern systems~\cite{Birman2009,Helland2009}. As a result, there has been
% increased interest in techniques for achieving correct program behavior without
% requiring coordination.  Two different frameworks for these techniques have
% received significant attention in recent research: \emph{Convergent Modules} and
% \emph{Monotonic Logic}.
%Both of these frameworks guarantee confluence: eventually deterministic outcomes in the face of message reordering and delay.

\vspace{0.5em}\noindent
\textbf{Convergent Modules}: In this approach, a programmer writes encapsulated
modules whose public methods guarantee certain properties regarding message
reordering and retry. For example, Statebox is an open-source library that
merges conflicting updates to data items in a key-value store; the user of the
library need only register commutative, idempotent merge
functions~\cite{statebox}. This approach has roots in research in
databases~\cite{Farrag1989,Garcia-Molina1983,Helland2009} and
groupware~\cite{Ellis1989,Sun1998}.  Shapiro et al.\ recently proposed a model
for these approaches called \emph{Conflict-Free Replicated Data Types} (CRDTs),
which formalizes these ideas in the algebraic framework of {\em join
  semilattices}~\cite{Shapiro2011b}.

The main problem with the CRDT approach is that it provides guarantees only
for individual data values, not for application logic in general. For example,
consider an application that uses a CRDT to represent a mutable set. Suppose the
application reads a version of the set and computes a derived value~$y$ that is
conditional on $x$ being present in the set. Concurrently, $x$ is removed from
the set by another replica. While the CRDT ensures that all replicas will
eventually agree that $x$ is absent from the set, application-level state may
remain inconsistent unless the derived value $y$ is updated to reflect the
removal of $x$. Although the CRDT maintains its own invariants, the programmer
still bears the burden of ensuring the consistency semantics of the entire
program.

% Many researchers have proposed the use of deductive database languages to enable
% high-level declarative implementations of distributed systems
% (e.g.,~\cite{Abiteboul2011,Alvaro2010,Field2009}).

\vspace{0.5em} \noindent
\textbf{Monotonic Logic}: In recent work, we observed that the database theory
literature on non-monotonic logic provides a promising starting point for
reasoning about distributed consistency. Intuitively, a \emph{monotonic} program
computes more information over time---it never ``retracts'' an earlier
conclusion in the face of new information. We proposed the CALM theorem, which
established that all monotonic programs are \emph{confluent} (invariant to
message reordering) and hence eventually
consistent~\cite{Ameloot2011,Hellerstein2010,dedalus-confluence}. Monotonicity of
a Datalog-style program is straightforward to determine conservatively from
syntax, so the CALM theorem provides the basis for a simple analysis technique
for verifying the consistency of distributed programs. We realized CALM analysis
as part of Bloom, a Datalog-based domain-specific language for distributed
programming~\cite{Alvaro2011,bloom}.

The original formulation of Bloom and CALM only verified the consistency of
programs that compute sets of facts that grow over time (``set monotonicity'');
that is, ``growth'' was defined according to set containment. As a practical
matter, this is overly conservative because it precludes the use of common
constructs such as timestamps and sequence numbers. For example, consider a
quorum voting scheme where a coordinator counts the number of votes received
from participant nodes. A quorum is reached once the number of votes exceeds a
threshold. This is monotonic in the broad sense: the vote counter increases
monotonically and the threshold test ($\mathtt{count(votes)} > k$) also grows
monotonically from False to True. But both of these constructs (upward-moving
mutable variables and aggregates) are considered to be non-monotonic by the
original CALM analysis.  As a result, the initial Bloom prototype would
mistakenly suggest that the voting program needs additional coordination logic
to ensure consistent results.

% \jmh{A problem with the above trading examples are that we don't return to them ever again. At minimum, we should flag that we return to the constructs they use: replicated mutable set, counters and threshold tests.}
\subsection{\lang: Logic and Lattices}
% The strengths and weaknesses of these two approaches appear
% complementary. CRDTs provide synchronization-free consistent objects, but
% cannot guarantee whole-program consistency. Bloom's CALM analysis guarantees
% whole-program consistency but is unable to verify a number of natural
% coordination-free mechanisms.
Instead of only allowing growth according to the set containment partial order,
we would like to allow any user-defined partial order to be used.  To this end,
we introduce \lang, an extension to Bloom which provides a programming
construct for defining join semilattices like CRDTs.  We give a formal
definition of this construct below, but the intuition is that the programmer
provides a commutative, idempotent merge function (``least upper bound'') that
takes two input values and produces an output value that is greater than or
equal to both input values, according to the user's partial order. This
generalizes Bloom (and traditional Datalog), which assumes a fixed merge
function (set union) and partial order (set containment).

% Relate user-defined merge functions to merge functions in other contexts?
% (e.g., key-value store, COPS, Piccolo)

\lang provides three main improvements in the state of the art of both Bloom and CRDTs:  
\begin{enumerate}
\item By combining lattices and logic, the CALM analysis in \lang is able to be
  significantly more liberal in identifying monotonic code that is confluent
  without the need for coordination.  This enables the coordination-free use of
  common monotonic constructs, including timestamps and sequence numbers.

\item {\lang} provides monotonicity-preserving mappings between lattices via
  \emph{morphisms} and \emph{monotone functions}.  By using such mappings, the
  per-component monotonicity guarantees offered by CRDTs can be extended across
  multiple lattice-based components.  This capability is key to the CALM
  analysis of monotonic \lang programs described above.  It is also useful for
  establishing the monotonicity of sub-programs even when the whole program is
  not designed to be monotonic.

\item For efficient execution, we extend the standard Datalog semi-naive
  evaluation scheme~\cite{Balbin1987} to support both lattices and traditional
  database relations. We also describe how an existing Datalog engine can be
  extended to support lattices with relatively minor changes.
\end{enumerate}

% \subsection{Beyond confluence}
% Both Convergent Objects and Monotonic Logic provide eventual consistency in the face of message delay and reordering.  In fact they provide an even stronger guarantee than consistency: {\em confluent} (i.e., deterministic) outcomes.  However, many distributed applications are not intended to be confluent.  Instead, they use coordination to achieve {\em controlled non-determinism}: the ability for timing conditions to affect the choice of one among many acceptable outcomes. This includes applications that require serializability or causal consistency, both of which employ coordination to stay within a ``family'' of acceptable timing schedules.  
% 
% The coordination protocols used for controlled non-determinism are expressible in Bloom, but typical implementations are not syntactically monotonic~\cite{Alvaro2011}.  In many cases, however, these protocols work in a monotonic fashion, providing distributed barriers in computation by using constructs like arrays of mutable counters.  These protocols can be quite directly mapped to \lang using lattices.  This further improves the fit between Bloom's logic programming roots and standard practice in distributed programming.  On a more concrete basis, \lang can provide strong monotonicity guarantees for these coordination constructs.  This can ensure, for example, that a barrier-inducing protocol does indeed ``coordinate'' correctly: it monotonically transitions from ``Wait'' to ``Go''.

\subsection{Outline}
The remainder of the paper proceeds as follows.  Section~\ref{sec:background}
provides background on Bloom and CALM.  In Section~\ref{sec:lang} we introduce
\lang, including cross-lattice morphisms and monotonic functions. We detail
\lang's built-in lattice types and show how developers can define new lattices.
We also describe how the CALM analysis extends to \lang.  In
Section~\ref{sec:impl}, we describe how we modified the Bloom runtime to support
\lang, including our extension to semi-naive evaluation that supports both
lattices and relations.

In Sections~\ref{sec:carts} and~\ref{sec:causal}, we consider two case studies
from the literature.  First we revisit the simple e-commerce scenario presented
in Alvaro et al.\ in which clients interact with a replicated shopping cart
service~\cite{Alvaro2011}. We show how \lang can be used to make the
``checkout'' operation monotonic and therefore confluent, despite the fact that
it requires aggregating over a distributed data set.  Second, we use \lang to
implement vector clocks and causal delivery, two standard building blocks for
non-confluent distributed programming.%   In the case of vector clocks, we show
% that our implementation is a line-for-line match to the algorithm
% pseudocode---anecdotal evidence that \lang is a good fit for distributed
% programming.

  % We generalize the CALM analysis to programs that contain both lattices and
  % set-oriented collections, and show how lattices can be used to prove the
  % confluence of several common distributed design patterns that were regarded as
  % non-monotonic in Bloom. % XXX: revisit this

\documentclass{article}
\usepackage{fullpage}
\title{BoomFS: A Declarative Distributed Filesystem}
\author{Peter Alvaro, Neil Conway}
\date{December 20, 2008}
\begin{document}
\maketitle
\begin{abstract}
  While architectures for distributed computing are changing rapidly,
  techniques for building distributed systems have remained
  stagnant. As distributed computation becomes the common case,
  traditional techniques for building distributed systems will become
  untenable, because they force programs to deal with the mundane
  boilerplate details of constructing reliable distributed
  systems. This yields programs that are difficult to construct,
  understand, modify, and port to new environments. We propose BOOM, a
  new paradigm for concisely specifying a broad class of distributed
  systems. In this paper, we describe the first application in the
  BOOM stack: BoomFS, a distributed filesystem similar to the Google
  File System\cite{gfs} that is implemented in a mixture of Java and
  declarative logic.
\end{abstract}

\section{Introduction}
With the widespread adoption of cloud computing, pervasive mobile
clients, and many-core processors, computing architectures are
undergoing a period of disruptive change. In the near future, nearly
every non-trivial software system will be physically distributed:
distributed programming will be the common case.

Traditional techniques for building distributed systems are ill-suited
to this new environment. Despite considerable research, developing
fault-tolerant distributed systems remains enormously difficult and
expensive, and is typically only attempted by experienced programmers
with extensive training in the field. As more journeyman developers
must deal with the challenges of distributed computing as a matter of
course, this situation will become untenable. Better techniques for
constructing distributed systems are urgently needed.

We believe a new approach to building distributed systems is necessary
to address this need. Inspired by prior work on declarative
networking, \ldots

In Section 2, we discuss the failings of traditional tools for
building distributed systems, and outline the BOOM vision in
contrast. We also motivate our decision to begin the BOOM project by
implementing a declarative file system. In Section 3, we describe the
design goals and basic architecture of BoomFS. In Section 4, we detail
how this architecture was realized in the BOOM style. In Section 5, we
report on a performance study comparing BoomFS and HDFS\cite{}. In
Section 6, we explore extensions to the file system that are
facilitated by our use of a declarative coordination language. In
Section 7, we discuss related work, and we conclude in Section 8.

\section{The BOOM Vision}
The fundamental problem with traditional techniques for building
distributed systems is that they provide the wrong abstractions to the
programmer. Distributed systems are typically implemented with tools
developed for single-machine programs, and only superficially adapted
to the challenges of a distributed setting. Programmers are forced to
deal with the mundane details of communication, synchronization, and
consensus. As a result, the essence of the distributed computation is
obscured by a forest of boilerplate details. Evidence for this can be
seen in the fact that distributed algorithms such as Paxos can be
stated in a page of pseudocode, but typically require many thousands
of lines of code to implement using standard
tools\cite{paxosmadelive}.

Traditional tools operate at a low level of abstraction because they
force programmers to intermingle the specification of \emph{what} a
distributed program should do with \emph{how} it can be done. This
results in fragile programs that fail to adapt to changes in their
environments. For example, consider a client program that wants to
compute a function over data stored in a compute cloud. Should the
function code be sent to the server, or should the data be sent to the
client? The optimal policy depends on factors including the relative
costs of network bandwidth, server-side computation and client-side
computation, as well as how much data is required, how expensive the
function is, and the frequency with which the function is invoked or
the input data is modified. All of these variables are likely to
fluctuate in a distributed system, so encoding a particular decision
into the application program results in a fragile design. This
fragility results in programs that cannot easily be modified, or
ported to distributed systems with varying performance
characteristics.

Inspired by the data independence provided by the relational model, we
aim to provide \emph{network scale independence} for distributed
systems by separating the programmer's intent from its concrete
realization. In BOOM, a distributed system is composed of two types of
components:
\begin{itemize}
\item
  \emph{imperative} components implement the basic units of
  functionality of a distributed system. Imperative components are
  typically used to perform tasks like I/O and numerical
  computation. These tasks are usually best stated in an imperative
  language like Java or C++, particularly because these components
  often involve interaction with the operating system or native
  libraries. In BoomFS, imperative components implemented in Java are
  used to transfer data chunks between hosts, and to read and write
  data from the native file system.

\item
  \emph{declarative} components specify the bulk of the logic of the
  distributed system. Declarative components are written as a
  collection of logical rules that describe the coordination and
  composition of the imperative components. Essentially, the
  declarative logic is responsible for deciding ``what'' a member of
  the distributed system should do; the imperative components are
  responsible for realizing those actions. A declarative component is
  essentially a join between a stream of events and a
  database. Evaluating this query over an event stream results in
  producing more events (either at the local node or a remote node),
  inserting new database tuples, or invoking imperative
  components.

  Declarative components are implemented in a high-level declarative
  logic language, such as Overlog[cite]. This requires the state of
  the distributed system to be represented in tables.

  In BoomFS, declarative components implement the protocols between
  clients and master nodes, between different masters, and between
  masters and data nodes. That is, declarative rules implement the
  ``control path''; the data path (from clients to data nodes and
  between different data nodes, is implemented as an imperative
  component, because it is straightforward and primarily involves
  copying bytes.
\end{itemize}

\subsection{Declarative Specification of Distributed Filesystems}
Why choose GFS to implement in a declarative language?
\begin{itemize}
\item
  Separation of control and data paths in the design.

\item
  Data centric, ``systemsy''

\item
  Existing implementations intermingle policy and mechanism
\end{itemize}

\section{System Architecture}

\section{System Realization}
\begin{itemize}
\item
  Language integration: what belongs in declarative land, and what in
  imperative land?

\item
  Representation of data

\item
  Use of Paxos as a component
\end{itemize}

\section{Performance Evaluation}
Compared with HDFS. Look at both overall throughput, and metadata ops/second.

\section{Future Work}
\begin{itemize}
\item
  Challenges/difficulties

\item
  Some of the Lincoln vision?

\item
  Cross-layer optimizations

\item
  Continuous query optimization

\item
  Hadoop integration
\end{itemize}

\section{Related Work}

\section{Conclusions}

\bibliographystyle{abbrv}
\bibliography{paper}
\appendix
\section{Paxos in Overlog}
\end{document}
